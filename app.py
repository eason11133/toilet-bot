import os
import csv
import json
import logging
import requests
import traceback
from math import radians, cos, sin, asin, sqrt
from flask_cors import CORS
from flask import Flask, request, abort, render_template, redirect, url_for, Response
from dotenv import load_dotenv
from urllib.parse import quote, unquote
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import (
    MessageEvent, TextMessage, LocationMessage,
    FlexSendMessage, PostbackEvent, TextSendMessage
)
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import joblib
import threading
import time
import statistics
from difflib import SequenceMatcher
from collections import defaultdict
import random
import re
from queue import Queue, Empty, Full

load_dotenv()
try:
    import pandas as pd
except Exception:
    pd = None

# ======================== Sheets å®‰å…¨å¤–æ›å±¤ï¼ˆæ–°å¢ï¼Œä¸å‹•åŸåŠŸèƒ½ï¼‰ ========================
SHEETS_MAX_CONCURRENCY = int(os.getenv("SHEETS_MAX_CONCURRENCY", "4"))
SHEETS_RETRY_MAX = int(os.getenv("SHEETS_RETRY_MAX", "6"))
SHEETS_READ_TTL_SEC = int(os.getenv("SHEETS_READ_TTL_SEC", "30"))
SHEETS_CACHE_MAX_ROWS = int(os.getenv("SHEETS_CACHE_MAX_ROWS", "20000"))

_sheets_sem = threading.Semaphore(SHEETS_MAX_CONCURRENCY)
_read_cache = {}            # key: (sheet_id, ws_title, op) -> {ts, val}
_cache_lock = threading.Lock()

def _is_quota_or_retryable(exc: Exception) -> bool:
    s = str(exc).lower()
    return ("429" in s or "quota" in s or "rate limit" in s or
            "timeout" in s or "timed out" in s or "503" in s or "500" in s)

def _with_retry(func, *args, **kwargs):
    backoff = 0.7
    for i in range(SHEETS_RETRY_MAX):
        try:
            with _sheets_sem:
                return func(*args, **kwargs)
        except Exception as e:
            if _is_quota_or_retryable(e):
                sleep_s = backoff * (2 ** i) + random.uniform(0, 0.25*i)
                time.sleep(sleep_s)
                continue
            raise
    raise

class SafeWS:
    """åŒ…è£ gspread worksheetï¼šè®€å–åŠ  TTL å¿«å–ï¼›æ‰€æœ‰æ“ä½œåŠ é€€é¿èˆ‡ä½µç™¼é–¥ã€‚"""
    def __init__(self, ws, sheet_id: str, name: str):
        self._ws = ws
        self._sheet_id = sheet_id
        self._name = name

    def get_all_values(self):
        key = (self._sheet_id, self._name, "get_all_values")
        now = time.time()
        with _cache_lock:
            c = _read_cache.get(key)
            if c and now - c["ts"] < SHEETS_READ_TTL_SEC:
                return c["val"]
        def _do():
            return self._ws.get_all_values()
        val = _with_retry(_do)
        if len(val) <= SHEETS_CACHE_MAX_ROWS:
            with _cache_lock:
                _read_cache[key] = {"ts": now, "val": val}
        return val

    def _invalidate(self):
        key = (self._sheet_id, self._name, "get_all_values")
        with _cache_lock:
            _read_cache.pop(key, None)

    def update(self, rng, values):
        def _do():
            return self._ws.update(rng, values)
        out = _with_retry(_do); self._invalidate(); return out

    def append_row(self, values, value_input_option="RAW"):
        def _do():
            return self._ws.append_row(values, value_input_option=value_input_option)
        out = _with_retry(_do); self._invalidate(); return out

    def delete_rows(self, index):
        def _do():
            return self._ws.delete_rows(index)
        out = _with_retry(_do); self._invalidate(); return out

    # è½‰ç™¼
    def row_values(self, i):           return _with_retry(self._ws.row_values, i)
    def worksheet(self, title):        return self.__class__(self._ws.worksheet(title), self._sheet_id, title)
    @property
    def title(self):                   return self._ws.title

# consent èƒŒæ™¯æ’éšŠï¼ˆ429 æ™‚ä¸å› 500ï¼‰
_consent_q = []
_consent_lock = threading.Lock()
def _start_consent_worker():
    def loop():
        while True:
            job = None
            with _consent_lock:
                if _consent_q:
                    job = _consent_q.pop(0)
            if not job:
                time.sleep(0.2); continue
            try:
                job()
            except Exception as e:
                logging.error(f"Consent worker error: {e}")
    threading.Thread(target=loop, daemon=True).start()
_start_consent_worker()
# ====================== /Sheets å®‰å…¨å¤–æ›å±¤ ======================

# === Fast-ACK ä½‡åˆ—èˆ‡å·¥äºº ===
TASK_Q = Queue(maxsize=int(os.getenv("TASK_QUEUE_SIZE", "5000")))
BOT_WORKERS = int(os.getenv("BOT_WORKERS", "8"))

def _worker_loop():
    while True:
        try:
            job = TASK_Q.get(timeout=0.2)
        except Empty:
            continue
        try:
            job()  # ä»»å‹™å…§æœƒç”¨ push_message å›è¦†
        except Exception as e:
            logging.error(f"[worker] error: {e}", exc_info=True)
        finally:
            TASK_Q.task_done()

for _ in range(BOT_WORKERS):
    threading.Thread(target=_worker_loop, daemon=True).start()

# === åˆå§‹åŒ– ===
logging.basicConfig(level=logging.INFO)
app = Flask(__name__)
CORS(app)

class _NoHealthzFilter(logging.Filter):
    def filter(self, record):
        try:
            msg = record.getMessage()
        except Exception:
            return True
        return "/healthz" not in msg

logging.getLogger("werkzeug").addFilter(_NoHealthzFilter())

@app.route("/statusz", methods=["GET"])
def statusz():
    payload = {
        "mode": guard.mode,
        "suspended_until": guard.suspended_until,
        "monthly_limit": guard.monthly_limit,
        "monthly_used": guard.monthly_used,
    }
    return Response(json.dumps(payload, ensure_ascii=False),
                    status=200,
                    headers={"Content-Type":"application/json; charset=utf-8","Cache-Control":"no-store"})

# === å¥åº·æª¢æŸ¥ç«¯é» ===
@app.route("/healthz", methods=["GET", "HEAD"])
def healthz():
    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-store",
        "X-Robots-Tag": "noindex",
    }
    if request.method == "HEAD":
        return Response(status=204, headers=headers)
    return Response("ok", status=200, headers=headers)

# === è‡ªæˆ‘æ¿€æ´»è¨­å®š ===
KEEPALIVE_URL = (
    os.getenv("KEEPALIVE_URL")
    or (os.getenv("PUBLIC_URL") and os.getenv("PUBLIC_URL").rstrip("/") + "/healthz")
    or (os.getenv("RENDER_EXTERNAL_URL") and os.getenv("RENDER_EXTERNAL_URL").rstrip("/") + "/healthz")
)
KEEPALIVE_ENABLE = os.getenv("KEEPALIVE_ENABLE", "1") == "1"
KEEPALIVE_INTERVAL_SECONDS = int(os.getenv("KEEPALIVE_INTERVAL_SECONDS", "600"))
KEEPALIVE_JITTER_SECONDS   = int(os.getenv("KEEPALIVE_JITTER_SECONDS", "60"))

def _self_keepalive_background():
    if not KEEPALIVE_ENABLE or not KEEPALIVE_URL:
        logging.info("â­ï¸ keepalive disabled (no URL or disabled by env).")
        return
    headers = {"User-Agent": f"SelfKeepalive/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}
    while True:
        try:
            requests.head(KEEPALIVE_URL, timeout=8, headers=headers)
            logging.debug("âœ… keepalive ok")
        except Exception as e:
            logging.debug(f"âš ï¸ keepalive failed: {e}")
        sleep_for = KEEPALIVE_INTERVAL_SECONDS + random.randint(0, KEEPALIVE_JITTER_SECONDS)
        time.sleep(sleep_for)

line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

# === æ°¸ä¹…ç‰ˆï¼šMessagingGuardï¼ˆé…é¡/é™ç´š/ä¸Šé™ ä¸€æ¬¡æå®šï¼‰ ===
LINE_LIMIT_COOLDOWN_SEC = int(os.getenv("LINE_LIMIT_COOLDOWN_SEC", str(7*24*3600)))
USER_DAILY_LIMIT = int(os.getenv("USER_DAILY_LIMIT", "6"))
DEGRADE_WARN_REMAIN_PCT = float(os.getenv("DEGRADE_WARN_REMAIN_PCT", "0.15"))
USAGE_POLL_SECONDS = int(os.getenv("USAGE_POLL_SECONDS", "600"))
SEND_UPDATE_CARD = os.getenv("SEND_UPDATE_CARD", "0") == "1"  # 2 å¼µå¡æ”¹æˆå¯é–‹é—œ

CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
_session = requests.Session()

class Mode:
    NORMAL="NORMAL"
    SAVER="SAVER"
    HARD_STOP="HARD_STOP"

class MessagingGuard:
    def __init__(self):
        self.mode = Mode.NORMAL
        self.suspended_until = 0.0
        self.monthly_limit = None
        self.monthly_used = 0
        self.lock = threading.Lock()
        self.user_daily = defaultdict(lambda: {"date":"", "count":0})
        self._start_usage_poller()

    def reply(self, event, messages, fallback_text_with_url=None):
        uid = getattr(event.source, "user_id", None)
        if not self._allow_send(uid):
            self._log_skip(uid, "reply")
            if fallback_text_with_url and self.mode != Mode.HARD_STOP:
                self._safe_reply_text(event, fallback_text_with_url)
            return False
        ok = self._guard.reply(event, messages, uid)
        if ok: self._bump(uid)
        return ok

    def push(self, uid, messages, fallback_text_with_url=None):
        if not self._allow_send(uid):
            self._log_skip(uid, "push")
            if fallback_text_with_url and self.mode != Mode.HARD_STOP:
                self._safe_push_text(uid, fallback_text_with_url)
            return False
        ok = self._safe_push(uid, messages)
        if ok: self._bump(uid)
        return ok

    # ---- åˆ¤æ–·/çµ±è¨ˆ ----
    def _allow_send(self, uid):
        now = time.time()
        with self.lock:
            if now < self.suspended_until:
                self.mode = Mode.HARD_STOP
                return False
            if self.mode == Mode.HARD_STOP:
                return False
            if uid:
                today = datetime.utcnow().strftime("%Y-%m-%d")
                rec = self.user_daily[uid]
                if rec["date"] != today:
                    rec["date"], rec["count"] = today, 0
                if rec["count"] >= USER_DAILY_LIMIT:
                    return False
            return True  # SAVER/NORMAL éƒ½å…è¨±ï¼Œç”±å‘¼å«ç«¯æ±ºå®šé€ä»€éº¼å…§å®¹

    def _bump(self, uid):
        if not uid: return
        today = datetime.utcnow().strftime("%Y-%m-%d")
        rec = self.user_daily[uid]
        if rec["date"] != today:
            rec["date"], rec["count"] = today, 0
        rec["count"] += 1

    def _log_skip(self, uid, kind):
        logging.info("â­ï¸ guard-skip %s uid=%s mode=%s used=%s limit=%s",
                     kind, uid, self.mode, self.monthly_used, self.monthly_limit)

    # ---- çœŸæ­£é€è¨Šï¼ˆå« 429 ç†”çµ²ï¼‰ ----
    def _safe_reply(self, event, messages, uid):
        try:
            line_bot_api.reply_message(event.reply_token, messages)
            return True
        except LineBotApiError as e:
            if self._is_monthly_limit(e): self._trip_fuse(); return False
            logging.warning(f"reply_message å¤±æ•—ï¼š{e}")
            return False

    def _safe_push(self, uid, messages):
        try:
            guard.push(uid, messages)
            return True
        except LineBotApiError as e:
            if self._is_monthly_limit(e): self._trip_fuse(); return False
            logging.error(f"push_message å¤±æ•—ï¼š{e}")
            return False

    def _safe_reply_text(self, event, text):
        try:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=text))
        except Exception as e:
            if self._is_monthly_limit(e): self._trip_fuse()

    def _safe_push_text(self, uid, text):
        try:
            guard.push(uid, TextSendMessage(text=text))
        except Exception as e:
            if self._is_monthly_limit(e): self._trip_fuse()

    def _is_monthly_limit(self, err):
        s = str(err).lower()
        return ("you have reached your monthly limit" in s) or ("status_code=429" in s)

    def _trip_fuse(self):
        with self.lock:
            self.suspended_until = time.time() + LINE_LIMIT_COOLDOWN_SEC
            self.mode = Mode.HARD_STOP
        logging.error("ğŸš« LINE monthly limit reached -> HARD_STOP for %d sec", LINE_LIMIT_COOLDOWN_SEC)

    # ---- ç›£æ§ï¼šå®šæœŸæŠ“ç”¨é‡ä¸¦è‡ªå‹•é™ç´š ----
    def _poll_usage_once(self):
        if not CHANNEL_ACCESS_TOKEN: return
        headers = {"Authorization": f"Bearer {CHANNEL_ACCESS_TOKEN}"}
        try:
            r1 = _session.get("https://api.line.me/v2/bot/message/quota", headers=headers, timeout=8)
            if r1.ok:
                data = r1.json()
                if data.get("type") == "limited":
                    self.monthly_limit = int(data.get("value", 0))
                else:
                    self.monthly_limit = None
            r2 = _session.get("https://api.line.me/v2/bot/message/quota/consumption", headers=headers, timeout=8)
            if r2.ok:
                self.monthly_used = int(r2.json().get("totalUsage", 0))
            with self.lock:
                if self.monthly_limit and self.monthly_limit > 0:
                    remain = max(self.monthly_limit - self.monthly_used, 0)
                    ratio = remain / float(self.monthly_limit)
                    if ratio <= DEGRADE_WARN_REMAIN_PCT and self.mode != Mode.HARD_STOP:
                        self.mode = Mode.SAVER
                    elif ratio > (DEGRADE_WARN_REMAIN_PCT + 0.05) and time.time() >= self.suspended_until:
                        self.mode = Mode.NORMAL
                else:
                    if time.time() >= self.suspended_until and self.mode != Mode.HARD_STOP:
                        self.mode = Mode.NORMAL
        except Exception as e:
            logging.warning(f"ç”¨é‡è¼ªè©¢å¤±æ•—ï¼š{e}")

    def _start_usage_poller(self):
        def loop():
            while True:
                self._poll_usage_once()
                time.sleep(USAGE_POLL_SECONDS)
        threading.Thread(target=loop, daemon=True).start()

guard = MessagingGuard()

# === æª”æ¡ˆ ===
DATA_DIR = os.path.join(os.getcwd(), "data")
TOILETS_FILE_PATH = os.path.join(DATA_DIR, "public_toilets.csv")
FAVORITES_FILE_PATH = os.path.join(DATA_DIR, "favorites.txt")
os.makedirs(DATA_DIR, exist_ok=True)

if not os.path.exists(FAVORITES_FILE_PATH):
    open(FAVORITES_FILE_PATH, "a", encoding="utf-8").close()

PUBLIC_HEADERS = [
    "country","city","village","number","name","address","administration",
    "latitude","longitude","grade","type2","type","exec","diaper"
]
if not os.path.exists(TOILETS_FILE_PATH):
    with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(PUBLIC_HEADERS)

# === Google Sheets è¨­å®š ===
GSHEET_SCOPE = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
GSHEET_CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON")
TOILET_SPREADSHEET_ID = "1Vg3tiqlXcXjcic2cAWCG-xTXfNzcI7wegEnZx8Ak7ys"
FEEDBACK_SPREADSHEET_ID = "15Ram7EZ9QMN6SZAVYQFNpL5gu4vTaRn4M5mpWUKmmZk"

# === åŒæ„æ›¸è¨­å®š ===
CONSENT_SHEET_TITLE = "consent"
CONSENT_PAGE_URL = os.getenv("CONSENT_PAGE_URL", "https://school-i9co.onrender.com/consent")

gc = worksheet = feedback_sheet = consent_ws = None

# === è¼‰å…¥æ¨¡å‹ ===
BASE_DIR = os.path.abspath(os.path.dirname(__file__))

def load_cleanliness_model():
    try:
        model_path = os.path.join(BASE_DIR, 'models', 'clean_model.pkl')
        model = joblib.load(model_path)
        logging.info("âœ… æ¸…æ½”åº¦æ¨¡å‹å·²è¼‰å…¥")
        return model
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def load_label_encoder():
    try:
        encoder_path = os.path.join(BASE_DIR, 'models', 'label_encoder.pkl')
        encoder = joblib.load(encoder_path)
        logging.info("âœ… LabelEncoder å·²è¼‰å…¥")
        return encoder
    except Exception as e:
        logging.error(f"âŒ LabelEncoder è¼‰å…¥å¤±æ•—: {e}")
        return None

cleanliness_model = load_cleanliness_model()
label_encoder = load_label_encoder()

# === åƒæ•¸ ===
LAST_N_HISTORY = 5

# === å·¥å…·ï¼šåº§æ¨™æ¨™æº–åŒ–ï¼è§£æ ===
def norm_coord(x, ndigits=6):
    try:
        return f"{round(float(x), ndigits):.{ndigits}f}"
    except:
        return str(x)

def _parse_lat_lon(lat_s, lon_s):
    try:
        lat = float(str(lat_s).strip())
        lon = float(str(lon_s).strip())
    except Exception:
        return None, None
    if abs(lat) > 90 and abs(lon) <= 90:
        lat, lon = lon, lat
    if not (-90 <= lat <= 90 and -180 <= lon <= 180):
        return None, None
    return lat, lon

# === æ¨“å±¤æ¨æ–· ===
def _floor_from_tags(tags: dict):
    if not tags:
        return None
    level = tags.get("level") or tags.get("level:ref") or tags.get("addr:floor")
    loc = (tags.get("location") or "").lower()
    try:
        if level is not None and str(level).strip() != "":
            lv_str = str(level).strip().replace("F","").replace("f","")
            lv = int(float(lv_str))
            if lv < 0:
                return f"åœ°ä¸‹{abs(lv)}F"
            if lv == 0:
                return "åœ°é¢"
            return f"{lv}F"
    except Exception:
        pass
    if loc == "underground":
        return "åœ°ä¸‹"
    if loc == "overground":
        return "åœ°é¢"
    return None

_ZH_DIGIT = {"é›¶":0,"ã€‡":0,"ä¸€":1,"äºŒ":2,"å…©":2,"ä¸‰":3,"å››":4,"äº”":5,"å…­":6,"ä¸ƒ":7,"å…«":8,"ä¹":9}

def _zh_to_int_word(word: str):
    if not word:
        return None
    w = word.replace("ä¸¤","å…©")
    if "å" not in w:
        return _ZH_DIGIT.get(w)
    left, _, right = w.partition("å")
    tens = 10 if left == "" else (_ZH_DIGIT.get(left, 0) * 10)
    ones = 0 if right == "" else _ZH_DIGIT.get(right, 0)
    val = tens + ones
    return val if val > 0 else None

def _normalize_floor_label(n: int, underground: bool=False):
    try:
        n = int(n)
    except Exception:
        return None
    if underground:
        return f"åœ°ä¸‹{abs(n)}F"
    if n == 0:
        return "åœ°é¢"
    return f"{n}F"

def _floor_from_name(name: str):
    if not name:
        return None
    s = str(name).strip()
    s_lower = s.lower()

    if re.search(r'(?:^|[^a-z])g\s*/?\s*f(?:[^a-z]|$)', s_lower) or re.search(r'ground\s*floor', s_lower):
        return "åœ°é¢"

    m = re.search(r'(?:^|[^a-z])[bï¼¢]\s*-?\s*(\d{1,2})\s*(?:f|æ¨“|å±¤)?(?:[^0-9]|$)', s_lower)
    if m:
        n = int(m.group(1))
        if n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'åœ°ä¸‹\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶\d]{1,3})\s*(?:æ¨“|å±¤|f)?', s_lower)
    if m:
        token = m.group(1)
        n = int(token) if token.isdigit() else _zh_to_int_word(token)
        if n and n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'(\d{1,3})\s*(?:f|æ¨“|å±¤)(?:[^a-z0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    m = re.search(r'ç¬¬?\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶]{1,3})\s*(?:æ¨“|å±¤)', s_lower)
    if m:
        n = _zh_to_int_word(m.group(1))
        if n:
            return _normalize_floor_label(n)

    m = re.search(r'(?:^|[^a-z])l\s*(\d{1,3})(?:[^0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    return None

# === ä¾é™„è¿‘å ´é¤¨å‘½å ===
_ENRICH_CACHE = {}
_ENRICH_TTL = 120

def enrich_nearby_places(lat, lon, radius=500):
    key = f"{round(lat,4)},{round(lon,4)}:{radius}"
    now = time.time()
    cached = _ENRICH_CACHE.get(key)
    if cached and (now - cached[0] < _ENRICH_TTL):
        return cached[1]

    q = f"""
    [out:json][timeout:25];
    (
      node(around:{radius},{lat},{lon})["name"]["building"];
      way(around:{radius},{lat},{lon})["name"]["building"];
      node(around:{radius},{lat},{lon})["name"]["shop"];
      way(around:{radius},{lat},{lon})["name"]["shop"];
      node(around:{radius},{lat},{lon})["name"]["amenity"];
      way(around:{radius},{lat},{lon})["name"]["amenity"];
    );
    out center tags;
    """
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]
    headers = {"User-Agent": f"ToiletBot/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}

    for url in endpoints:
        try:
            resp = requests.post(url, data=q, headers=headers, timeout=30)
            if resp.status_code == 200 and "json" in (resp.headers.get("Content-Type","").lower()):
                els = resp.json().get("elements", [])
                out = []
                for e in els:
                    if e["type"] == "node":
                        clat, clon = e.get("lat"), e.get("lon")
                    else:
                        c = e.get("center") or {}
                        clat, clon = c.get("lat"), c.get("lon")
                    if clat is None or clon is None:
                        continue
                    t = e.get("tags", {}) or {}
                    nm = t.get("name")
                    if nm:
                        out.append({"name": nm, "lat": float(clat), "lon": float(clon)})
                _ENRICH_CACHE[key] = (now, out)
                return out
        except Exception:
            continue
    _ENRICH_CACHE[key] = (now, [])
    return []

# === å¯æ‰¾æ€§åˆ†æ•¸ + æ’åº ===
def _findability_bonus(t):
    b = 0.0
    if t.get("place_hint"): b += 0.5
    if t.get("floor_hint"): b += 0.3
    return b

def sort_toilets(toilets):
    toilets.sort(key=lambda x: (int(x.get("distance", 1e9)), -_findability_bonus(x)))
    return toilets

# === åˆå§‹åŒ– Google Sheetsï¼ˆåŒ… SafeWSï¼›å…¶é¤˜ä¸è®Šï¼‰ ===
def init_gsheet():
    global gc, worksheet, feedback_sheet, consent_ws
    try:
        if not GSHEET_CREDENTIALS_JSON:
            raise RuntimeError("ç¼ºå°‘ GSHEET_CREDENTIALS_JSON")
        creds_dict = json.loads(GSHEET_CREDENTIALS_JSON)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, GSHEET_SCOPE)
        gc = gspread.authorize(creds)

        worksheet_raw = gc.open_by_key(TOILET_SPREADSHEET_ID).sheet1
        fb_spread = gc.open_by_key(FEEDBACK_SPREADSHEET_ID)
        feedback_raw = fb_spread.sheet1

        try:
            consent_raw = fb_spread.worksheet(CONSENT_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            consent_raw = fb_spread.add_worksheet(title=CONSENT_SHEET_TITLE, rows=1000, cols=10)
            consent_raw.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])

        # åŒ…è£æˆ SafeWSï¼Œåº•ä¸‹æ‰€æœ‰å‘¼å«ç¶­æŒåŸ API
        worksheet = SafeWS(worksheet_raw, TOILET_SPREADSHEET_ID, worksheet_raw.title)
        feedback_sheet = SafeWS(feedback_raw, FEEDBACK_SPREADSHEET_ID, feedback_raw.title)
        consent_ws = SafeWS(consent_raw, FEEDBACK_SPREADSHEET_ID, consent_raw.title)

        logging.info("âœ… Sheets åˆå§‹åŒ–å®Œæˆï¼ˆå« consentï¼›å•Ÿç”¨ SafeWS å¿«å–/é‡è©¦/ä½µç™¼æ§ç®¡ï¼‰")
    except Exception as e:
        logging.critical(f"âŒ Sheets åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

init_gsheet()

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
TOILET_REQUIRED_HEADER = [
    "user_id", "name", "address", "lat", "lon",
    "level", "floor_hint", "entrance_hint", "access_note", "open_hours",
    "timestamp"
]

def ensure_toilet_sheet_header(ws):
    try:
        header = ws.row_values(1) or []
        if not header:
            ws.update("A1", [TOILET_REQUIRED_HEADER])
            return TOILET_REQUIRED_HEADER[:]

        changed = False
        for col in TOILET_REQUIRED_HEADER:
            if col not in header:
                header.append(col)
                changed = True
        if changed:
            ws.update("A1", [header])
        return header
    except Exception as e:
        logging.error(f"ensure_toilet_sheet_header å¤±æ•—ï¼š{e}")
        return header if 'header' in locals() and header else TOILET_REQUIRED_HEADER[:]

# === è¨ˆç®—è·é›¢ ===
def haversine(lat1, lon1, lat2, lon2):
    try:
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
        return 2 * asin(sqrt(a)) * 6371000  # m
    except Exception as e:
        logging.error(f"è¨ˆç®—è·é›¢å¤±æ•—: {e}")
        return 0

# === é˜²é‡è¤‡ ===
DEDUPE_WINDOW = int(os.getenv("DEDUPE_WINDOW", "10"))
_RECENT_EVENTS = {}

def is_duplicate_and_mark(key: str, window: int = DEDUPE_WINDOW) -> bool:
    now = time.time()
    ts = _RECENT_EVENTS.get(key)
    if ts is not None and (now - ts) < window:
        logging.info(f"ğŸ” skip duplicate: {key}")
        return True
    _RECENT_EVENTS[key] = now
    if len(_RECENT_EVENTS) > 5000 or (len(_RECENT_EVENTS) > 1000):
        for k, tstamp in list(_RECENT_EVENTS.items()):
            if now - tstamp > window:
                _RECENT_EVENTS.pop(k, None)
    return False

def is_redelivery(event) -> bool:
    try:
        dc = getattr(event, "delivery_context", None)
        return bool(getattr(dc, "is_redelivery", False))
    except Exception:
        return False

def safe_reply(event, messages):
    try:
        line_bot_api.reply_message(event.reply_token, messages)
    except LineBotApiError as e:
        msg_txt = ""
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)
        if is_redelivery(event) or ("Invalid reply token" in msg_txt):
            logging.warning(f"reply_message å¤±æ•—ä½†ä¸ pushï¼ˆé¿å…é‡è¤‡ï¼‰ï¼š{msg_txt}")
            return
        logging.warning(f"reply_message å¤±æ•—ï¼Œæ”¹ç”¨ pushï¼š{msg_txt}")
        try:
            uid = getattr(event.source, "user_id", None)
            if uid:
                guard.push(uid, messages)
        except Exception as ex:
            logging.error(f"push_message ä¹Ÿå¤±æ•—ï¼š{ex}")

# === åŒæ„å·¥å…· ===
def _booly(v):
    s = str(v).strip().lower()
    return s in ["1", "true", "yes", "y", "åŒæ„"]

# ï¼ˆå¯é¸å¾®å„ªåŒ–ï¼‰æœ¬æ©ŸåŒæ„å¿«å–ï¼ŒTTL é è¨­ 10 åˆ†é˜ï¼›å¤±æ•—æ™‚ç•¶æœªåŒæ„ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰
_consent_cache = {}   # user_id -> (ts, bool)
_CONSENT_TTL = int(os.getenv("CONSENT_TTL_SEC", "600"))

def has_consented(user_id: str) -> bool:
    try:
        if not user_id or consent_ws is None:
            return False
        now = time.time()
        hit = _consent_cache.get(user_id)
        if hit and (now - hit[0] < _CONSENT_TTL):
            return hit[1]

        rows = consent_ws.get_all_values()
        if not rows or len(rows) < 2:
            _consent_cache[user_id] = (now, False)
            return False
        header = rows[0]; data = rows[1:]
        try:
            i_uid = header.index("user_id")
            i_ag  = header.index("agreed")
        except ValueError:
            _consent_cache[user_id] = (now, False)
            return False
        ok = False
        for r in data:
            if len(r) <= max(i_uid, i_ag):
                continue
            if (r[i_uid] or "").strip() == user_id and _booly(r[i_ag]):
                ok = True
                break
        _consent_cache[user_id] = (now, ok)
        return ok
    except Exception as e:
        logging.warning(f"æŸ¥è©¢åŒæ„å¤±æ•—: {e}")
        return False

def upsert_consent(user_id: str, agreed: bool, display_name: str, source_type: str, ua: str, ts_iso: str):
    try:
        rows = consent_ws.get_all_values()
        if not rows:
            consent_ws.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])
            rows = [["user_id","agreed","display_name","source_type","ua","timestamp"]]
        header = rows[0]; data = rows[1:]

        idx = {h:i for i,h in enumerate(header)}
        for k in ["user_id","agreed","display_name","source_type","ua","timestamp"]:
            if k not in idx:
                header.append(k); idx[k] = len(header)-1
        if len(header) != len(rows[0]):
            consent_ws.update("A1", [header])

        row_to_update = None
        for i, r in enumerate(data, start=2):
            if len(r) > idx["user_id"] and (r[idx["user_id"]] or "").strip() == user_id:
                row_to_update = i
                break

        row_values = [""] * len(header)
        row_values[idx["user_id"]] = user_id or ""
        row_values[idx["agreed"]] = "true" if agreed else "false"
        row_values[idx["display_name"]] = display_name or ""
        row_values[idx["source_type"]] = source_type or ""
        row_values[idx["ua"]] = ua or ""
        row_values[idx["timestamp"]] = ts_iso or datetime.utcnow().isoformat()

        if row_to_update:
            consent_ws.update(f"A{row_to_update}", [row_values])
        else:
            consent_ws.append_row(row_values, value_input_option="USER_ENTERED")
        # æ›´æ–°æœ¬æ©Ÿå¿«å–
        _consent_cache[user_id] = (time.time(), bool(agreed))
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥/æ›´æ–°åŒæ„å¤±æ•—: {e}")
        return False

def ensure_consent_or_prompt(user_id: str):
    if has_consented(user_id):
        return None
    tip = (
        "ğŸ›¡ï¸ ä½¿ç”¨å‰è«‹å…ˆå®ŒæˆåŒæ„ï¼š\n"
        f"{CONSENT_PAGE_URL}\n\n"
        "è‹¥ä¸åŒæ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡ç„¡æ³•æä¾›ã€‚"
    )
    return TextSendMessage(text=tip)

# === å¾ Google Sheets æŸ¥ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
def query_sheet_toilets(user_lat, user_lon, radius=500):
    toilets = []
    try:
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) < 5:
                continue
            name = (row[1] if len(row) > 1 else "").strip() or "ç„¡åç¨±"
            address = (row[2] if len(row) > 2 else "").strip()
            try:
                t_lat = float(row[3]); t_lon = float(row[4])
            except:
                continue
            dist = haversine(user_lat, user_lon, t_lat, t_lon)
            if dist <= radius:
                floor_hint = _floor_from_name(name)
                toilets.append({
                    "name": name,
                    "lat": float(norm_coord(t_lat)),
                    "lon": float(norm_coord(t_lon)),
                    "address": address,
                    "distance": dist,
                    "type": "sheet",
                    "floor_hint": floor_hint
                })
    except Exception as e:
        logging.error(f"è®€å– Google Sheets å»æ‰€ä¸»è³‡æ–™éŒ¯èª¤: {e}")
    return sorted(toilets, key=lambda x: x["distance"])

# === OSM Overpass ===
def query_overpass_toilets(lat, lon, radius=500):
    overall_deadline = time.time() + 8.0  # æœ€å¤š 8 ç§’
    def _left():
        return max(1.0, overall_deadline - time.time())

    ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
    headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]

    for r in (300, radius):
        if time.time() >= overall_deadline:
            break

        query = f"""
        [out:json][timeout:25];
        (
          node["amenity"="toilets"](around:{r},{lat},{lon});
          way["amenity"="toilets"](around:{r},{lat},{lon});
          relation["amenity"="toilets"](around:{r},{lat},{lon});
        );
        out center tags;
        """

        last_err = None
        for idx, url in enumerate(endpoints):
            if time.time() >= overall_deadline:
                break
            try:
                resp = requests.post(url, data=query, headers=headers, timeout=min(8, _left()))
                ctype = (resp.headers.get("Content-Type") or "").lower()
                if resp.status_code != 200 or "json" not in ctype:
                    last_err = RuntimeError(f"overpass non-json {resp.status_code}")
                    continue

                data = resp.json()
                elements = data.get("elements", [])
                toilets = []
                for elem in elements:
                    if "center" in elem:
                        t_lat, t_lon = elem["center"]["lat"], elem["center"]["lon"]
                    elif elem.get("type") == "node":
                        t_lat, t_lon = elem["lat"], elem["lon"]
                    else:
                        continue

                    tags = elem.get("tags", {}) or {}
                    name = tags.get("name", "ç„¡åç¨±")
                    address = tags.get("addr:full", "") or tags.get("addr:street", "") or ""
                    floor_hint = _floor_from_tags(tags) or _floor_from_name(name)

                    toilets.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": address,
                        "distance": haversine(lat, lon, t_lat, t_lon),
                        "type": "osm",
                        "floor_hint": floor_hint
                    })

                # åªæœ‰åœ¨æ‹¿åˆ°è³‡æ–™æ™‚æ‰åš enrichï¼ˆé¿å…å¤šé¤˜è«‹æ±‚ï¼‰
                try:
                    nearby_named = enrich_nearby_places(lat, lon, radius=500)
                    if nearby_named:
                        for t in toilets:
                            if (not t.get("name")) or t["name"] == "ç„¡åç¨±":
                                best = None; best_d = 61
                                for p in nearby_named:
                                    d = haversine(t["lat"], t["lon"], p["lat"], p["lon"])
                                    if d < best_d:
                                        best_d = d; best = p
                                if best:
                                    t["place_hint"] = best["name"]
                except Exception:
                    pass

                return sorted(toilets, key=lambda x: x["distance"])
            except Exception as e:
                last_err = e
                logging.warning(f"Overpass API æŸ¥è©¢å¤±æ•—ï¼ˆendpoint {idx}ï¼‰: {e}")
        logging.warning(f"Overpass åŠå¾‘ {r} å¤±æ•—ï¼š{last_err}")
    return []

# === è®€å– public_toilets.csv ===
def query_public_csv_toilets(user_lat, user_lon, radius=500):
    pts = []
    if not os.path.exists(TOILETS_FILE_PATH):
        return pts
    try:
        with open(TOILETS_FILE_PATH, "r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    t_lat = float(row.get("latitude"))
                    t_lon = float(row.get("longitude"))
                except Exception:
                    continue
                dist = haversine(user_lat, user_lon, t_lat, t_lon)
                if dist <= radius:
                    name = (row.get("name") or "ç„¡åç¨±").strip()
                    addr = (row.get("address") or "").strip()
                    floor_hint = _floor_from_name(name)
                    pts.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": addr,
                        "distance": dist,
                        "type": "public_csv",
                        "grade": row.get("grade", ""),
                        "category": row.get("type2", ""),
                        "floor_hint": floor_hint
                    })
    except Exception as e:
        logging.error(f"è®€ public_toilets.csv å¤±æ•—ï¼š{e}")
    return sorted(pts, key=lambda x: x["distance"])

# === åˆä½µ + å»é‡ ===
def _merge_and_dedupe_lists(*lists, dist_th=35, name_sim_th=0.55):
    all_pts = []
    for l in lists:
        if l: all_pts.extend(l)
    all_pts.sort(key=lambda x: x["distance"])

    merged = []
    for p in all_pts:
        dup = False
        for q in merged:
            try:
                near = haversine(p["lat"], p["lon"], q["lat"], q["lon"]) <= dist_th
            except Exception:
                near = False
            sim = SequenceMatcher(None, (p.get("name") or "").lower(), (q.get("name") or "").lower()).ratio()
            if near and sim >= name_sim_th:
                dup = True
                break
        if not dup:
            merged.append(p)
    return merged

# === æœ€æ„›ç®¡ç† ===
def add_to_favorites(uid, toilet):
    try:
        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        with open(FAVORITES_FILE_PATH, "a", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([uid, toilet['name'], lat_s, lon_s, toilet.get('address','')])
    except Exception as e:
        logging.error(f"åŠ å…¥æœ€æ„›å¤±æ•—: {e}")

def remove_from_favorites(uid, name, lat, lon):
    try:
        lat_s = norm_coord(lat)
        lon_s = norm_coord(lon)
        rows = []
        changed = False
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    rows.append(row); continue
                if not (row[0] == uid and row[1] == name and row[2] == lat_s and row[3] == lon_s):
                    rows.append(row)
                else:
                    changed = True
        with open(FAVORITES_FILE_PATH, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerows(rows)
        return changed
    except Exception as e:
        logging.error(f"ç§»é™¤æœ€æ„›å¤±æ•—: {e}")
        return False

def get_user_favorites(uid):
    favs = []
    try:
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    continue
                if row[0] == uid:
                    favs.append({
                        "name": row[1],
                        "lat": float(row[2]),
                        "lon": float(row[3]),
                        "address": row[4],
                        "distance": 0,
                        "type": "favorite"
                    })
    except Exception as e:
        logging.error(f"è®€å–æœ€æ„›å¤±æ•—: {e}")
    return favs

# === åœ°å€è½‰ç¶“ç·¯åº¦ ===
def geocode_address(address):
    try:
        ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
        url = f"https://nominatim.openstreetmap.org/search?format=json&q={quote(address)}"
        headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
        resp = requests.get(url, headers=headers, timeout=10)
        data = resp.json()
        if resp.status_code == 200 and data:
            return float(data[0]['lat']), float(data[0]['lon'])
    except Exception as e:
        logging.error(f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: {e}")
    return None, None

# === é™„è¿‘å»æ‰€ API ===
@app.route("/nearby_toilets", methods=["GET"])
def nearby_toilets():
    user_lat = request.args.get('lat')
    user_lon = request.args.get('lon')
    if not user_lat or not user_lon:
        return {"error": "ç¼ºå°‘ä½ç½®åƒæ•¸"}, 400

    user_lat = float(user_lat)
    user_lon = float(user_lon)

    public_csv_toilets = query_public_csv_toilets(user_lat, user_lon, radius=500) or []
    sheet_toilets = query_sheet_toilets(user_lat, user_lon, radius=500) or []
    osm_toilets = query_overpass_toilets(user_lat, user_lon, radius=500) or []

    all_toilets = _merge_and_dedupe_lists(public_csv_toilets, sheet_toilets, osm_toilets)
    sort_toilets(all_toilets)

    if not all_toilets:
        return {"message": "é™„è¿‘æ‰¾ä¸åˆ°å»æ‰€"}, 404
    return {"toilets": all_toilets}, 200

# === é¡¯ç¤ºå›é¥‹è¡¨å–® ===
@app.route("/feedback_form/<toilet_name>/", defaults={'address': ''})
@app.route("/feedback_form/<toilet_name>/<path:address>")
def feedback_form(toilet_name, address):
    address = address or request.args.get("address", "")
    return render_template(
        "feedback_form.html",
        toilet_name=toilet_name,
        address=address,
        lat=request.args.get("lat", ""),
        lon=request.args.get("lon", "")
    )

# === å°é½Š ===
def _norm_h(s):
    return (s or "").strip().lower()

def _find_idx(header, candidates):
    hmap = {_norm_h(h): i for i, h in enumerate(header)}
    for c in candidates:
        if _norm_h(c) in hmap:
            return hmap[_norm_h(c)]
    return None

def _feedback_indices(header):
    return {
        "name": _find_idx(header, ["åç¨±", "name", "toilet_name"]),
        "address": _find_idx(header, ["åœ°å€", "address"]),
        "rating": _find_idx(header, ["æ¸…æ½”åº¦è©•åˆ†", "æ¸…æ½”è©•åˆ†", "rating", "score"]),
        "paper": _find_idx(header, ["æ˜¯å¦æœ‰è¡›ç”Ÿç´™", "toilet_paper", "è¡›ç”Ÿç´™", "ç´™"]),
        "access": _find_idx(header, ["æ˜¯å¦æœ‰ç„¡éšœç¤™è¨­æ–½", "accessibility", "ç„¡éšœç¤™"]),
        "time": _find_idx(header, ["ä½¿ç”¨æ™‚é–“", "time_of_use", "time"]),
        "comment": _find_idx(header, ["ç•™è¨€", "comment", "å‚™è¨»"]),
        "pred": _find_idx(header, ["é æ¸¬åˆ†æ•¸", "é æ¸¬è©•åˆ†", "cleanliness_score", "predicted_score"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["created_at", "å»ºç«‹æ™‚é–“", "æ™‚é–“", "timestamp"]),
        "floor": _find_idx(header, ["floor", "æ¨“å±¤", "floor_hint", "level", "ä½ç½®æ¨“å±¤"]),
    }

def _toilet_sheet_indices(header):
    return {
        "user_id": _find_idx(header, ["user_id", "uid", "ä½¿ç”¨è€…"]),
        "name": _find_idx(header, ["name", "åç¨±"]),
        "address": _find_idx(header, ["address", "åœ°å€"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["timestamp", "created_at", "å»ºç«‹æ™‚é–“"]),
    }

# === æ¸…æ½”åº¦é æ¸¬ ===
def expected_from_feats(feats):
    try:
        if not feats or cleanliness_model is None:
            return None
        if pd is not None:
            df = pd.DataFrame(feats, columns=["rating","toilet_paper","accessibility"])
            probs = cleanliness_model.predict_proba(df)
        else:
            probs = cleanliness_model.predict_proba(feats)

        try:
            classes_enc = cleanliness_model.classes_
            labels = label_encoder.inverse_transform(classes_enc)
            labels = [float(x) for x in labels]
        except Exception:
            labels = [float(c) + 1.0 for c in cleanliness_model.classes_]

        exps = [sum(float(p)*float(l) for p, l in zip(p_row, labels)) for p_row in probs]
        return round(sum(exps)/len(exps), 2) if exps else None
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦é æ¸¬éŒ¯èª¤: {e}")
        return None

def _simple_score(rr, paper, acc):
    try:
        base = 1.0 + 4.0 * (int(rr) - 1) / 9.0
    except Exception:
        return None
    bonus = (0.25 if (paper == "æœ‰") else 0.0) + (0.25 if (acc == "æœ‰") else 0.0)
    score = base + bonus
    if score < 1.0: score = 1.0
    if score > 5.0: score = 5.0
    return round(score, 2)

def _pred_from_row(r, idx):
    paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
    access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}

    rr = None
    if idx["rating"] is not None and len(r) > idx["rating"]:
        try:
            rr = int((r[idx["rating"]] or "").strip())
        except:
            rr = None
    pp = (r[idx["paper"]] or "").strip() if idx["paper"] is not None and len(r) > idx["paper"] else "æ²’æ³¨æ„"
    aa = (r[idx["access"]] or "").strip() if idx["access"] is not None and len(r) > idx["access"] else "æ²’æ³¨æ„"

    score = None
    if rr is not None and cleanliness_model is not None:
        try:
            feat = [rr, paper_map.get(pp, 0), access_map.get(aa, 0)]
            score = expected_from_feats([feat])
        except Exception:
            score = None
    if score is None and idx["pred"] is not None and len(r) > idx["pred"]:
        try:
            score = float((r[idx["pred"]] or "").strip())
        except:
            score = None
    if score is None:
        score = _simple_score(rr, pp, aa)
    return (score, rr, pp, aa)

# === å³æ™‚é æ¸¬ / 95% CI ===
def compute_nowcast_ci(lat, lon, k=LAST_N_HISTORY, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return None

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return None

        def close(a, b):
            try:
                return abs(float(a) - float(b)) <= tol
            except:
                return False

        same = [r for r in data
                if len(r) > max(idx["lat"], idx["lon"])
                and close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon)]
        if not same:
            return None

        if idx["created"] is not None:
            same.sort(key=lambda x: x[idx["created"]], reverse=True)
        recent = same[:k]

        vals = []
        for r in recent:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                vals.append(float(sc))
        if not vals:
            return None

        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            vals = []
            for r in recent:
                sc, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    vals.append(sc2)
            if not vals:
                return None

        mean = round(sum(vals) / len(vals), 2)
        if len(vals) == 1:
            return {"mean": mean, "lower": mean, "upper": mean, "n": 1}

        try:
            s = statistics.stdev(vals)
        except statistics.StatisticsError:
            s = 0.0
        se = s / (len(vals) ** 0.5)
        lower = max(1.0, round(mean - 1.96 * se, 2))
        upper = min(5.0, round(mean + 1.96 * se, 2))
        return {"mean": mean, "lower": lower, "upper": upper, "n": len(vals)}
    except Exception as e:
        logging.error(f"âŒ compute_nowcast_ci å¤±æ•—: {e}")
        return None

# === Nowcast API ===
@app.route("/get_nowcast_by_coord/<lat>/<lon>")
def get_nowcast_by_coord(lat, lon):
    try:
        res = compute_nowcast_ci(lat, lon)
        if not res:
            return {"success": True, "n": 0}, 200
        res["success"] = True
        return res, 200
    except Exception as e:
        logging.error(f"âŒ Nowcast API éŒ¯èª¤: {e}")
        return {"success": False}, 500

# === å›é¥‹ ===
@app.route("/submit_feedback", methods=["POST"])
def submit_feedback():
    try:
        data = request.form
        name = (data.get("name","") or "").strip()
        address = (data.get("address","") or "").strip()

        lat_raw = data.get("lat","")
        lon_raw = data.get("lon","")
        lat_f, lon_f = _parse_lat_lon(lat_raw, lon_raw)
        if lat_f is None or lon_f is None:
            return "åº§æ¨™æ ¼å¼éŒ¯èª¤", 400
        lat = norm_coord(lat_f)
        lon = norm_coord(lon_f)

        rating = (data.get("rating","") or "").strip()
        toilet_paper = (data.get("toilet_paper","") or "").strip()
        accessibility = (data.get("accessibility","") or "").strip()
        time_of_use = (data.get("time_of_use","") or "").strip()
        comment = (data.get("comment","") or "").strip()
        floor_hint = (data.get("floor_hint","") or "").strip()

        if not all([name, rating, lat, lon]):
            return "ç¼ºå°‘å¿…è¦æ¬„ä½ï¼ˆéœ€è¦ï¼šnameã€ratingã€latã€lonï¼‰", 400

        try:
            r = int(rating)
            if r < 1 or r > 10:
                return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆåœ¨ 1 åˆ° 10 ä¹‹é–“", 400
        except ValueError:
            return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆæ˜¯æ•¸å­—", 400

        if floor_hint and len(floor_hint) < 4:
            return "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—", 400

        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        cur_feat = [r, paper_map.get(toilet_paper, 0), access_map.get(accessibility, 0)]

        hist_feats = []
        try:
            rows = feedback_sheet.get_all_values()
            header = rows[0]; data_rows = rows[1:]
            idx = _feedback_indices(header)

            def close(a, b, tol=1e-6):
                try: return abs(float(a) - float(b)) <= tol
                except: return False

            same_coord = []
            for row in data_rows:
                if idx["lat"] is None or idx["lon"] is None:
                    break
                if len(row) <= max(idx["lat"], idx["lon"]):
                    continue
                if close(row[idx["lat"]], lat) and close(row[idx["lon"]], lon):
                    same_coord.append(row)

            if idx["created"] is not None:
                same_coord.sort(key=lambda x: x[idx["created"]], reverse=True)
            recent = same_coord[:LAST_N_HISTORY]

            if idx["rating"] is not None:
                for row in recent:
                    try:
                        rr = int((row[idx["rating"]] or "").strip())
                    except:
                        continue
                    pp = (row[idx["paper"]] or "").strip() if idx["paper"] is not None else "æ²’æ³¨æ„"
                    aa = (row[idx["access"]] or "").strip() if idx["access"] is not None else "æ²’æ³¨æ„"
                    hist_feats.append([rr, paper_map.get(pp,0), access_map.get(aa,0)])
        except Exception as e:
            logging.warning(f"è®€æ­·å²å›é¥‹å¤±æ•—ï¼Œåƒ…ç”¨å–®ç­†ç‰¹å¾µé æ¸¬ï¼š{e}")

        pred_with_hist = expected_from_feats([cur_feat] + hist_feats) or expected_from_feats([cur_feat]) or "æœªé æ¸¬"

        feedback_sheet.append_row([
            name, address, rating, toilet_paper, accessibility, time_of_use,
            comment, pred_with_hist, lat, lon, datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            floor_hint
        ])

        return redirect(url_for("feedback_form", toilet_name=name, address=address or "") + f"?lat={lat}&lon={lon}")
    except Exception as e:
        logging.error(f"âŒ æäº¤å›é¥‹è¡¨å–®éŒ¯èª¤: {e}")
        return "æäº¤å¤±æ•—", 500

# === è®€åº§æ¨™çš„å›é¥‹æ¸…å–® ===
def get_feedbacks_by_coord(lat, lon, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return []
        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        out = []
        for r in data:
            if idx["lat"] is None or idx["lon"] is None:
                break
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                def val(key):
                    i = idx[key]
                    return (r[i] if i is not None and len(r) > i else "").strip()
                out.append({
                    "rating": val("rating"),
                    "toilet_paper": val("paper"),
                    "accessibility": val("access"),
                    "time_of_use": val("time"),
                    "comment": val("comment"),
                    "cleanliness_score": val("pred"),
                    "created_at": val("created"),
                })
        out.sort(key=lambda d: d.get("created_at", ""), reverse=True)
        return out
    except Exception as e:
        logging.error(f"âŒ è®€å–å›é¥‹åˆ—è¡¨ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return []

# === åº§æ¨™èšåˆçµ±è¨ˆ ===
def get_feedback_summary_by_coord(lat, lon, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return "ï¼ˆè¡¨é ­ç¼ºå°‘ lat/lon æ¬„ä½ï¼‰"

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched.append(r)

        if not matched:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        scores = []
        comments = []

        for r in matched:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                scores.append(float(sc))
            if pp in paper_counts: paper_counts[pp] += 1
            if aa in access_counts: access_counts[aa] += 1
            if idx["comment"] is not None and len(r) > idx["comment"]:
                c = (r[idx["comment"]] or "").strip()
                if c:
                    comments.append(c)

        avg_score = round(sum(scores) / len(scores), 2) if scores else "æœªé æ¸¬"

        summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\n"
        summary += f"ğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg_score}\n"
        summary += f"ğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰'] >= paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        summary += f"â™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰'] >= access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        if comments:
            summary += f"ğŸ’¬ æœ€æ–°ç•™è¨€ï¼š{comments[-1]}"
        return summary
    except Exception as e:
        logging.error(f"âŒ æŸ¥è©¢å›é¥‹çµ±è¨ˆï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "è®€å–éŒ¯èª¤"

# === æŒ‡ç¤ºç‡ˆç´¢å¼• ===
_feedback_index_cache = {"ts": 0, "data": {}}
_FEEDBACK_INDEX_TTL = 30

def build_feedback_index():
    global _feedback_index_cache
    now = time.time()
    if now - _feedback_index_cache["ts"] < _FEEDBACK_INDEX_TTL and _feedback_index_cache["data"]:
        return _feedback_index_cache["data"]

    result = {}
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            _feedback_index_cache = {"ts": now, "data": {}}
            return result
        header = rows[0]; data = rows[1:]
        idx = _feedback_indices(header)

        bucket = {}
        for r in data:
            try:
                if idx["lat"] is None or idx["lon"] is None:
                    continue
                lat_s = norm_coord(r[idx["lat"]])
                lon_s = norm_coord(r[idx["lon"]])
            except Exception:
                continue
            rec = bucket.setdefault((lat_s, lon_s), {"paper": {"æœ‰":0,"æ²’æœ‰":0}, "access":{"æœ‰":0,"æ²’æœ‰":0}, "scores":[]})
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if pp in rec["paper"]: rec["paper"][pp] += 1
            if aa in rec["access"]: rec["access"][aa] += 1
            if isinstance(sc, (int, float)): rec["scores"].append(float(sc))

        out = {}
        for key, v in bucket.items():
            paper = "æœ‰" if v["paper"]["æœ‰"] >= v["paper"]["æ²’æœ‰"] and sum(v["paper"].values())>0 else ("æ²’æœ‰" if sum(v["paper"].values())>0 else "?")
            access = "æœ‰" if v["access"]["æœ‰"] >= v["access"]["æ²’æœ‰"] and sum(v["access"].values())>0 else ("æ²’æœ‰" if sum(v["access"].values())>0 else "?")
            avg = round(sum(v["scores"])/len(v["scores"]),2) if v["scores"] else None
            out[key] = {"paper": paper, "access": access, "avg": avg}

        _feedback_index_cache = {"ts": now, "data": out}
        return out
    except Exception as e:
        logging.warning(f"å»ºç«‹æŒ‡ç¤ºç‡ˆç´¢å¼•å¤±æ•—ï¼š{e}")
        return {}

# === èˆŠè·¯ç”±ä¿ç•™===
@app.route("/toilet_feedback/<toilet_name>")
def toilet_feedback(toilet_name):
    try:
        address = "æœªçŸ¥åœ°å€"
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) > 1 and row[1] == toilet_name:
                address = (row[2] if len(row) > 2 else "") or "æœªçŸ¥åœ°å€"
                break

        if address == "æœªçŸ¥åœ°å€":
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="è«‹æ”¹ç”¨åº§æ¨™ç‰ˆå…¥å£ï¼ˆå¡ç‰‡ä¸Šçš„ã€æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰ã€ï¼‰ã€‚",
                                   feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="")

        rows_fb = feedback_sheet.get_all_values()
        header = rows_fb[0]; data_fb = rows_fb[1:]
        idx = _feedback_indices(header)
        if idx["address"] is None:
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="ï¼ˆè¡¨é ­ç¼ºå°‘ã€åœ°å€ã€æ¬„ä½ï¼‰", feedbacks=[], address=address,
                                   avg_pred_score="æœªé æ¸¬", lat="", lon="")

        matched = [r for r in data_fb
                   if len(r) > idx["address"] and (r[idx["address"]] or "").strip() == address.strip()]

        fbs = []
        nums = []
        for r in matched:
            def val(k):
                i = idx[k]
                return (r[i] if i is not None and len(r) > i else "").strip()
            sc, rr, pp, aa = _pred_from_row(r, idx)
            try: nums.append(float(sc))
            except: pass
            fbs.append({
                "rating": val("rating"),
                "toilet_paper": val("paper"),
                "accessibility": val("access"),
                "time_of_use": val("time"),
                "comment": val("comment"),
                "cleanliness_score": str(sc) if sc is not None else "",
                "created_at": val("created"),
            })
        fbs.sort(key=lambda d: d.get("created_at",""), reverse=True)
        avg_pred_score = round(sum(nums)/len(nums), 2) if nums else "æœªé æ¸¬"

        if matched:
            paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            for r in matched:
                _, _, pp, aa = _pred_from_row(r, idx)
                if pp in paper_counts: paper_counts[pp] += 1
                if aa in access_counts: access_counts[aa] += 1
            avg = avg_pred_score
            summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\nğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg}\nğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰']>=paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\nâ™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰']>=access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        else:
            summary = "å°šç„¡å›é¥‹è³‡æ–™"

        return render_template("toilet_feedback.html",
                               toilet_name=toilet_name, summary=summary,
                               feedbacks=fbs, address=address,
                               avg_pred_score=avg_pred_score, lat="", lon="")
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ–°è·¯ç”± ===
@app.route("/toilet_feedback_by_coord/<lat>/<lon>")
def toilet_feedback_by_coord(lat, lon):
    try:
        name = f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰"
        summary = get_feedback_summary_by_coord(lat, lon)
        feedbacks = get_feedbacks_by_coord(lat, lon)

        rows = feedback_sheet.get_all_values()
        header = rows[0]; data = rows[1:]
        idx = _feedback_indices(header)

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        scores = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                sc, _, _, _ = _pred_from_row(r, idx)
                if isinstance(sc, (int, float)):
                    scores.append(float(sc))
        avg_pred_score = round(sum(scores)/len(scores), 2) if scores else "æœªé æ¸¬"

        return render_template(
            "toilet_feedback.html",
            toilet_name=name,
            summary=summary,
            feedbacks=feedbacks,
            address=f"{lat},{lon}",
            avg_pred_score=avg_pred_score,
            lat=lat,
            lon=lon
        )
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ¸…æ½”åº¦è¶¨å‹¢ API ===
@app.route("/get_clean_trend_by_coord/<lat>/<lon>")
def get_clean_trend_by_coord(lat, lon):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return {"success": True, "data": []}, 200

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return {"success": False, "data": []}, 200

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched_rows = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched_rows.append(r)

        if not matched_rows:
            return {"success": True, "data": []}, 200

        recomputed = []
        for r in matched_rows:
            created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if sc is None:
                sc = _simple_score(rr, pp, aa)
            if isinstance(sc, (int, float)):
                recomputed.append((created, float(sc)))

        if not recomputed:
            return {"success": True, "data": []}, 200

        vals = [p for _, p in recomputed]
        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            forced = []
            for r in matched_rows:
                created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
                _, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    forced.append((created, float(sc2)))
            if forced:
                recomputed = forced

        recomputed.sort(key=lambda t: t[0])
        out = [{"score": round(p, 2)} for _, p in recomputed]
        return {"success": True, "data": out}, 200

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === åŒæ„é é¢ / éš±ç§é  ===
@app.route("/consent", methods=["GET"])
def render_consent_page():
    return render_template("consent.html")

@app.route("/privacy", methods=["GET"])
def render_privacy_page():
    return render_template("privacy_policy.html")

# === LIFF åŒæ„ APIï¼ˆæ–°å¢ï¼šå¾®ç¯€æµï¼‹å¤±æ•—å…¥èƒŒæ™¯ä½‡åˆ—ï¼Œå› 200ï¼‰ ===
_last_consent_ts = {}
CONSENT_MIN_INTERVAL = float(os.getenv("CONSENT_MIN_INTERVAL", "1.0"))

@app.route("/api/consent", methods=["POST"])
def api_consent():
    try:
        payload = request.get_json(force=True, silent=False) or {}
        agreed = bool(payload.get("agree"))
        user_id = (payload.get("userId") or "").strip()
        display_name = payload.get("displayName") or ""
        source_type = payload.get("sourceType") or ""
        ua = payload.get("ua") or request.headers.get("User-Agent","")
        ts = payload.get("ts") or datetime.utcnow().isoformat()

        if not user_id:
            return {"ok": False, "message": "ç¼ºå°‘ userId"}, 400

        now = time.time()
        last = _last_consent_ts.get(user_id, 0.0)
        if now - last < CONSENT_MIN_INTERVAL:
            return {"ok": True, "message": "accepted"}, 200
        _last_consent_ts[user_id] = now

        ok = upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
        if not ok:
            def job():
                try:
                    upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
                except Exception:
                    pass
            with _consent_lock:
                if len(_consent_q) < 1000:
                    _consent_q.append(job)
            return {"ok": True, "message": "queued"}, 200

        return {"ok": True}, 200
    except Exception as e:
        logging.error(f"/api/consent å¤±æ•—: {e}")
        return {"ok": False}, 500

@app.route("/_debug_predict")
def _debug_predict():
    try:
        r = int(request.args.get("rating"))
        paper = request.args.get("paper", "æ²’æ³¨æ„")
        acc = request.args.get("access", "æ²’æ³¨æ„")

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        feat = [r, paper_map.get(paper, 0), access_map.get(acc, 0)]
        exp = expected_from_feats([feat])

        return {
            "ok": True,
            "input": {"rating": r, "paper": paper, "access": acc},
            "expected": exp
        }, 200
    except Exception as e:
        logging.error(e)
        return {"ok": False}, 500

# === å»ºç«‹ Flex ===
def create_toilet_flex_messages(toilets, show_delete=False, uid=None):
    indicators = build_feedback_index()
    bubbles = []
    for toilet in toilets[:5]:
        actions = []

        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        addr_text = toilet.get('address') or "ï¼ˆç„¡åœ°å€ï¼Œä½¿ç”¨åº§æ¨™ï¼‰"

        title = toilet.get('name') or ""
        if (not title) or title == "ç„¡åç¨±":
            ph = toilet.get("place_hint")
            title = f"{ph}ï¼ˆé™„è¿‘ï¼‰å»æ‰€" if ph else "ï¼ˆæœªå‘½åï¼‰å»æ‰€"

        floor_hint = toilet.get("floor_hint")
        floor_text = f"ğŸ§­ ä½ç½®ï¼š{floor_hint}" if floor_hint else "ğŸ§­ ä½ç½®ï¼šæ¨“å±¤æœªçŸ¥"

        ind = indicators.get((lat_s, lon_s), {"paper":"?","access":"?","avg":None})
        star_text = f"â­{ind['avg']}" if ind.get("avg") is not None else "â­â€”"
        paper_text = "ğŸ§»æœ‰" if ind.get("paper")=="æœ‰" else ("ğŸ§»ç„¡" if ind.get("paper")=="æ²’æœ‰" else "ğŸ§»â€”")
        access_text = "â™¿æœ‰" if ind.get("access")=="æœ‰" else ("â™¿ç„¡" if ind.get("access")=="æ²’æœ‰" else "â™¿â€”")

        actions.append({
            "type": "uri",
            "label": "å°èˆª",
            "uri": f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"
        })
        actions.append({
            "type": "uri",
            "label": "æŸ¥è©¢å›é¥‹",
            "uri": f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"
        })
        addr_raw = toilet.get('address') or ""
        addr_param = quote(addr_raw or "-")
        actions.append({
            "type": "uri",
            "label": "å»æ‰€å›é¥‹",
            "uri": (
                "https://school-i9co.onrender.com/feedback_form/"
                f"{quote(title)}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
            )
        })

        if toilet.get("type") == "favorite" and uid:
            actions.append({
                "type": "postback",
                "label": "ç§»é™¤æœ€æ„›",
                "data": f"remove_fav:{quote(title)}:{lat_s}:{lon_s}"
            })
        elif toilet.get("type") not in ["user", "favorite"] and uid:
            actions.append({
                "type": "postback",
                "label": "åŠ å…¥æœ€æ„›",
                "data": f"add:{quote(title)}:{lat_s}:{lon_s}"
            })

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": title, "weight": "bold", "size": "lg", "wrap": True},
                    {"type": "text", "text": f"{paper_text}  {access_text}  {star_text}", "size": "sm", "color": "#555555", "wrap": True},
                    {"type": "text", "text": addr_text, "size": "sm", "color": "#666666", "wrap": True},
                    {"type": "text", "text": floor_text, "size": "sm", "color": "#666666", "wrap": True},
                    {"type": "text", "text": f"{int(toilet.get('distance',0))} å…¬å°º", "size": "sm", "color": "#999999"}
                ]
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {"type": "button", "style": "primary", "height": "sm", "action": actions[0]}
                ] + [
                    {"type": "button", "style": "secondary", "height": "sm", "action": a}
                    for a in actions[1:]
                ]
            }
        }
        bubbles.append(bubble)
    return {"type": "carousel", "contents": bubbles}

# === åˆ—å‡º æˆ‘çš„è²¢ç» & åˆªé™¤ ===
def get_user_contributions(uid):
    items = []
    try:
        rows = worksheet.get_all_values()
        if not rows or len(rows) < 2:
            return items
        header = rows[0]; data = rows[1:]
        idx = _toilet_sheet_indices(header)
        for i, r in enumerate(data, start=2):
            if idx["user_id"] is None: break
            if len(r) <= idx["user_id"]: continue
            if r[idx["user_id"]] != uid: continue
            try:
                lat = float(r[idx["lat"]]); lon = float(r[idx["lon"]])
            except:
                continue
            items.append({
                "row_index": i,
                "name": (r[idx["name"]] if idx["name"] is not None and len(r)>idx["name"] else "ç„¡åç¨±"),
                "address": (r[idx["address"]] if idx["address"] is not None and len(r)>idx["address"] else ""),
                "lat": float(norm_coord(lat)),
                "lon": float(norm_coord(lon)),
                "created": (r[idx["created"]] if idx["created"] is not None and len(r)>idx["created"] else ""),
            })
        return items
    except Exception as e:
        logging.error(f"è®€å–æˆ‘çš„è²¢ç»å¤±æ•—ï¼š{e}")
        return items

def create_my_contrib_flex(uid):
    contribs = get_user_contributions(uid)
    if not contribs:
        return None
    bubbles = []
    for it in contribs[:10]:
        lat_s = norm_coord(it["lat"]); lon_s = norm_coord(it["lon"])
        addr_raw = it.get('address','') or ""
        addr_param = quote(addr_raw or "-")
        actions = [
            {"type":"uri","label":"å°èˆª","uri":f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"},
            {"type":"uri","label":"æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰","uri":f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"},
            {"type":"uri","label":"å»æ‰€å›é¥‹",
             "uri":(
                f"https://school-i9co.onrender.com/feedback_form/{quote(it['name'])}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
             )},
            {"type":"postback","label":"åˆªé™¤æ­¤è²¢ç»","data":f"confirm_delete_my_toilet:{it['row_index']}"}
        ]
        bubble = {
            "type":"bubble",
            "body":{
                "type":"box","layout":"vertical","contents":[
                    {"type":"text","text":it["name"],"size":"lg","weight":"bold","wrap":True},
                    {"type":"text","text":it.get("address") or "ï¼ˆç„¡åœ°å€ï¼‰","size":"sm","color":"#666666","wrap":True},
                    {"type":"text","text":it['created'], "size":"xs","color":"#999999"}
                ]
            },
            "footer":{
                "type":"box","layout":"vertical","spacing":"sm",
                "contents":[{"type":"button","style":"primary","height":"sm","action":actions[0]}] + [
                    {"type":"button","style":"secondary","height":"sm","action":a} for a in actions[1:]
                ]
            }
        }
        bubbles.append(bubble)
    return {"type":"carousel","contents":bubbles}

# === Webhook ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

@app.route("/", methods=["GET"])
def home():
    return "Toilet bot is running!", 200

# === ä½¿ç”¨è€…ä½ç½®è³‡æ–™ ===
user_locations = {}
pending_delete_confirm = {}

def _do_nearby_toilets_and_push(uid, lat, lon):
    # --- é™ç´šæ¨¡å¼ç›´æ¥è·³é ---
    if guard.mode in (Mode.SAVER, Mode.HARD_STOP):
        logging.info("â­ï¸ degrade mode=%s â€” skip bg push, rely on link", guard.mode)
        return

    try:
        # å…ˆæŸ¥å¿«çš„ä¾†æºï¼ˆCSV + Sheetsï¼‰ï¼Œå¹¾ç™¾æ¯«ç§’å…§å¯å‡º
        quick = _merge_and_dedupe_lists(
            query_public_csv_toilets(lat, lon) or [],
            query_sheet_toilets(lat, lon) or [],
        )
        sort_toilets(quick)

        if quick:
            msg = create_toilet_flex_messages(quick, show_delete=False, uid=uid)
            guard.push(uid,
                       FlexSendMessage("é™„è¿‘å»æ‰€", msg),
                       fallback_text_with_url=f"ğŸ“‰ é¡åº¦ä¸è¶³ï¼Œè«‹ç”¨ç¶²é æŸ¥è©¢ï¼š https://school-i9co.onrender.com/toilet_feedback_by_coord/{norm_coord(lat)}/{norm_coord(lon)}")

        # å†è·‘ OSMï¼ˆæœ‰ 8 ç§’ä¸Šé™ï¼‰
        osm = query_overpass_toilets(lat, lon, radius=500) or []
        all_pts = _merge_and_dedupe_lists(quick, osm)
        sort_toilets(all_pts)

        if SEND_UPDATE_CARD and len(all_pts) > len(quick):  # æ§åˆ¶æ˜¯å¦æ¨æ›´æ–°å¡
            msg2 = create_toilet_flex_messages(all_pts, show_delete=False, uid=uid)
            guard.push(uid,
                       FlexSendMessage("é™„è¿‘å»æ‰€ï¼ˆæ›´æ–°ï¼‰", msg2),
                       fallback_text_with_url=f"ğŸ“‰ é¡åº¦ä¸è¶³ï¼Œè«‹ç”¨ç¶²é æŸ¥è©¢ï¼š https://school-i9co.onrender.com/toilet_feedback_by_coord/{norm_coord(lat)}/{norm_coord(lon)}")

        elif not quick and not all_pts:
            guard.push(uid,
                       TextSendMessage(text="é™„è¿‘æ²’æœ‰å»æ‰€ï¼Œå¯èƒ½è¦åŸåœ°è§£æ”¾äº† ğŸ’¦"),
                       fallback_text_with_url=f"ğŸ“‰ é¡åº¦ä¸è¶³ï¼Œè«‹ç”¨ç¶²é æŸ¥è©¢ï¼š https://school-i9co.onrender.com/toilet_feedback_by_coord/{norm_coord(lat)}/{norm_coord(lon)}")

    except Exception as e:
        logging.error(f"bg nearby error: {e}", exc_info=True)
        guard.push(uid,
                   TextSendMessage(text="ç³»çµ±å¿™ç·šä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™"),
                   fallback_text_with_url=f"ğŸ“‰ é¡åº¦ä¸è¶³ï¼Œè«‹ç”¨ç¶²é æŸ¥è©¢ï¼š https://school-i9co.onrender.com/toilet_feedback_by_coord/{norm_coord(lat)}/{norm_coord(lon)}")

# === TextMessage ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    uid = event.source.user_id
    text_raw = event.message.text or ""
    text = text_raw.strip().lower()

    if is_duplicate_and_mark(f"text|{uid}|{text}"):
        return

    
    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        guard.reply(event, gate_msg)
        return

    reply_messages = []

    if uid in pending_delete_confirm:
        info = pending_delete_confirm[uid]
        if text == "ç¢ºèªåˆªé™¤":
            if info.get("mode") == "sheet_row":
                ok = False
                try:
                    worksheet.delete_rows(int(info["row"]))
                    ok = True
                except Exception as e:
                    logging.error(f"åˆªä¸»è³‡æ–™åˆ—å¤±æ•—ï¼š{e}")
                msg = "âœ… å·²åˆªé™¤ä½ çš„è²¢ç»" if ok else "âŒ åˆªé™¤å¤±æ•—"
            else:
                success = remove_from_favorites(uid, info["name"], info["lat"], info["lon"])
                msg = "âœ… å·²åˆªé™¤è©²å»æ‰€" if success else "âŒ ç§»é™¤å¤±æ•—"
            del pending_delete_confirm[uid]
            reply_messages.append(TextSendMessage(text=msg))
        elif text == "å–æ¶ˆ":
            del pending_delete_confirm[uid]
            reply_messages.append(TextSendMessage(text="âŒ å·²å–æ¶ˆåˆªé™¤"))
        else:
            reply_messages.append(TextSendMessage(text="âš ï¸ è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€"))

    elif text == "é™„è¿‘å»æ‰€":
        loc = user_locations.pop(uid, None)
        if not loc:
            guard.reply(event, TextSendMessage(text="è«‹å…ˆå‚³é€ä½ç½®"))
        else:
            la, lo = loc
            link = f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{norm_coord(la)}/{norm_coord(lo)}"
            # é™ç´šæ¨¡å¼ï¼šä¸æ’èƒŒæ™¯æ¨é€ï¼Œæ”¹å›é€£çµ
            if guard.mode != Mode.NORMAL:
                guard.reply(event, TextSendMessage(text=f"ğŸ“‰ æœ¬æœˆè¨Šæ¯é¡åº¦ç·Šå¼µï¼Œè«‹æ”¹ç”¨ç¶²é æŸ¥çœ‹ï¼š\n{link}"))
                return
            try:
                TASK_Q.put_nowait(lambda uid=uid, la=la, lo=lo: _do_nearby_toilets_and_push(uid, la, lo))
            except Full:
                guard.push(uid, TextSendMessage(text="ç³»çµ±å¿™ç·šä¸­ï¼Œè«‹ç¨å€™å†è©¦ ğŸ™"), fallback_text_with_url=link)
            except Exception as e:
                logging.error(f"enqueue error: {e}", exc_info=True)
                guard.push(uid, TextSendMessage(text="æ’ç¨‹å¤±æ•—ï¼Œè«‹å†å‚³ä¸€æ¬¡ä½ç½® ğŸ™"), fallback_text_with_url=link)

    elif text == "æˆ‘çš„æœ€æ„›":
        favs = get_user_favorites(uid)
        if not favs:
            reply_messages.append(TextSendMessage(text="ä½ å°šæœªæ”¶è—ä»»ä½•å»æ‰€"))
        else:
            loc = user_locations.get(uid)
            if loc:
                lat, lon = loc
                for f in favs:
                    f["distance"] = haversine(lat, lon, f["lat"], f["lon"])
            msg = create_toilet_flex_messages(favs, show_delete=True, uid=uid)
            reply_messages.append(FlexSendMessage("æˆ‘çš„æœ€æ„›", msg))

    elif text == "æˆ‘çš„è²¢ç»":
        msg = create_my_contrib_flex(uid)
        if msg:
            reply_messages.append(FlexSendMessage("æˆ‘æ–°å¢çš„å»æ‰€", msg))
        else:
            reply_messages.append(TextSendMessage(text="ä½ é‚„æ²’æœ‰æ–°å¢éå»æ‰€å–”ã€‚"))

    elif text == "æ–°å¢å»æ‰€":
        base = "https://school-i9co.onrender.com/add"
        loc = user_locations.get(uid)
        if loc:
            la, lo = loc
            url = f"{base}?uid={quote(uid)}&lat={la}&lon={lo}#openExternalBrowser=1"
        else:
            url = f"{base}?uid={quote(uid)}#openExternalBrowser=1"
        reply_messages.append(TextSendMessage(text=f"è«‹å‰å¾€æ­¤é æ–°å¢å»æ‰€ï¼š\n{url}"))

    elif text == "å›é¥‹":
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdsibz15enmZ3hJsQ9s3BiTXV_vFXLy0llLKlpc65vAoGo_hg/viewform?usp=sf_link"
        reply_messages.append(TextSendMessage(text=f"ğŸ’¡ è«‹é€éä¸‹åˆ—é€£çµå›å ±å•é¡Œæˆ–æä¾›æ„è¦‹ï¼š\n{form_url}"))

    if reply_messages:
        guard.reply(event, reply_messages)

# === LocationMessage ===
@handler.add(MessageEvent, message=LocationMessage)
def handle_location(event):
    uid = event.source.user_id
    lat = event.message.latitude
    lon = event.message.longitude

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        guard.reply(event, gate_msg)
        return

    key = f"loc|{uid}|{round(lat,5)},{round(lon,5)}"
    if is_duplicate_and_mark(key):
        return

    user_locations[uid] = (lat, lon)
    guard.reply(event, TextSendMessage(text="âœ… ä½ç½®å·²æ›´æ–°"))

# === Postback ===
@handler.add(PostbackEvent)
def handle_postback(event):
    uid = event.source.user_id
    data = event.postback.data or ""

    if is_duplicate_and_mark(f"pb|{uid}|{data}"):
        return

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        guard.reply(event, gate_msg)
        return

    try:
        if data.startswith("add:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            toilet = {
                "name": name,
                "lat": float(lat),
                "lon": float(lon),
                "address": f"{lat},{lon}",
                "distance": 0,
                "type": "sheet"
            }
            add_to_favorites(uid, toilet)
            guard.reply(event, TextSendMessage(text=f"âœ… å·²æ”¶è— {name}"))

        elif data.startswith("remove_fav:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            success = remove_from_favorites(uid, name, lat, lon)
            msg = "âœ… å·²ç§»é™¤æœ€æ„›" if success else "âŒ ç§»é™¤å¤±æ•—"
            guard.reply(event, TextSendMessage(text=msg))

        elif data.startswith("confirm_delete:"):
            _, qname, qaddr, lat, lon = data.split(":", 4)
            name = unquote(qname)
            pending_delete_confirm[uid] = {
                "mode": "favorite",
                "name": name,
                "lat": norm_coord(lat),
                "lon": norm_coord(lon)
            }
            guard.reply(event, [
                TextSendMessage(text=f"âš ï¸ ç¢ºå®šè¦åˆªé™¤ {name} å—ï¼Ÿï¼ˆç›®å‰åˆªé™¤ç‚ºç§»é™¤æœ€æ„›ï¼‰"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])

        elif data.startswith("confirm_delete_my_toilet:"):
            _, row_str = data.split(":", 1)
            pending_delete_confirm[uid] = {
                "mode": "sheet_row",
                "row": int(row_str)
            }
            guard.reply(event, [
                TextSendMessage(text="âš ï¸ ç¢ºå®šè¦åˆªé™¤æ­¤ã€ä½ æ–°å¢çš„å»æ‰€ã€å—ï¼Ÿæ­¤å‹•ä½œæœƒå¾ä¸»è³‡æ–™è¡¨åˆªé™¤è©²åˆ—ã€‚"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])

    except Exception as e:
        logging.error(f"âŒ è™•ç† postback å¤±æ•—: {e}")

# === æ–°å¢å»æ‰€é é¢ ===
@app.route("/add", methods=["GET"])
def render_add_page():
    uid = request.args.get("uid", "")
    lat = request.args.get("lat", "")
    lon = request.args.get("lon", "")
    preset_address = ""

    if lat and lon:
        try:
            ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
            url = f"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat={lat}&lon={lon}&addressdetails=1"
            headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                a = data.get("address", {})
                pretty = " ".join(filter(None, [
                    a.get("country", ""),
                    a.get("state", a.get("region", "")),
                    a.get("city", a.get("town", a.get("village", a.get("county", "")))),
                    a.get("suburb", a.get("neighbourhood", "")),
                    a.get("road", ""),
                    a.get("house_number", ""),
                    a.get("postcode", "")
                ])).strip()
                preset_address = pretty or data.get("display_name", "")
        except Exception as e:
            logging.warning(f"reverse geocode å¤±æ•—: {e}")

    return render_template(
        "submit_toilet.html",
        preset_address=preset_address,
        preset_lat=lat,
        preset_lon=lon
    )

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ API ===
@app.route("/submit_toilet", methods=["POST"])
def submit_toilet():
    try:
        data = request.get_json(force=True, silent=False) or {}
        logging.info(f"ğŸ“¥ æ”¶åˆ°è¡¨å–®è³‡æ–™: {data}")

        uid   = (data.get("user_id") or "web").strip()
        name  = (data.get("name") or "").strip()
        addr  = (data.get("address") or "").strip()

        level          = (data.get("level") or "").strip()
        floor_hint     = (data.get("floor_hint") or "").strip()
        entrance_hint  = (data.get("entrance_hint") or "").strip()
        access_note    = (data.get("access_note") or "").strip()
        open_hours     = (data.get("open_hours") or "").strip()

        lat_in = (data.get("lat") or "").strip()
        lon_in = (data.get("lon") or "").strip()

        if not name or not addr:
            return {"success": False, "message": "è«‹æä¾›ã€å»æ‰€åç¨±ã€èˆ‡ã€åœ°å€ã€"}, 400

        if floor_hint and len(floor_hint) < 4:
            return {"success": False, "message": "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—"}, 400

        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        lat_f, lon_f = (None, None)
        if lat_in and lon_in:
            lat_f, lon_f = _parse_lat_lon(lat_in, lon_in)

        if lat_f is None or lon_f is None:
            lat_f, lon_f = geocode_address(addr)

        if lat_f is None or lon_f is None:
            return {"success": False, "message": "åœ°å€è½‰æ›å¤±æ•—ï¼Œè«‹ä¿®æ­£åœ°å€æˆ–æä¾›åº§æ¨™"}, 400

        lat_s, lon_s = norm_coord(lat_f), norm_coord(lon_f)

        header = ensure_toilet_sheet_header(worksheet)
        idx = {h: i for i, h in enumerate(header)}

        row_values = [""] * len(header)
        def put(col, val):
            if col in idx:
                row_values[idx[col]] = val

        put("user_id", uid)
        put("name", name)
        put("address", addr)
        put("lat", lat_s)
        put("lon", lon_s)
        put("level", level)
        put("floor_hint", floor_hint)  
        put("entrance_hint", entrance_hint)
        put("access_note", access_note)
        put("open_hours", open_hours)
        put("timestamp", datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"))

        worksheet.append_row(row_values, value_input_option="USER_ENTERED")
        logging.info(f"âœ… å»æ‰€è³‡æ–™å·²å¯«å…¥ Google Sheets: {name}")

        try:
            if not os.path.exists(TOILETS_FILE_PATH):
                with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(PUBLIC_HEADERS)
            with open(TOILETS_FILE_PATH, "a", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "00000","0000000","æœªçŸ¥é‡Œ","USERADD", name, addr, "ä½¿ç”¨è€…è£œå……",
                    lat_s, lon_s,
                    "æ™®é€šç´š","å…¬å…±å ´æ‰€","æœªçŸ¥","ä½¿ç”¨è€…","0"
                ])
        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³æœ¬åœ° CSV å¤±æ•—ï¼š{e}")

        return {"success": True, "message": f"âœ… å·²æ–°å¢å»æ‰€ {name}"}
    except Exception as e:
        logging.error(f"âŒ æ–°å¢å»æ‰€éŒ¯èª¤:\n{traceback.format_exc()}")
        return {"success": False, "message": "ä¼ºæœå™¨éŒ¯èª¤"}, 500

# === èƒŒæ™¯æ’ç¨‹ï¼ˆé ç•™ï¼‰ ===
def auto_predict_cleanliness_background():
    while True:
        try:
            logging.info("ğŸŒ€ èƒŒæ™¯æ’ç¨‹å•Ÿå‹•ä¸­ï¼ˆæœªä¾†å¯åŠ å…¥è‡ªå‹•çµ±è¨ˆï¼‰")
        except Exception as e:
            logging.error(f"âŒ èƒŒæ™¯ä»»å‹™å‡ºéŒ¯ï¼š{e}")
        time.sleep(1800)

# === å•Ÿå‹• ===
if __name__ == "__main__":
    threading.Thread(target=auto_predict_cleanliness_background, daemon=True).start()
    threading.Thread(target=_self_keepalive_background, daemon=True).start()

    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port)