import os
import csv
import json
import logging
import sqlite3
import requests
import traceback
from collections import OrderedDict
from math import radians, cos, sin, asin, sqrt
from flask_cors import CORS
from flask import Flask, request, abort, render_template, redirect, url_for, Response
from dotenv import load_dotenv
from urllib.parse import quote, unquote
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import (
    MessageEvent, TextMessage, LocationMessage,
    TextSendMessage, FlexSendMessage,
    QuickReply, QuickReplyButton, LocationAction, MessageAction,
    PostbackEvent   
)
from linebot.models import QuickReply, QuickReplyButton
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
from openai import OpenAI
import html
import joblib
import threading
import time
import statistics
from difflib import SequenceMatcher
import random
import re

load_dotenv()
try:
    import pandas as pd
except Exception:
    pd = None

# === å…¨åŸŸè¨­å®š ===
def _try_acquire_loc_slot() -> bool:
    try:
        return _LOC_SEM.acquire(blocking=False)
    except Exception:
        return False

def _release_loc_slot():
    try:
        _LOC_SEM.release()
    except Exception:
        pass

# === reply_token ä½¿ç”¨è¨˜éŒ„ï¼ˆæ–°å¢ï¼‰ ===
_USED_REPLY_TOKENS = set()
_MAX_USED_TOKENS = 50000  # é˜²æ­¢é›†åˆç„¡é™æˆé•·
CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")

def show_loading(uid, seconds=10):
    url = "https://api.line.me/v2/bot/chat/loading/start"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {CHANNEL_ACCESS_TOKEN}"
    }
    payload = {
        "chatId": uid,
        "loadingSeconds": max(5, min(seconds, 60))
    }

    resp = requests.post(url, headers=headers, json=payload)
    logging.info(f"[loading] {resp.status_code} {resp.text}")

def _mark_token_used(tok: str):
    try:
        _USED_REPLY_TOKENS.add(tok)
        if len(_USED_REPLY_TOKENS) > _MAX_USED_TOKENS:
            _USED_REPLY_TOKENS.clear()  # ç°¡å–®æ¸…ç†
    except Exception:
        pass

def _is_token_used(tok: str) -> bool:
    return tok in _USED_REPLY_TOKENS

class SimpleLRU(OrderedDict):
    def __init__(self, maxsize=500):
        super().__init__()
        self.maxsize = maxsize
    def get(self, key, default=None):
        if key in self:
            self.move_to_end(key)
            return super().get(key)
        return default
    def set(self, key, value):
        super().__setitem__(key, value)
        self.move_to_end(key)
        while len(self) > self.maxsize:
            self.popitem(last=False)

# ------ çµ±ä¸€è¨­å®šï¼ˆå¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼›è‹¥ä½ å·²åœ¨åˆ¥è™•å®šç¾©ï¼Œè«‹ä»¥é€™è£¡ç‚ºæº–ï¼‰------

LOC_MAX_CONCURRENCY = int(os.getenv("LOC_MAX_CONCURRENCY", "3"))      # åŒæ™‚æœ€å¤šå¹¾å€‹ä½¿ç”¨è€…åœ¨è·‘é™„è¿‘æŸ¥è©¢
LOC_QUERY_TIMEOUT_SEC = float(os.getenv("LOC_QUERY_TIMEOUT_SEC", "3.0"))  # å„è³‡æ–™æºé€¾æ™‚ï¼ˆç§’ï¼‰
LOC_MAX_RESULTS = int(os.getenv("LOC_MAX_RESULTS", "4"))             # æœ€å¤šå›å¹¾å€‹

SHOW_SEARCHING_BUBBLE = False
_LOC_SEM = threading.Semaphore(LOC_MAX_CONCURRENCY)
ENRICH_MAX_ITEMS    = int(os.getenv("ENRICH_MAX_ITEMS", "60"))
OVERPASS_MAX_ITEMS  = int(os.getenv("OVERPASS_MAX_ITEMS", "60"))
ENRICH_LRU_SIZE     = int(os.getenv("ENRICH_LRU_SIZE", "300"))
NEARBY_LRU_SIZE     = int(os.getenv("NEARBY_LRU_SIZE", "300"))

FEEDBACK_INDEX_TTL  = int(os.getenv("FEEDBACK_INDEX_TTL", "180"))  # ç”± 60 â†’ 180
STATUS_INDEX_TTL    = int(os.getenv("STATUS_INDEX_TTL", "180"))    # ç”± 60 â†’ 180
MAX_SHEET_ROWS      = int(os.getenv("MAX_SHEET_ROWS", "4000"))     # åªè®€å°¾ç«¯ N åˆ—

# ------ å°‡åŸæœ¬çš„ dict æ›æˆ LRUï¼ˆâš ï¸ åˆ¥åœ¨æª”æ¡ˆå…¶ä»–åœ°æ–¹å†è³¦å€¼è¦†è“‹å®ƒå€‘ï¼‰------
_ENRICH_CACHE = SimpleLRU(maxsize=ENRICH_LRU_SIZE)
_CACHE        = SimpleLRU(maxsize=NEARBY_LRU_SIZE)

# ï¼ˆå¯é¸ï¼‰å•Ÿå‹•æ™‚å°å‡ºå¿«å–å‹åˆ¥ï¼Œæ–¹ä¾¿æª¢æŸ¥æ²’æœ‰è¢«è¦†è“‹å› dict
try:
    logging.info(f"ğŸ” ENRICH_CACHE={_ENRICH_CACHE.__class__.__name__} NEARBY_CACHE={_CACHE.__class__.__name__}")
except Exception:
    pass

# ======================== Sheets å®‰å…¨å¤–æ›å±¤ï¼ˆæ²¿ç”¨ä½ ç¾æœ‰çš„è¨­å®šå³å¯ï¼‰ ========================
SHEETS_MAX_CONCURRENCY = int(os.getenv("SHEETS_MAX_CONCURRENCY", "4"))
SHEETS_RETRY_MAX = int(os.getenv("SHEETS_RETRY_MAX", "6"))
SHEETS_READ_TTL_SEC = int(os.getenv("SHEETS_READ_TTL_SEC", "45"))
SHEETS_CACHE_MAX_ROWS = int(os.getenv("SHEETS_CACHE_MAX_ROWS", "20000"))

_sheets_sem = threading.Semaphore(SHEETS_MAX_CONCURRENCY)
_read_cache = {}            # key: (sheet_id, ws_title, op) -> {ts, val}
_ENRICH_CACHE = {}
_cache_lock = threading.Lock()
_gsheet_lock = threading.Lock()
_cache_lock = threading.Lock()
_fallback_lock = threading.Lock()

def _is_quota_or_retryable(exc: Exception) -> bool:
    s = str(exc).lower()
    return ("429" in s or "quota" in s or "rate limit" in s or
            "timeout" in s or "timed out" in s or "503" in s or "500" in s)

def delay_request():
    delay_time = random.uniform(0.5, 1.5)  # éš¨æ©Ÿå»¶é²æ™‚é–“ï¼Œæ ¹æ“šéœ€æ±‚èª¿æ•´
    time.sleep(delay_time)

def _with_retry(func, *args, **kwargs):
    backoff = 0.7
    last_exc = None
    for i in range(SHEETS_RETRY_MAX):
        try:
            with _sheets_sem:
                return func(*args, **kwargs)
        except Exception as e:
            last_exc = e
            if _is_quota_or_retryable(e):
                delay_request()
                sleep_s = backoff * (2 ** i) + random.uniform(0, 0.25*i)
                time.sleep(sleep_s)
                continue
            raise
    raise last_exc if last_exc else RuntimeError("Sheets retry exhausted")

def batch_query_sheets(query_keys):
    # åŒæ™‚æŸ¥è©¢å¤šå€‹å¿«å–çš„è³‡æ–™
    results = []
    for key in query_keys:
        cached_data = get_cached_data(key)
        if cached_data:
            results.append(cached_data)
        else:
            results.append(None)  # è‹¥ç„¡å¿«å–ï¼Œæœƒå†é€²è¡Œ API è«‹æ±‚
    return results

def retry_request(func, *args, **kwargs):
    retries = 3
    for i in range(retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if i < retries - 1:
                time.sleep(2 ** i)  # Exponential backoff
                continue
            else:
                raise e

class SafeWS:
    def __init__(self, ws, sheet_id: str, name: str):
        self._ws = ws
        self._sheet_id = sheet_id
        self._name = name

    # ---------- è®€å–ï¼ˆå«å¿«å–ï¼‰ ----------
    def get_all_values(self):
        key = (self._sheet_id, self._name, "get_all_values")
        now = time.time()
        with _cache_lock:
            c = _read_cache.get(key)
            if c and now - c["ts"] < SHEETS_READ_TTL_SEC:
                return c["val"]

        def _do():
            return self._ws.get_all_values()

        val = _with_retry(_do)
        # åªå¿«å–åˆç†å¤§å°ï¼Œé¿å…æŠŠæ•´å€‹è¶…å¤§è¡¨å¡é€²è¨˜æ†¶é«”
        if isinstance(val, list) and len(val) <= SHEETS_CACHE_MAX_ROWS:
            with _cache_lock:
                _read_cache[key] = {"ts": now, "val": val}
        return val

    def row_values(self, i):
        return _with_retry(self._ws.row_values, i)

    # âœ… æ–°å¢ï¼šçµ¦ _get_header_and_tail / è¼•é‡ä¼°ç®—ç¸½åˆ—æ•¸ç”¨
    def col_values(self, i):
        return _with_retry(self._ws.col_values, i)

    # âœ… æ–°å¢ï¼šçµ¦å€æ®µè®€å–ï¼ˆå¦‚ "A2:AZ100"ï¼‰
    def get(self, rng):
        return _with_retry(self._ws.get, rng)

    # ---------- å¯«å…¥ï¼ˆæˆåŠŸå¾Œå¤±æ•ˆå¿«å–ï¼‰ ----------
    def _invalidate(self):
        key = (self._sheet_id, self._name, "get_all_values")
        with _cache_lock:
            _read_cache.pop(key, None)

    def update(self, rng, values):
        def _do():
            return self._ws.update(rng, values)
        out = _with_retry(_do)
        self._invalidate()
        return out

    def append_row(self, values, value_input_option="RAW"):
        def _do():
            return self._ws.append_row(values, value_input_option=value_input_option)
        out = _with_retry(_do)
        self._invalidate()
        return out

    def delete_rows(self, index):
        def _do():
            return self._ws.delete_rows(index)
        out = _with_retry(_do)
        self._invalidate()
        return out

    # ---------- å…¶ä»– ----------
    def worksheet(self, title):
        # å–å¾—åŒè©¦ç®—è¡¨å…§çš„å…¶ä»–å·¥ä½œè¡¨ï¼ŒæŒçºŒæ²¿ç”¨ SafeWS åŒ…è£
        return self.__class__(self._ws.worksheet(title), self._sheet_id, title)

    @property
    def title(self):
        return self._ws.title

# === consent èƒŒæ™¯æ’éšŠï¼ˆ429 æ™‚ä¸å› 500ï¼‰ ===
_consent_q = []                    
_consent_lock = threading.Lock()    

def _start_consent_worker():
    def loop():
        while True:
            job = None
            try:
                # å–å‡ºä¸€å€‹å·¥ä½œ
                with _consent_lock:
                    if _consent_q:
                        job = _consent_q.pop(0)
            except Exception as e:
                logging.error(f"Consent worker dequeue error: {e}")

            if not job:
                time.sleep(0.2)
                continue

            try:
                job()  # åŸ·è¡Œè£œå¯«
            except Exception as e:
                logging.error(f"Consent worker error: {e}")

    t = threading.Thread(target=loop, name="consent-worker", daemon=True)
    t.start()

_start_consent_worker()

def make_location_quick_reply(prompt_text="ğŸ“ è«‹åˆ†äº«ä½ çš„ä½ç½®", mode="normal"):
    items = [
        QuickReplyButton(
            action=LocationAction(label="å‚³é€æˆ‘çš„ä½ç½®")
        )
    ]

    if mode == "normal":
        # é¡¯ç¤ºã€ŒAI æ¨è–¦é™„è¿‘å»æ‰€ã€â†’ é€å‡ºæ–‡å­—çµ¦ handle_text
        items.append(
            QuickReplyButton(
                action=MessageAction(
                    label="AI æ¨è–¦é™„è¿‘å»æ‰€",
                    text="AIæ¨è–¦é™„è¿‘å»æ‰€"
                )
            )
        )
    else:  # mode == "ai"
        # é¡¯ç¤ºã€Œåˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ã€â†’ é€å‡ºæ–‡å­—çµ¦ handle_text
        items.append(
            QuickReplyButton(
                action=MessageAction(
                    label="åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼",
                    text="åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼"
                )
            )
        )

    return TextSendMessage(
        text=prompt_text,
        quick_reply=QuickReply(items=items)
    )

def make_retry_location_text(text="ç¾åœ¨æŸ¥è©¢äººæ•¸æœ‰é»å¤šï¼Œæˆ‘æ’ä¸€ä¸‹éšŠï¼›ä½ å¯å†å‚³ä¸€æ¬¡ä½ç½®æˆ–ç¨å€™å¹¾ç§’ï½"):
    return TextSendMessage(
        text=text,
        quick_reply=QuickReply(items=[
            QuickReplyButton(action=LocationAction(label="å‚³é€æˆ‘çš„ä½ç½®"))
        ])
    )
def make_no_toilet_quick_reply(uid, lat=None, lon=None,
                               text="é™„è¿‘æ²’æœ‰å»æ‰€ ğŸ˜¥ è¦ä¸è¦è£œä¸Šä¸€é–“ï¼Ÿ"):
    base = "https://school-i9co.onrender.com/add"
    if lat is not None and lon is not None:
        add_url = f"{base}?uid={quote(uid)}&lat={lat}&lon={lon}#openExternalBrowser=1"
    else:
        add_url = f"{base}?uid={quote(uid)}#openExternalBrowser=1"

    return TextSendMessage(
        text=text,
        quick_reply=QuickReply(items=[
            QuickReplyButton(action=LocationAction(label="å‚³é€æˆ‘çš„ä½ç½®")),
            QuickReplyButton(action=MessageAction(label="æ–°å¢å»æ‰€", text="æ–°å¢å»æ‰€"))
        ])
    )

# === åˆå§‹åŒ– ===
logging.basicConfig(level=logging.INFO)
app = Flask(__name__)
CORS(app)

class _NoHealthzFilter(logging.Filter):
    def filter(self, record):
        try:
            msg = record.getMessage()
        except Exception:
            return True
        return "/healthz" not in msg

# === å®‰å…¨æ¨™é ­èˆ‡å¿«å–ç­–ç•¥ï¼ˆæ–°å¢ï¼‰ ===
@app.after_request
def add_security_headers(resp):
    try:
        # é€šç”¨å®‰å…¨èˆ‡å¿«å–æ”¿ç­–
        resp.headers.setdefault("Cache-Control", "no-store")
        resp.headers.setdefault("Pragma", "no-cache")
        resp.headers.setdefault("X-Content-Type-Options", "nosniff")
        resp.headers.setdefault("X-Frame-Options", "DENY")
        resp.headers.setdefault("Referrer-Policy", "strict-origin-when-cross-origin")

        path = (request.path or "").lower()

        if path.startswith("/consent") or path.startswith("/api/consent"):
            # ğŸ”“ å®Œå…¨æ”¾å¯¬ CSPï¼Œé¿å…æ“‹åˆ° LIFF
            resp.headers["Content-Security-Policy"] = (
                "default-src * data: blob: filesystem: about: 'unsafe-inline' 'unsafe-eval';"
            )
        else:
            # âœ… å…¶ä»–é é¢ï¼šå…è¨±å¸¸è¦‹ CDN è¼‰å…¥ Chart.jsï¼›ä¸¦åŠ ä¸Š connect-src ä»¥ä¾¿ fetch
            csp = [
                "default-src 'self'",
                "img-src 'self' data: https:",
                "script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net https://cdnjs.cloudflare.com https://unpkg.com",
                "style-src 'self' 'unsafe-inline'",
                "connect-src 'self' https:",
                "font-src 'self' data: https:",
                "frame-ancestors 'none'",
            ]
            # ç”¨ã€Œç›´æ¥æŒ‡å®šã€å–ä»£ setdefaultï¼Œç¢ºä¿è¦†è“‹èˆŠå€¼
            resp.headers["Content-Security-Policy"] = "; ".join(csp) + ";"
    except Exception as e:
        logging.debug(f"add_security_headers skipped: {e}")
    return resp

# === å°±ç·’æª¢æŸ¥ç«¯é»ï¼ˆæ–°å¢ï¼‰ ===
@app.route("/readyz", methods=["GET", "HEAD"])
def readyz():
    _ensure_sheets_ready()
    ok = (worksheet is not None) and (feedback_sheet is not None) and (consent_ws is not None)
    status = 200 if ok else 503
    msg = "ready" if ok else "not-ready"
    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-store",
        "X-Robots-Tag": "noindex",
    }
    if request.method == "HEAD":
        return Response(status=204 if ok else 503, headers=headers)
    return Response(msg, status=status, headers=headers)

logging.getLogger("werkzeug").addFilter(_NoHealthzFilter())

# === å¥åº·æª¢æŸ¥ç«¯é» ===
@app.route("/healthz", methods=["GET", "HEAD"])
def healthz():
    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-store",
        "X-Robots-Tag": "noindex",
    }
    if request.method == "HEAD":
        return Response(status=204, headers=headers)
    return Response("ok", status=200, headers=headers)

# === è‡ªæˆ‘æ¿€æ´»è¨­å®š ===
KEEPALIVE_URL = (
    os.getenv("KEEPALIVE_URL")
    or (os.getenv("PUBLIC_URL") and os.getenv("PUBLIC_URL").rstrip("/") + "/healthz")
    or (os.getenv("RENDER_EXTERNAL_URL") and os.getenv("RENDER_EXTERNAL_URL").rstrip("/") + "/healthz")
)
KEEPALIVE_ENABLE = os.getenv("KEEPALIVE_ENABLE", "1") == "1"
KEEPALIVE_INTERVAL_SECONDS = int(os.getenv("KEEPALIVE_INTERVAL_SECONDS", "600"))
KEEPALIVE_JITTER_SECONDS   = int(os.getenv("KEEPALIVE_JITTER_SECONDS", "60"))

def _self_keepalive_background():
    if not KEEPALIVE_ENABLE or not KEEPALIVE_URL:
        logging.info("â­ï¸ keepalive disabled (no URL or disabled by env).")
        return
    headers = {"User-Agent": f"SelfKeepalive/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}
    while True:
        try:
            requests.head(KEEPALIVE_URL, timeout=8, headers=headers)
            logging.debug("âœ… keepalive ok")
        except Exception as e:
            logging.debug(f"âš ï¸ keepalive failed: {e}")
        sleep_for = KEEPALIVE_INTERVAL_SECONDS + random.randint(0, KEEPALIVE_JITTER_SECONDS)
        time.sleep(sleep_for)

line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

def get_nearby_toilets(uid, lat, lon):
    key = f"{lat},{lon}"
    cached = _CACHE.get(key)
    if cached is not None:
        return cached
    toilets = query_public_csv_toilets(lat, lon)
    _CACHE.set(key, toilets)
    return toilets

# === æª”æ¡ˆ ===
DATA_DIR = os.path.join(os.getcwd(), "data")
TOILETS_FILE_PATH = os.path.join(DATA_DIR, "public_toilets.csv")
FAVORITES_FILE_PATH = os.path.join(DATA_DIR, "favorites.txt")
os.makedirs(DATA_DIR, exist_ok=True)

if not os.path.exists(FAVORITES_FILE_PATH):
    open(FAVORITES_FILE_PATH, "a", encoding="utf-8").close()

PUBLIC_HEADERS = [
    "country","city","village","number","name","address","administration",
    "latitude","longitude","grade","type2","type","exec","diaper"
]
if not os.path.exists(TOILETS_FILE_PATH):
    with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(PUBLIC_HEADERS)

# === Google Sheets è¨­å®š ===
GSHEET_SCOPE = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
GSHEET_CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON")
TOILET_SPREADSHEET_ID = "1Vg3tiqlXcXjcic2cAWCG-xTXfNzcI7wegEnZx8Ak7ys"
FEEDBACK_SPREADSHEET_ID = "15Ram7EZ9QMN6SZAVYQFNpL5gu4vTaRn4M5mpWUKmmZk"

# === åŒæ„æ›¸è¨­å®š ===
CONSENT_SHEET_TITLE = "consent"
CONSENT_PAGE_URL = os.getenv("CONSENT_PAGE_URL", "https://school-i9co.onrender.com/consent")

gc = worksheet = feedback_sheet = consent_ws = None

# === ç‹€æ…‹å›å ±è¨­å®š ===
STATUS_SHEET_TITLE = "status"
status_ws = None

# è¿‘é»/å¿«å–/æœ‰æ•ˆæœŸ
_STATUS_NEAR_M = 35
_STATUS_TTL_HOURS = 6
_status_index_cache = {"ts": 0, "data": {}}
_STATUS_INDEX_TTL = 60

MAX_SHEET_ROWS = int(os.getenv("MAX_SHEET_ROWS", "4000")) 

def _a1_col(n: int) -> str:
    if n <= 0:
        return "A"
    out = []
    while n > 0:
        n, r = divmod(n - 1, 26)
        out.append(chr(65 + r))
    return "".join(reversed(out))


def _get_header_and_tail(ws, max_rows: int = MAX_SHEET_ROWS):
    try:
        max_rows = int(max_rows)
        if max_rows <= 0:
            max_rows = 1
    except Exception:
        max_rows = 1000  

    try:
        header = ws.row_values(1) or []
        if not header:
            return [], []

        col_a = ws.col_values(1) or []
        last_row = len(col_a)
        if last_row < 2:  
            return header, []

        start_row = max(2, last_row - max_rows + 1)

        end_col = _a1_col(max(1, len(header)))
        rng = f"A{start_row}:{end_col}{last_row}"

        data = ws.get(rng) or []
        return header, data

    except Exception as e:
        logging.warning(f"_get_header_and_tail primary path failed: {e}")

        # === Fallbackï¼šä¸€æ¬¡æŠ“ï¼Œç„¶å¾Œåªä¿ç•™å°¾ç«¯ max_rowsï¼Œé¿å…ä½”è¨˜æ†¶é«” ===
        try:
            rows = ws.get_all_values() or []
            if not rows:
                return [], []
            header = rows[0]
            data = rows[1:]
            if len(data) > max_rows:
                data = data[-max_rows:]
            return header, data
        except Exception as e2:
            logging.warning(f"_get_header_and_tail fallback failed: {e2}")
            return [], []

# === è¼‰å…¥æ¨¡å‹ ===
BASE_DIR = os.path.abspath(os.path.dirname(__file__))

def load_cleanliness_model():
    try:
        model_path = os.path.join(BASE_DIR, 'models', 'clean_model.pkl')
        model = joblib.load(model_path)
        logging.info("âœ… æ¸…æ½”åº¦æ¨¡å‹å·²è¼‰å…¥")
        return model
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def load_label_encoder():
    try:
        encoder_path = os.path.join(BASE_DIR, 'models', 'label_encoder.pkl')
        encoder = joblib.load(encoder_path)
        logging.info("âœ… LabelEncoder å·²è¼‰å…¥")
        return encoder
    except Exception as e:
        logging.error(f"âŒ LabelEncoder è¼‰å…¥å¤±æ•—: {e}")
        return None

cleanliness_model = load_cleanliness_model()
label_encoder = load_label_encoder()

# === åƒæ•¸ ===
LAST_N_HISTORY = 5

# === å·¥å…·ï¼šåº§æ¨™æ¨™æº–åŒ–ï¼è§£æ ===
def norm_coord(x, ndigits=6):
    try:
        return f"{round(float(x), ndigits):.{ndigits}f}"
    except:
        return str(x)
    
def safe_html(s):
    return html.escape(s or "")

def _parse_lat_lon(lat_s, lon_s):
    try:
        lat = float(str(lat_s).strip())
        lon = float(str(lon_s).strip())
    except Exception:
        return None, None
    if abs(lat) > 90 and abs(lon) <= 90:
        lat, lon = lon, lat
    if not (-90 <= lat <= 90 and -180 <= lon <= 180):
        return None, None
    return lat, lon

# === LIFF è¨­å®š ===
PUBLIC_URL = (os.getenv("PUBLIC_URL") or "").rstrip("/")
LIFF_STATUS_ID = os.getenv("LIFF_STATUS_ID", "")

def _status_liff_url(lat=None, lon=None):
    """å›å‚³ç‹€æ…‹å›å ± LIFF é é¢ç¶²å€ã€‚è‹¥æ²’å¸¶åº§æ¨™ï¼Œè®“ LIFF è‡ªå·±å–å®šä½ã€‚"""
    if not PUBLIC_URL:
        return None
    base = f"{PUBLIC_URL}/status_liff"
    if lat is None or lon is None:
        return base
    return f"{base}?lat={norm_coord(lat)}&lon={norm_coord(lon)}"

# === æ¨“å±¤æ¨æ–· ===
def _floor_from_tags(tags: dict):
    if not tags:
        return None
    level = tags.get("level") or tags.get("level:ref") or tags.get("addr:floor")
    loc = (tags.get("location") or "").lower()
    try:
        if level is not None and str(level).strip() != "":
            lv_str = str(level).strip().replace("F","").replace("f","")
            lv = int(float(lv_str))
            if lv < 0:
                return f"åœ°ä¸‹{abs(lv)}F"
            if lv == 0:
                return "åœ°é¢"
            return f"{lv}F"
    except Exception:
        pass
    if loc == "underground":
        return "åœ°ä¸‹"
    if loc == "overground":
        return "åœ°é¢"
    return None

_ZH_DIGIT = {"é›¶":0,"ã€‡":0,"ä¸€":1,"äºŒ":2,"å…©":2,"ä¸‰":3,"å››":4,"äº”":5,"å…­":6,"ä¸ƒ":7,"å…«":8,"ä¹":9}

def _zh_to_int_word(word: str):
    if not word:
        return None
    w = word.replace("ä¸¤","å…©")
    if "å" not in w:
        return _ZH_DIGIT.get(w)
    left, _, right = w.partition("å")
    tens = 10 if left == "" else (_ZH_DIGIT.get(left, 0) * 10)
    ones = 0 if right == "" else _ZH_DIGIT.get(right, 0)
    val = tens + ones
    return val if val > 0 else None

def _normalize_floor_label(n: int, underground: bool=False):
    try:
        n = int(n)
    except Exception:
        return None
    if underground:
        return f"åœ°ä¸‹{abs(n)}F"
    if n == 0:
        return "åœ°é¢"
    return f"{n}F"

def _floor_from_name(name: str):
    if not name:
        return None
    s = str(name).strip()
    s_lower = s.lower()

    if re.search(r'(?:^|[^a-z])g\s*/?\s*f(?:[^a-z]|$)', s_lower) or re.search(r'ground\s*floor', s_lower):
        return "åœ°é¢"

    m = re.search(r'(?:^|[^a-z])[bï¼¢]\s*-?\s*(\d{1,2})\s*(?:f|æ¨“|å±¤)?(?:[^0-9]|$)', s_lower)
    if m:
        n = int(m.group(1))
        if n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'åœ°ä¸‹\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶\d]{1,3})\s*(?:æ¨“|å±¤|f)?', s_lower)
    if m:
        token = m.group(1)
        n = int(token) if token.isdigit() else _zh_to_int_word(token)
        if n and n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'(\d{1,3})\s*(?:f|æ¨“|å±¤)(?:[^a-z0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    m = re.search(r'ç¬¬?\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶]{1,3})\s*(?:æ¨“|å±¤)', s_lower)
    if m:
        n = _zh_to_int_word(m.group(1))
        if n:
            return _normalize_floor_label(n)

    m = re.search(r'(?:^|[^a-z])l\s*(\d{1,3})(?:[^0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    return None

# === ä¾é™„è¿‘å ´é¤¨å‘½å ===
_ENRICH_TTL = 120

def enrich_nearby_places(lat, lon, radius=500):
    # ğŸ”Œ ç¸½é–‹é—œï¼šé è¨­é—œé–‰ï¼ˆENV å¯è¨­ ENRICH_ENABLE=1 é–‹å•Ÿï¼‰
    enabled = globals().get("ENRICH_ENABLE", None)
    if enabled is None:
        try:
            enabled = int(os.getenv("ENRICH_ENABLE", "0"))
        except Exception:
            enabled = 0
    if not enabled:
        return []

    key = f"{round(lat,4)},{round(lon,4)}:{radius}"
    now = time.time()
    cached = _ENRICH_CACHE.get(key)
    if cached and (now - cached[0] < _ENRICH_TTL):
        return cached[1]

    q = f"""
    [out:json][timeout:25];
    (
      node(around:{radius},{lat},{lon})["name"]["building"];
      way(around:{radius},{lat},{lon})["name"]["building"];
      node(around:{radius},{lat},{lon})["name"]["shop"];
      way(around:{radius},{lat},{lon})["name"]["shop"];
      node(around:{radius},{lat},{lon})["name"]["amenity"];
      way(around:{radius},{lat},{lon})["name"]["amenity"];
    );
    out center tags;
    """
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]
    headers = {"User-Agent": f"ToiletBot/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}

    for url in endpoints:
        try:
            resp = requests.post(url, data=q, headers=headers, timeout=30)
            if resp.status_code == 200 and "json" in (resp.headers.get("Content-Type","").lower()):
                els = resp.json().get("elements", [])
                out = []
                for e in els:
                    if e.get("type") == "node":
                        clat, clon = e.get("lat"), e.get("lon")
                    else:
                        c = e.get("center") or {}
                        clat, clon = c.get("lat"), c.get("lon")
                    if clat is None or clon is None:
                        continue
                    nm = (e.get("tags", {}) or {}).get("name")
                    if nm:
                        try:
                            d = haversine(float(lat), float(lon), float(clat), float(clon))
                        except Exception:
                            d = 9e9
                        out.append({"name": nm, "lat": float(clat), "lon": float(clon), "_d": d})

                # è·é›¢æ’åº + æˆªæ–·ï¼Œé¿å…è¨˜æ†¶é«”æš´è¡
                if out:
                    out.sort(key=lambda x: x["_d"])
                    # ä½¿ç”¨å…¨åŸŸ/ENV çš„ ENRICH_MAX_ITEMSï¼ˆè‹¥ç„¡å‰‡é è¨­ 60ï¼‰
                    max_items = globals().get("ENRICH_MAX_ITEMS", None)
                    if max_items is None:
                        try:
                            max_items = int(os.getenv("ENRICH_MAX_ITEMS", "60"))
                        except Exception:
                            max_items = 60
                    out = out[:max_items]
                    for o in out:
                        o.pop("_d", None)

                _ENRICH_CACHE.set(key, (now, out))
                return out
        except Exception:
            continue

    _ENRICH_CACHE.set(key, (now, []))
    return []

# === å¯æ‰¾æ€§åˆ†æ•¸ + æ’åº ===
def _findability_bonus(t):
    b = 0.0
    if t.get("place_hint"): b += 0.5
    if t.get("floor_hint"): b += 0.3
    return b

def sort_toilets(toilets):
    toilets.sort(key=lambda x: (int(x.get("distance", 1e9)), -_findability_bonus(x)))
    return toilets

# === åˆå§‹åŒ– Google Sheetsï¼ˆåŒ… SafeWSï¼›å…¶é¤˜ä¸è®Šï¼‰ ===
def init_gsheet():
    global gc, worksheet, feedback_sheet, consent_ws, status_ws
    try:
        if not GSHEET_CREDENTIALS_JSON:
            logging.critical("âŒ ç¼ºå°‘ GSHEET_CREDENTIALS_JSON")
            return  # ä¸ raiseï¼Œè®“æœå‹™å…ˆæ´»è‘—
        creds_dict = json.loads(GSHEET_CREDENTIALS_JSON)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, GSHEET_SCOPE)
        gc = gspread.authorize(creds)

        worksheet_raw = gc.open_by_key(TOILET_SPREADSHEET_ID).sheet1
        fb_spread = gc.open_by_key(FEEDBACK_SPREADSHEET_ID)
        feedback_raw = fb_spread.sheet1

        try:
            consent_raw = fb_spread.worksheet(CONSENT_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            consent_raw = fb_spread.add_worksheet(title=CONSENT_SHEET_TITLE, rows=1000, cols=10)
            consent_raw.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])

        worksheet = SafeWS(worksheet_raw, TOILET_SPREADSHEET_ID, worksheet_raw.title)
        feedback_sheet = SafeWS(feedback_raw, FEEDBACK_SPREADSHEET_ID, feedback_raw.title)
        consent_ws = SafeWS(consent_raw, FEEDBACK_SPREADSHEET_ID, consent_raw.title)
        
        try:
            status_raw = fb_spread.worksheet(STATUS_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            status_raw = fb_spread.add_worksheet(title=STATUS_SHEET_TITLE, rows=1000, cols=10)
            status_raw.update("A1:G1", [["lat","lon","status","user_id","display_name","note","timestamp"]])

        status_ws = SafeWS(status_raw, FEEDBACK_SPREADSHEET_ID, status_raw.title)

        logging.info("âœ… Sheets åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logging.critical(f"âŒ Sheets åˆå§‹åŒ–å¤±æ•—ï¼ˆæ”¹ç‚ºå»¶å¾Œå†è©¦ï¼‰: {e}")
        return

def _ensure_sheets_ready():
    if any(x is None for x in (worksheet, feedback_sheet, consent_ws)):
        try:
            init_gsheet()
        except Exception:
            # ä¿æŒéœé»˜ï¼Œå‘¼å«ç«¯è¦è‡ªå·±å®¹éŒ¯ï¼ˆä¾‹å¦‚å›ç©ºçµæœ / å„ªé›…é™ç´šï¼‰
            pass

init_gsheet()

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
TOILET_REQUIRED_HEADER = [
    "user_id", "name", "address", "lat", "lon",
    "level", "floor_hint", "entrance_hint", "access_note", "open_hours",
    "timestamp"
]

def ensure_toilet_sheet_header(ws):
    _ensure_sheets_ready()
    if ws is None:
        return TOILET_REQUIRED_HEADER[:]
    try:
        header = ws.row_values(1) or []
        if not header:
            ws.update("A1", [TOILET_REQUIRED_HEADER])
            return TOILET_REQUIRED_HEADER[:]

        changed = False
        for col in TOILET_REQUIRED_HEADER:
            if col not in header:
                header.append(col)
                changed = True
        if changed:
            ws.update("A1", [header])
        return header
    except Exception as e:
        logging.error(f"ensure_toilet_sheet_header å¤±æ•—ï¼š{e}")
        return header if 'header' in locals() and header else TOILET_REQUIRED_HEADER[:]

# === è¨ˆç®—è·é›¢ ===
def haversine(lat1, lon1, lat2, lon2):
    try:
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
        return 2 * asin(sqrt(a)) * 6371000  # m
    except Exception as e:
        logging.error(f"è¨ˆç®—è·é›¢å¤±æ•—: {e}")
        return 0

# === é˜²é‡è¤‡ ===
DEDUPE_WINDOW = int(os.getenv("DEDUPE_WINDOW", "10"))
_RECENT_EVENTS = {}

def is_duplicate_and_mark(key: str, window: int = DEDUPE_WINDOW) -> bool:
    now = time.time()
    ts = _RECENT_EVENTS.get(key)
    if ts is not None and (now - ts) < window:
        logging.info(f"ğŸ” skip duplicate: {key}")
        return True
    _RECENT_EVENTS[key] = now
    if len(_RECENT_EVENTS) > 5000 or (len(_RECENT_EVENTS) > 1000):
        for k, tstamp in list(_RECENT_EVENTS.items()):
            if now - tstamp > window:
                _RECENT_EVENTS.pop(k, None)
    return False

def is_redelivery(event) -> bool:
    try:
        dc = getattr(event, "delivery_context", None)
        return bool(getattr(dc, "is_redelivery", False))
    except Exception:
        return False

LINE_REPLY_MAX = 5

def safe_reply(event, messages):
    try:
        tok = event.reply_token
        if _is_token_used(tok):
            logging.warning("[safe_reply] duplicate reply_token detected; skip sending.")
            return

        # âœ… æœ€å¤š 5 å‰‡ï¼Œå¤šçš„ç æ‰ï¼ˆæˆ–è‡ªè¡Œæ”¹æˆåˆä½µæ–‡å­—ï¼‰
        if isinstance(messages, list) and len(messages) > LINE_REPLY_MAX:
            logging.warning(f"[safe_reply] messages too many ({len(messages)}), truncating to {LINE_REPLY_MAX}.")
            messages = messages[:LINE_REPLY_MAX]

        line_bot_api.reply_message(tok, messages)
        _mark_token_used(tok)

    except LineBotApiError as e:
        # è§£æéŒ¯èª¤è¨Šæ¯
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)

        # é‡é€ï¼ˆredeliveryï¼‰ä¸€å¾‹ä¸å›è¦†ï¼ˆé¿å…é‡è¤‡ï¼‰
        if is_redelivery(event):
            logging.warning(f"[safe_reply] redelivery detected; skip. err={msg_txt}")
            return

        # reply_token ç„¡æ•ˆæˆ–å·²éæœŸ â†’ ä¸å† fallback åˆ° pushï¼ˆé¿å…ç‹‚åˆ·ï¼‰
        if "Invalid reply token" in msg_txt:
            logging.warning(f"[safe_reply] invalid reply token; skip. err={msg_txt}")
            return

        # å…¶ä»–éŒ¯èª¤åªè¨˜éŒ„
        logging.warning(f"[safe_reply] reply_message failed (no push). err={msg_txt}")

# === æ›´ç²¾æº–çš„é˜²é‡è¤‡ï¼ˆæ–°ï¼‰ ===
_DEDUPE_LOCK = threading.Lock()

# äº‹ä»¶é¡å‹å°ˆå±¬æ™‚é–“çª—ï¼ˆç§’ï¼‰â€” å¯ç”¨ç’°å¢ƒè®Šæ•¸èª¿æ•´
TEXT_DEDUPE_WINDOW = int(os.getenv("TEXT_DEDUPE_WINDOW", "6"))
LOC_DEDUPE_WINDOW  = int(os.getenv("LOC_DEDUPE_WINDOW",  "3"))
PB_DEDUPE_WINDOW   = int(os.getenv("PB_DEDUPE_WINDOW",   "6"))

# å®šä½äº‹ä»¶çŸ­æ™‚é–“é‡è¤‡çš„è·é›¢é–¾å€¼ï¼ˆå…¬å°ºï¼‰
LOC_DEDUPE_DISTANCE_M = float(os.getenv("LOC_DEDUPE_DISTANCE_M", "8"))

# æœ€è¿‘è™•ç†äº‹ä»¶æ™‚é–“ç´¢å¼•
_RECENT_EVENTS = getattr(globals(), "_RECENT_EVENTS", {})  # è‹¥å‰é¢å·²æœ‰åŒå dictï¼Œæ²¿ç”¨

def _now():
    return time.time()

def _purge_expired(now_ts: float):
    """è¼•é‡æ¸…ç†ï¼šç§»é™¤ 10 ç§’å‰çš„èˆŠè¨˜éŒ„ï¼Œé¿å… dict ç„¡é™æˆé•·"""
    cutoff = now_ts - 10.0
    for k, ts in list(_RECENT_EVENTS.items()):
        if ts < cutoff:
            _RECENT_EVENTS.pop(k, None)

def _event_type_and_key(event):
    """å›å‚³ (etype, key, window_sec)ï¼Œå„ªå…ˆä½¿ç”¨ LINE message.idï¼ˆè‹¥æœ‰ï¼‰"""
    mid = None
    try:
        mid = getattr(getattr(event, "message", None), "id", None)
    except Exception:
        pass

    if isinstance(getattr(event, "message", None), TextMessage):
        etype = "text"
        window = TEXT_DEDUPE_WINDOW
        base = f"text|{event.source.user_id}|{(event.message.text or '').strip().lower()}"
        key = f"mid:{mid}" if mid else base
        return etype, key, window

    if isinstance(getattr(event, "message", None), LocationMessage):
        etype = "loc"
        window = LOC_DEDUPE_WINDOW
        lat = getattr(event.message, "latitude", None)
        lon = getattr(event.message, "longitude", None)
        base = f"loc|{event.source.user_id}|{norm_coord(lat)}:{norm_coord(lon)}"
        key = f"mid:{mid}" if mid else base
        return etype, key, window

    # Postbackï¼ˆæ²’æœ‰ messageï¼‰
    etype = "pb"
    window = PB_DEDUPE_WINDOW
    data = getattr(getattr(event, "postback", None), "data", "")
    key = f"pb|{event.source.user_id}|{data}"
    return etype, key, window

def is_duplicate_and_mark_event(event) -> bool:
    now_ts = _now()
    etype, key, window = _event_type_and_key(event)

    # ç‚º Location åŠ ä¸Šã€Œè·é›¢ + æ™‚é–“ã€è¦å‰‡
    if etype == "loc":
        try:
            uid = event.source.user_id
            lat = float(event.message.latitude)
            lon = float(event.message.longitude)
            last = get_user_location(uid)
        except Exception:
            last = None
        else:
            if last:
                try:
                    d = haversine(lat, lon, float(last[0]), float(last[1]))
                except Exception:
                    d = 1e9
                with _DEDUPE_LOCK:
                    last_ts = _RECENT_EVENTS.get(f"loc_ts|{uid}", 0.0)
                    if (now_ts - last_ts) < LOC_DEDUPE_WINDOW and d <= LOC_DEDUPE_DISTANCE_M:
                        logging.info(f"ğŸ” skip duplicate loc: uid={uid} d={int(d)}m Î”t={round(now_ts-last_ts,2)}s")
                        return True
                    _RECENT_EVENTS[f"loc_ts|{uid}"] = now_ts  # æ›´æ–°æœ€å¾Œå®šä½æ™‚é–“

    # ä¸€èˆ¬è·¯å¾‘ï¼škey + window
    with _DEDUPE_LOCK:
        last_ts = _RECENT_EVENTS.get(key)
        if last_ts is not None and (now_ts - last_ts) < window:
            logging.info(f"ğŸ” skip duplicate {etype}: key={key}")
            return True
        _RECENT_EVENTS[key] = now_ts
        _purge_expired(now_ts)

    return False

def _too_old_to_reply(event, limit_seconds=55):
    try:
        evt_ms = int(getattr(event, "timestamp", 0))  # æ¯«ç§’
        if evt_ms <= 0:
            return False
        now_ms = int(time.time() * 1000)
        return (now_ms - evt_ms) > (limit_seconds * 1000)
    except Exception:
        return False

def reply_only(event, messages):
    try:
        line_bot_api.reply_message(event.reply_token, messages)
    except LineBotApiError as e:
        msg_txt = ""
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)
        logging.warning(f"reply_message å¤±æ•—ï¼ˆä¸åš pushï¼‰ï¼š{msg_txt}")
    except Exception as ex:
        logging.error(f"reply_only åŸ·è¡ŒéŒ¯èª¤ï¼š{ex}")

# === åŒæ„å·¥å…· ===
def _booly(v):
    s = str(v).strip().lower()
    return s in ["1", "true", "yes", "y", "åŒæ„"]

# ï¼ˆå¯é¸å¾®å„ªåŒ–ï¼‰æœ¬æ©ŸåŒæ„å¿«å–ï¼ŒTTL é è¨­ 10 åˆ†é˜ï¼›å¤±æ•—æ™‚ç•¶æœªåŒæ„ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰
_consent_cache = {}   # user_id -> (ts, bool)
_CONSENT_TTL = int(os.getenv("CONSENT_TTL_SEC", "600"))

def has_consented(user_id: str) -> bool:
    _ensure_sheets_ready()
    if not user_id or consent_ws is None:
        return False
    try:
        if not user_id or consent_ws is None:
            return False
        now = time.time()
        hit = _consent_cache.get(user_id)
        if hit and (now - hit[0] < _CONSENT_TTL):
            return hit[1]

        rows = consent_ws.get_all_values()
        if not rows or len(rows) < 2:
            _consent_cache[user_id] = (now, False)
            return False
        header = rows[0]; data = rows[1:]
        try:
            i_uid = header.index("user_id")
            i_ag  = header.index("agreed")
        except ValueError:
            _consent_cache[user_id] = (now, False)
            return False
        ok = False
        for r in data:
            if len(r) <= max(i_uid, i_ag):
                continue
            if (r[i_uid] or "").strip() == user_id and _booly(r[i_ag]):
                ok = True
                break
        _consent_cache[user_id] = (now, ok)
        return ok
    except Exception as e:
        logging.warning(f"æŸ¥è©¢åŒæ„å¤±æ•—: {e}")
        return False

def upsert_consent(user_id: str, agreed: bool, display_name: str, source_type: str, ua: str, ts_iso: str):
    _ensure_sheets_ready()
    if consent_ws is None:
        return False
    try:
        rows = consent_ws.get_all_values()
        if not rows:
            consent_ws.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])
            rows = [["user_id","agreed","display_name","source_type","ua","timestamp"]]
        header = rows[0]; data = rows[1:]

        idx = {h:i for i,h in enumerate(header)}
        for k in ["user_id","agreed","display_name","source_type","ua","timestamp"]:
            if k not in idx:
                header.append(k); idx[k] = len(header)-1
        if len(header) != len(rows[0]):
            consent_ws.update("A1", [header])

        row_to_update = None
        for i, r in enumerate(data, start=2):
            if len(r) > idx["user_id"] and (r[idx["user_id"]] or "").strip() == user_id:
                row_to_update = i
                break

        row_values = [""] * len(header)
        row_values[idx["user_id"]] = user_id or ""
        row_values[idx["agreed"]] = "true" if agreed else "false"
        row_values[idx["display_name"]] = display_name or ""
        row_values[idx["source_type"]] = source_type or ""
        row_values[idx["ua"]] = ua or ""
        row_values[idx["timestamp"]] = ts_iso or datetime.utcnow().isoformat()

        if row_to_update:
            consent_ws.update(f"A{row_to_update}", [row_values])
        else:
            consent_ws.append_row(row_values, value_input_option="USER_ENTERED")
        # æ›´æ–°æœ¬æ©Ÿå¿«å–
        _consent_cache[user_id] = (time.time(), bool(agreed))
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥/æ›´æ–°åŒæ„å¤±æ•—: {e}")
        return False

def ensure_consent_or_prompt(user_id: str):
    if has_consented(user_id):
        return None
    tip = (
        "ğŸ›¡ï¸ ä½¿ç”¨å‰è«‹å…ˆå®ŒæˆåŒæ„ï¼š\n"
        f"{CONSENT_PAGE_URL}\n\n"
        "è‹¥ä¸åŒæ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡ç„¡æ³•æä¾›ã€‚"
    )
    return TextSendMessage(text=tip)

# === å¾ Google Sheets æŸ¥ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
# è¨­å®š SQLite è³‡æ–™åº«ä½ç½®
CACHE_DB_PATH = "cache.db"

# å»ºç«‹ SQLite é€£ç·š
def create_cache_db():
    if not os.path.exists(CACHE_DB_PATH):
        conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
        cursor = conn.cursor()
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS sheets_cache (
            query_key TEXT PRIMARY KEY,
            data TEXT,
            timestamp REAL
        )
        """)
        conn.commit()
        conn.close()

# === SQLite åƒæ•¸å¼·åŒ–ï¼ˆæ–°å¢ï¼‰ ===
def tune_sqlite_for_concurrency():
    try:
        conn = sqlite3.connect(CACHE_DB_PATH)
        cur = conn.cursor()
        # å•Ÿç”¨ WAL æé«˜å¤šåŸ·è¡Œç·’è®€/å¯«ä¸¦è¡Œèƒ½åŠ›
        cur.execute("PRAGMA journal_mode=WAL;")
        # è¨­å®š busy timeoutï¼ˆæ¯«ç§’ï¼‰ï¼Œé¿å…çŸ­æš«é–è¡çªç›´æ¥æ‹‹éŒ¯
        cur.execute("PRAGMA busy_timeout=3000;")
        conn.commit()
        conn.close()
        logging.info("âœ… SQLite tuned: WAL + busy_timeout")
    except Exception as e:
        logging.warning(f"SQLite tuning skipped: {e}")

# ç¢ºèªå¿«å–æ˜¯å¦æœ‰æ•ˆ
def get_cached_data(query_key, ttl_sec=60*5):
    conn = sqlite3.connect(CACHE_DB_PATH)
    cursor = conn.cursor()
    cursor.execute("SELECT data, timestamp FROM sheets_cache WHERE query_key = ?", (query_key,))
    result = cursor.fetchone()
    conn.close()

    if result:
        data, timestamp = result
        if time.time() - timestamp < ttl_sec:
            return json.loads(data)
    return None

# å„²å­˜å¿«å–
def save_cache(query_key, data):
    conn = sqlite3.connect(CACHE_DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
    INSERT OR REPLACE INTO sheets_cache (query_key, data, timestamp)
    VALUES (?, ?, ?)
    """, (query_key, json.dumps(data), time.time()))
    conn.commit()
    conn.close()

# å¿«å–åˆå§‹åŒ–
create_cache_db()
tune_sqlite_for_concurrency()

# æŸ¥è©¢å»æ‰€è³‡æ–™
def query_sheet_toilets(user_lat, user_lon, radius=500):
    _ensure_sheets_ready()
    if worksheet is None:
        return []

    # è®€å–å¯èª¿ä¸Šé™ï¼šé è¨­ 120ï¼ˆå¯ç”¨ SHEET_MAX_ITEMS ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼‰
    try:
        SHEET_MAX_ITEMS = int(os.getenv("SHEET_MAX_ITEMS", "120"))
    except Exception:
        SHEET_MAX_ITEMS = 120

    query_key = f"{user_lat},{user_lon},{radius}"
    cached_data = get_cached_data(query_key)
    if cached_data:
        return cached_data

    toilets = []
    try:
        header, data = _get_header_and_tail(worksheet, MAX_SHEET_ROWS)
        if not header or not data:
            save_cache(query_key, toilets)
            return toilets

        idx = _toilet_sheet_indices(header)

        # è‹¥å¿…å‚™æ¬„ä½ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›ï¼ˆé¿å… index éŒ¯èª¤ï¼‰
        if idx.get("lat") is None or idx.get("lon") is None:
            logging.warning("query_sheet_toilets: sheet header lacks lat/lon columns")
            save_cache(query_key, toilets)
            return toilets

        for row in data:
            # åŸºæœ¬æ¬„ä½æª¢æŸ¥
            if len(row) <= max(
                v for k, v in idx.items() if v is not None and k in ("name", "address", "lat", "lon")
            ):
                continue

            name = (row[idx["name"]] if idx["name"] is not None and len(row) > idx["name"] else "").strip() or "ç„¡åç¨±"
            address = (row[idx["address"]] if idx["address"] is not None and len(row) > idx["address"] else "").strip()

            try:
                t_lat = float(row[idx["lat"]]) if len(row) > idx["lat"] else None
                t_lon = float(row[idx["lon"]]) if len(row) > idx["lon"] else None
            except Exception:
                t_lat = t_lon = None
            if t_lat is None or t_lon is None:
                continue

            dist = haversine(user_lat, user_lon, t_lat, t_lon)
            if dist > radius:
                continue

            level         = (row[idx["level"]] if idx["level"] is not None and len(row) > idx["level"] else "").strip()
            floor_hint_ws = (row[idx["floor_hint"]] if idx["floor_hint"] is not None and len(row) > idx["floor_hint"] else "").strip()
            open_hours    = (row[idx["open_hours"]] if idx["open_hours"] is not None and len(row) > idx["open_hours"] else "").strip()

            auto_floor = _floor_from_name(name)
            floor_hint = floor_hint_ws or level or auto_floor

            toilets.append({
                "name": name,
                "lat": float(norm_coord(t_lat)),
                "lon": float(norm_coord(t_lon)),
                "address": address,
                "distance": dist,
                "type": "sheet",
                "level": level,
                "floor_hint": floor_hint,
                "open_hours": open_hours,
            })

        # è·é›¢æ’åº + æˆªæ–·ï¼ˆå…ˆæˆªæ–·å†å¯«å¿«å–ï¼Œç¸®å°å¿«å–é«”ç©ï¼‰
        toilets.sort(key=lambda x: x["distance"])
        if len(toilets) > SHEET_MAX_ITEMS:
            toilets = toilets[:SHEET_MAX_ITEMS]

    except Exception as e:
        logging.error(f"è®€å– Google Sheets å»æ‰€ä¸»è³‡æ–™éŒ¯èª¤: {e}")

    save_cache(query_key, toilets)
    return toilets

# === OSM Overpass ===
def query_overpass_toilets(lat, lon, radius=500):
    overall_deadline = time.time() + 8.0
    def _left():
        return max(1.0, overall_deadline - time.time())

    ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
    headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]

    # è®€å–é™åˆ¶å€¼ï¼ˆæœ‰é è¨­ï¼Œä¸è¨­ç’°å¢ƒè®Šæ•¸ä¹Ÿèƒ½è·‘ï¼‰
    try:
        max_items = int(os.getenv("OVERPASS_MAX_ITEMS", "80"))
    except Exception:
        max_items = 80
    try:
        enrich_on = int(os.getenv("ENRICH_ENABLE", "0")) == 1
    except Exception:
        enrich_on = False

    # å…ˆå°åŠå¾‘å†åŸåŠå¾‘ï¼Œç¸®çŸ­æ™‚é–“ & æ¸›å°‘çµæœæ•¸
    for r in (300, radius):
        if time.time() >= overall_deadline:
            break

        query = f"""
        [out:json][timeout:25];
        (
          node["amenity"="toilets"](around:{r},{lat},{lon});
          way["amenity"="toilets"](around:{r},{lat},{lon});
          relation["amenity"="toilets"](around:{r},{lat},{lon});
        );
        out center tags;
        """

        last_err = None
        for idx, url in enumerate(endpoints):
            if time.time() >= overall_deadline:
                break
            try:
                resp = requests.post(url, data=query, headers=headers, timeout=min(8, _left()))
                ctype = (resp.headers.get("Content-Type") or "").lower()
                if resp.status_code != 200 or "json" not in ctype:
                    last_err = RuntimeError(f"overpass non-json {resp.status_code}")
                    continue

                data = resp.json()
                elements = data.get("elements", [])

                toilets = []
                # å…ˆå° elements é€²è¡Œã€Œå¿«é€Ÿè·é›¢è¿‘ä¼¼ã€æˆªæ–·ï¼šæœ€å¤šè™•ç† 4 * max_items ç­†
                # ï¼ˆway/relation è§£æ center å‰ç„¡æ³•ç²¾ç®—è·é›¢ï¼Œå…ˆé™å®šé‡ï¼‰
                hard_cap = max(40, max_items * 4)
                processed = 0

                for elem in elements:
                    if processed >= hard_cap:
                        break
                    processed += 1

                    if "center" in elem:
                        t_lat, t_lon = elem["center"].get("lat"), elem["center"].get("lon")
                    elif elem.get("type") == "node":
                        t_lat, t_lon = elem.get("lat"), elem.get("lon")
                    else:
                        continue
                    if t_lat is None or t_lon is None:
                        continue

                    tags = elem.get("tags", {}) or {}
                    name = tags.get("name", "ç„¡åç¨±")
                    address = tags.get("addr:full", "") or tags.get("addr:street", "") or ""

                    # æ¨“å±¤/ä½ç½®æ¨æ–·
                    floor_hint = _floor_from_tags(tags) or _floor_from_name(name)

                    # ä¸€æ¬¡è¨ˆç®—è·é›¢ï¼Œå¾ŒçºŒæ’åº/æˆªæ–·é‡ç”¨
                    try:
                        dist = haversine(float(lat), float(lon), float(t_lat), float(t_lon))
                    except Exception:
                        dist = 9e9

                    toilets.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": address,
                        "distance": dist,
                        "type": "osm",
                        "floor_hint": floor_hint,
                        # é™„åŠ æ¬„ä½
                        "level": tags.get("level") or tags.get("addr:floor") or "",
                        "open_hours": tags.get("opening_hours") or "",
                        "entrance_hint": tags.get("entrance") or "",
                    })

                # è‹¥ç„¡çµæœï¼Œæ›ä¸‹å€‹ endpoint/åŠå¾‘
                if not toilets:
                    continue

                # enrich åªåœ¨é–‹å•Ÿæ™‚åŸ·è¡Œï¼Œè€Œä¸”åªç‚ºã€Œæœªå‘½åã€è²¼è¿‘çš„é»è£œä¸Š place_hint
                if enrich_on:
                    try:
                        nearby_named = enrich_nearby_places(lat, lon, radius=500)
                        if nearby_named:
                            for t in toilets:
                                if (not t.get("name")) or t["name"] == "ç„¡åç¨±":
                                    best = None; best_d = 61.0
                                    for p in nearby_named:
                                        d = haversine(t["lat"], t["lon"], p["lat"], p["lon"])
                                        if d < best_d:
                                            best_d = d; best = p
                                    if best:
                                        t["place_hint"] = best["name"]
                    except Exception:
                        pass

                # è·é›¢æ’åº + æˆªæ–·ï¼ˆé›™é‡ä¿éšªï¼Œç¢ºä¿å›å‚³ä¸Šé™ï¼‰
                toilets.sort(key=lambda x: x["distance"])
                if len(toilets) > max_items:
                    toilets = toilets[:max_items]
                return toilets

            except Exception as e:
                last_err = e
                logging.warning(f"Overpass API æŸ¥è©¢å¤±æ•—ï¼ˆendpoint {idx}ï¼‰: {e}")
        logging.warning(f"Overpass åŠå¾‘ {r} å¤±æ•—ï¼š{last_err}")
    return []

# === è®€å– public_toilets.csv ===
def query_public_csv_toilets(user_lat, user_lon, radius=500):
    pts = []
    if not os.path.exists(TOILETS_FILE_PATH):
        return pts
    try:
        with open(TOILETS_FILE_PATH, "r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    t_lat = float(row.get("latitude"))
                    t_lon = float(row.get("longitude"))
                except Exception:
                    continue
                dist = haversine(user_lat, user_lon, t_lat, t_lon)
                if dist <= radius:
                    name = (row.get("name") or "ç„¡åç¨±").strip()
                    addr = (row.get("address") or "").strip()
                    floor_hint = _floor_from_name(name)
                    pts.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": addr,
                        "distance": dist,
                        "type": "public_csv",
                        "grade": row.get("grade", ""),
                        "category": row.get("type2", ""),
                        "floor_hint": floor_hint
                    })
    except Exception as e:
        logging.error(f"è®€ public_toilets.csv å¤±æ•—ï¼š{e}")
    return sorted(pts, key=lambda x: x["distance"])

# === åˆä½µ + å»é‡ ===
def _merge_and_dedupe_lists(*lists, dist_th=35, name_sim_th=0.55):
    all_pts = []
    for l in lists:
        if l: all_pts.extend(l)
    all_pts.sort(key=lambda x: x["distance"])

    merged = []
    for p in all_pts:
        dup = False
        for q in merged:
            try:
                near = haversine(p["lat"], p["lon"], q["lat"], q["lon"]) <= dist_th
            except Exception:
                near = False
            sim = SequenceMatcher(None, (p.get("name") or "").lower(), (q.get("name") or "").lower()).ratio()
            if near and sim >= name_sim_th:
                dup = True
                break
        if not dup:
            merged.append(p)
    return merged

# === æœ€æ„›ç®¡ç† ===
def add_to_favorites(uid, toilet):
    try:
        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        with open(FAVORITES_FILE_PATH, "a", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([uid, toilet['name'], lat_s, lon_s, toilet.get('address','')])
    except Exception as e:
        logging.error(f"åŠ å…¥æœ€æ„›å¤±æ•—: {e}")

def remove_from_favorites(uid, name, lat, lon):
    try:
        lat_s = norm_coord(lat)
        lon_s = norm_coord(lon)
        rows = []
        changed = False
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    rows.append(row); continue
                if not (row[0] == uid and row[1] == name and row[2] == lat_s and row[3] == lon_s):
                    rows.append(row)
                else:
                    changed = True
        with open(FAVORITES_FILE_PATH, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerows(rows)
        return changed
    except Exception as e:
        logging.error(f"ç§»é™¤æœ€æ„›å¤±æ•—: {e}")
        return False

def get_user_favorites(uid):
    favs = []
    try:
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    continue
                if row[0] == uid:
                    favs.append({
                        "name": row[1],
                        "lat": float(row[2]),
                        "lon": float(row[3]),
                        "address": row[4],
                        "distance": 0,
                        "type": "favorite"
                    })
    except Exception as e:
        logging.error(f"è®€å–æœ€æ„›å¤±æ•—: {e}")
    return favs

# === åœ°å€è½‰ç¶“ç·¯åº¦ ===
def geocode_address(address):
    try:
        ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
        url = f"https://nominatim.openstreetmap.org/search?format=json&q={quote(address)}"
        headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
        resp = requests.get(url, headers=headers, timeout=10)
        data = resp.json()
        if resp.status_code == 200 and data:
            return float(data[0]['lat']), float(data[0]['lon'])
    except Exception as e:
        logging.error(f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: {e}")
    return None, None

# === é™„è¿‘å»æ‰€ API ===
@app.route("/nearby_toilets", methods=["GET"])
def nearby_toilets():
    user_lat = request.args.get('lat')
    user_lon = request.args.get('lon')
    if not user_lat or not user_lon:
        return {"error": "ç¼ºå°‘ä½ç½®åƒæ•¸"}, 400

    user_lat = float(user_lat)
    user_lon = float(user_lon)

    public_csv_toilets = query_public_csv_toilets(user_lat, user_lon, radius=500) or []
    sheet_toilets = query_sheet_toilets(user_lat, user_lon, radius=500) or []
    osm_toilets = query_overpass_toilets(user_lat, user_lon, radius=500) or []

    all_toilets = _merge_and_dedupe_lists(public_csv_toilets, sheet_toilets, osm_toilets)
    sort_toilets(all_toilets)

    if not all_toilets:
        return {"message": "é™„è¿‘æ‰¾ä¸åˆ°å»æ‰€"}, 404
    return {"toilets": all_toilets}, 200

# === é¡¯ç¤ºå›é¥‹è¡¨å–® ===
@app.route("/feedback_form/<toilet_name>/", defaults={'address': ''})
@app.route("/feedback_form/<toilet_name>/<path:address>")
def feedback_form(toilet_name, address):
    address = address or request.args.get("address", "")
    return render_template(
        "feedback_form.html",
        toilet_name=toilet_name,
        address=address,
        lat=request.args.get("lat", ""),
        lon=request.args.get("lon", "")
    )

# === å°é½Š ===
def _norm_h(s):
    return (s or "").strip().lower()

def _find_idx(header, candidates):
    hmap = {_norm_h(h): i for i, h in enumerate(header)}
    for c in candidates:
        if _norm_h(c) in hmap:
            return hmap[_norm_h(c)]
    return None

def _feedback_indices(header):
    return {
        "name": _find_idx(header, ["åç¨±", "name", "toilet_name"]),
        "address": _find_idx(header, ["åœ°å€", "address"]),
        "rating": _find_idx(header, ["æ¸…æ½”åº¦è©•åˆ†", "æ¸…æ½”è©•åˆ†", "rating", "score"]),
        "paper": _find_idx(header, ["æ˜¯å¦æœ‰è¡›ç”Ÿç´™", "toilet_paper", "è¡›ç”Ÿç´™", "ç´™"]),
        "access": _find_idx(header, ["æ˜¯å¦æœ‰ç„¡éšœç¤™è¨­æ–½", "accessibility", "ç„¡éšœç¤™"]),
        "time": _find_idx(header, ["ä½¿ç”¨æ™‚é–“", "time_of_use", "time"]),
        "comment": _find_idx(header, ["ç•™è¨€", "comment", "å‚™è¨»"]),
        "pred": _find_idx(header, ["é æ¸¬åˆ†æ•¸", "é æ¸¬è©•åˆ†", "cleanliness_score", "predicted_score"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["created_at", "å»ºç«‹æ™‚é–“", "æ™‚é–“", "timestamp"]),
        "floor": _find_idx(header, ["floor", "æ¨“å±¤", "floor_hint", "level", "ä½ç½®æ¨“å±¤"]),
    }

def _toilet_sheet_indices(header):
    return {
        "user_id": _find_idx(header, ["user_id", "uid", "ä½¿ç”¨è€…"]),
        "name": _find_idx(header, ["name", "åç¨±"]),
        "address": _find_idx(header, ["address", "åœ°å€"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["timestamp", "created_at", "å»ºç«‹æ™‚é–“"]),
        "level": _find_idx(header, ["level", "æ¨“å±¤"]),
        "floor_hint": _find_idx(header, ["floor_hint", "ä½ç½®æ¨“å±¤", "æ¨“å±¤èªªæ˜"]),
        "open_hours": _find_idx(header, ["open_hours", "é–‹æ”¾æ™‚é–“", "ç‡Ÿæ¥­æ™‚é–“"]),
    }

# === æ¸…æ½”åº¦é æ¸¬ ===
def expected_from_feats(feats):
    try:
        if not feats or cleanliness_model is None:
            return None
        if pd is not None:
            df = pd.DataFrame(feats, columns=["rating","toilet_paper","accessibility"])
            probs = cleanliness_model.predict_proba(df)
        else:
            probs = cleanliness_model.predict_proba(feats)

        try:
            classes_enc = cleanliness_model.classes_
            labels = label_encoder.inverse_transform(classes_enc)
            labels = [float(x) for x in labels]
        except Exception:
            labels = [float(c) + 1.0 for c in cleanliness_model.classes_]

        exps = [sum(float(p)*float(l) for p, l in zip(p_row, labels)) for p_row in probs]
        return round(sum(exps)/len(exps), 2) if exps else None
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦é æ¸¬éŒ¯èª¤: {e}")
        return None

def _simple_score(rr, paper, acc):
    try:
        base = 1.0 + 4.0 * (int(rr) - 1) / 9.0
    except Exception:
        return None
    bonus = (0.25 if (paper == "æœ‰") else 0.0) + (0.25 if (acc == "æœ‰") else 0.0)
    score = base + bonus
    if score < 1.0: score = 1.0
    if score > 5.0: score = 5.0
    return round(score, 2)

def _pred_from_row(r, idx):
    paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
    access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}

    rr = None
    if idx["rating"] is not None and len(r) > idx["rating"]:
        try:
            rr = int((r[idx["rating"]] or "").strip())
        except:
            rr = None
    pp = (r[idx["paper"]] or "").strip() if idx["paper"] is not None and len(r) > idx["paper"] else "æ²’æ³¨æ„"
    aa = (r[idx["access"]] or "").strip() if idx["access"] is not None and len(r) > idx["access"] else "æ²’æ³¨æ„"

    score = None
    if rr is not None and cleanliness_model is not None:
        try:
            feat = [rr, paper_map.get(pp, 0), access_map.get(aa, 0)]
            score = expected_from_feats([feat])
        except Exception:
            score = None
    if score is None and idx["pred"] is not None and len(r) > idx["pred"]:
        try:
            score = float((r[idx["pred"]] or "").strip())
        except:
            score = None
    if score is None:
        score = _simple_score(rr, pp, aa)
    return (score, rr, pp, aa)

# === å³æ™‚é æ¸¬ / 95% CI ===
def compute_nowcast_ci(lat, lon, k=LAST_N_HISTORY, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return None

    # k ä¸Šé™ï¼Œé¿å…ä¸€æ¬¡åƒå¤ªå¤šåˆ—
    try:
        NOWCAST_MAX_K = int(os.getenv("NOWCAST_MAX_K", "8"))
    except Exception:
        NOWCAST_MAX_K = 8
    if k is None or not isinstance(k, int) or k <= 0:
        k = LAST_N_HISTORY
    k = min(k, NOWCAST_MAX_K)

    # ç›®æ¨™åº§æ¨™è½‰ç‚º floatï¼Œç”¨æ–¼æ¯”è¼ƒ
    try:
        target_lat = float(lat)
        target_lon = float(lon)
    except Exception:
        return None

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return None

        idx = _feedback_indices(header)
        i_lat, i_lon = idx.get("lat"), idx.get("lon")
        if i_lat is None or i_lon is None:
            return None

        def close(a, b):
            try:
                return abs(float(a) - float(b)) <= tol
            except Exception:
                return False

        # åªä¿ç•™åŒåº§æ¨™çš„æœ€è¿‘ k ç­†
        same_rows = []
        for r in data:
            # é•·åº¦æª¢æŸ¥
            if max(i_lat, i_lon) >= len(r):
                continue
            if close(r[i_lat], target_lat) and close(r[i_lon], target_lon):
                same_rows.append(r)
                if len(same_rows) >= k * 3:
                    # å¤šæŠ“ä¸€é»å‚™ç”¨ï¼Œç¨å¾ŒæŒ‰æ™‚é–“å–å‰ k
                    break

        if not same_rows:
            return None

        # è‹¥æœ‰ created æ¬„ä½å°±æŒ‰æ™‚é–“æ–°åˆ°èˆŠæ’ï¼Œå†å–å‰ k ç­†
        i_created = idx.get("created")
        if i_created is not None:
            try:
                same_rows.sort(key=lambda x: (x[i_created] if len(x) > i_created else ""), reverse=True)
            except Exception:
                pass

        recent = same_rows[:k]
        if not recent:
            return None

        # ä¸€æ¬¡èµ°è¨ªï¼ŒåŒæ™‚è¨ˆç®—æ¨¡å‹åˆ†æ•¸èˆ‡å‚™ç”¨ç°¡åŒ–åˆ†æ•¸
        vals_model = []
        vals_simple = []
        for r in recent:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                try:
                    vals_model.append(float(sc))
                except Exception:
                    pass
            # ç°¡åŒ–åˆ†æ•¸éš¨æ‰‹å‚™è‘—ï¼Œé¿å…ä¹‹å¾Œå†è·‘ä¸€æ¬¡
            s2 = _simple_score(rr, pp, aa)
            if isinstance(s2, (int, float)):
                vals_simple.append(float(s2))

        # æ²’æœ‰æ¨¡å‹åˆ†æ•¸å°±ç”¨ç°¡åŒ–åˆ†æ•¸
        vals = vals_model[:] if vals_model else vals_simple[:]
        if not vals:
            return None

        # è‹¥æ¨¡å‹åˆ†æ•¸å…¨ç›¸åŒï¼ˆæ¥µå¸¸è¦‹æ–¼å°‘é‡æ¨£æœ¬ï¼‰ï¼Œæ”¹ç”¨ç°¡åŒ–åˆ†æ•¸ä»¥æ‰“é–‹åˆ†ä½ˆ
        if vals_model and len(vals_model) >= 2:
            try:
                if max(vals_model) - min(vals_model) < 1e-6 and vals_simple:
                    vals = vals_simple[:]
            except Exception:
                pass

        n = len(vals)
        mean = round(sum(vals) / n, 2)

        if n == 1:
            return {"mean": mean, "lower": mean, "upper": mean, "n": 1}

        try:
            s = statistics.stdev(vals)
        except statistics.StatisticsError:
            s = 0.0

        se = s / (n ** 0.5)
        lower = max(1.0, round(mean - 1.96 * se, 2))
        upper = min(5.0, round(mean + 1.96 * se, 2))
        return {"mean": mean, "lower": lower, "upper": upper, "n": n}

    except Exception as e:
        logging.error(f"âŒ compute_nowcast_ci å¤±æ•—: {e}")
        return None

# === Nowcast API ===
@app.route("/get_nowcast_by_coord/<lat>/<lon>")
def get_nowcast_by_coord(lat, lon):
    try:
        res = compute_nowcast_ci(lat, lon)
        if not res:
            return {"success": True, "n": 0}, 200
        res["success"] = True
        return res, 200
    except Exception as e:
        logging.error(f"âŒ Nowcast API éŒ¯èª¤: {e}")
        return {"success": False}, 500

# ==== ç‹€æ…‹ï¼šå€™é¸ä¸‰é–“ï¼ˆé  build_nearby_toiletsï¼‰====
@app.route("/api/status_candidates")
def api_status_candidates():
    try:
        lat = float(request.args.get("lat"))
        lon = float(request.args.get("lon"))
    except Exception:
        return {"ok": False, "message": "ç¼ºå°‘æˆ–éŒ¯èª¤çš„åº§æ¨™"}, 400

    try:
        # åŠå¾‘æ”¾å¯¬ä¸€é»ï¼Œæé«˜å‘½ä¸­ç‡ï¼›å·²å…§å»ºå¿«å–/å»é‡/æ’åº
        items = build_nearby_toilets("status", lat, lon, radius=700) or []
        out = []
        for t in items[:3]:
            out.append({
                "title": t.get("name") or t.get("place_hint") or "ï¼ˆæœªå‘½åï¼‰å»æ‰€",
                "address": t.get("address") or "",
                # ç”¨ norm_coordï¼ˆå­—ä¸²ï¼‰è®“ä¹‹å¾Œæ¯”å°è©¦ç®—è¡¨åº§æ¨™æ›´ç©©å®š
                "lat": norm_coord(t["lat"]),
                "lon": norm_coord(t["lon"]),
                "distance": int(t.get("distance", 0))
            })
        return {"ok": True, "candidates": out}, 200
    except Exception as e:
        logging.error(f"/api/status_candidates å¤±æ•—: {e}")
        return {"ok": False, "message": "server error"}, 500


# ==== ç‹€æ…‹ï¼šå›å ±ï¼ˆé  submit_status_update å¯«å…¥ status åˆ†é ï¼‰====
@app.route("/api/status_report", methods=["POST"])
def api_status_report():
    try:
        payload = request.get_json(force=True)
        lat = float(payload["lat"])
        lon = float(payload["lon"])
        status_text = (payload.get("status") or "").strip()
        user_id = (payload.get("user_id") or "").strip()
        display_name = (payload.get("display_name") or "").strip()
        note = (payload.get("note") or "").strip()
    except Exception:
        return {"ok": False, "message": "åƒæ•¸éŒ¯èª¤"}, 400

    # ç™½åå–®æª¢æŸ¥ï¼Œé¿å…é«’è³‡æ–™
    allowed = {"æœ‰äººæ’éšŠ", "ç¼ºè¡›ç”Ÿç´™", "æš«åœä½¿ç”¨", "æ¢å¾©æ­£å¸¸"}
    if status_text not in allowed:
        return {"ok": False, "message": "ä¸æ”¯æ´çš„ç‹€æ…‹"}, 400

    try:
        ok = submit_status_update(lat, lon, status_text, user_id, display_name, note)
        return ({"ok": True}, 200) if ok else ({"ok": False, "message": "å¯«å…¥å¤±æ•—"}, 500)
    except Exception as e:
        logging.error(f"/api/status_report å¯«å…¥å¤±æ•—: {e}")
        return {"ok": False, "message": "server error"}, 500

# === å›é¥‹ ===
@app.route("/submit_feedback", methods=["POST"])
def submit_feedback():
    _ensure_sheets_ready()
    try:
        data = request.form
        name = (data.get("name","") or "").strip()
        address = (data.get("address","") or "").strip()

        lat_raw = data.get("lat","")
        lon_raw = data.get("lon","")
        lat_f, lon_f = _parse_lat_lon(lat_raw, lon_raw)
        if lat_f is None or lon_f is None:
            return "åº§æ¨™æ ¼å¼éŒ¯èª¤", 400
        lat = norm_coord(lat_f)
        lon = norm_coord(lon_f)

        rating = (data.get("rating","") or "").strip()
        toilet_paper = (data.get("toilet_paper","") or "").strip()
        accessibility = (data.get("accessibility","") or "").strip()
        time_of_use = (data.get("time_of_use","") or "").strip()
        comment = (data.get("comment","") or "").strip()
        floor_hint = (data.get("floor_hint","") or "").strip()

        if not all([name, rating, lat, lon]):
            return "ç¼ºå°‘å¿…è¦æ¬„ä½ï¼ˆéœ€è¦ï¼šnameã€ratingã€latã€lonï¼‰", 400

        try:
            r = int(rating)
            if r < 1 or r > 10:
                return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆåœ¨ 1 åˆ° 10 ä¹‹é–“", 400
        except ValueError:
            return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆæ˜¯æ•¸å­—", 400

        if floor_hint and len(floor_hint) < 4:
            return "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—", 400

        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        cur_feat = [r, paper_map.get(toilet_paper, 0), access_map.get(accessibility, 0)]

        hist_feats = []
        try:
            rows = feedback_sheet.get_all_values()
            header = rows[0]; data_rows = rows[1:]
            idx = _feedback_indices(header)

            def close(a, b, tol=1e-6):
                try: return abs(float(a) - float(b)) <= tol
                except: return False

            same_coord = []
            for row in data_rows:
                if idx["lat"] is None or idx["lon"] is None:
                    break
                if len(row) <= max(idx["lat"], idx["lon"]):
                    continue
                if close(row[idx["lat"]], lat) and close(row[idx["lon"]], lon):
                    same_coord.append(row)

            if idx["created"] is not None:
                same_coord.sort(key=lambda x: x[idx["created"]], reverse=True)
            recent = same_coord[:LAST_N_HISTORY]

            if idx["rating"] is not None:
                for row in recent:
                    try:
                        rr = int((row[idx["rating"]] or "").strip())
                    except:
                        continue
                    pp = (row[idx["paper"]] or "").strip() if idx["paper"] is not None else "æ²’æ³¨æ„"
                    aa = (row[idx["access"]] or "").strip() if idx["access"] is not None else "æ²’æ³¨æ„"
                    hist_feats.append([rr, paper_map.get(pp,0), access_map.get(aa,0)])
        except Exception as e:
            logging.warning(f"è®€æ­·å²å›é¥‹å¤±æ•—ï¼Œåƒ…ç”¨å–®ç­†ç‰¹å¾µé æ¸¬ï¼š{e}")

        pred_with_hist = expected_from_feats([cur_feat] + hist_feats) or expected_from_feats([cur_feat]) or "æœªé æ¸¬"

        feedback_sheet.append_row([
            name, address, rating, toilet_paper, accessibility, time_of_use,
            comment, pred_with_hist, lat, lon, datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            floor_hint
        ])

        return redirect(url_for("feedback_form", toilet_name=name, address=address or "") + f"?lat={lat}&lon={lon}")
    except Exception as e:
        logging.error(f"âŒ æäº¤å›é¥‹è¡¨å–®éŒ¯èª¤: {e}")
        return "æäº¤å¤±æ•—", 500

# === è®€åº§æ¨™çš„å›é¥‹æ¸…å–® ===
def get_feedbacks_by_coord(lat, lon, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return []
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return []

        # ğŸ”§ è£œä¸Šé€™è¡Œ
        idx = _feedback_indices(header)

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        out = []
        for r in data:
            if idx["lat"] is None or idx["lon"] is None:
                break
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                def val(key):
                    i = idx[key]
                    return (r[i] if i is not None and len(r) > i else "").strip()
                out.append({
                    "rating": val("rating"),
                    "toilet_paper": val("paper"),
                    "accessibility": val("access"),
                    "time_of_use": val("time"),
                    "comment": safe_html(val("comment")),
                    "cleanliness_score": val("pred"),
                    "created_at": val("created"),
                })
        out.sort(key=lambda d: d.get("created_at", ""), reverse=True)
        return out
    except Exception as e:
        logging.error(f"âŒ è®€å–å›é¥‹åˆ—è¡¨ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return []

# === åº§æ¨™èšåˆçµ±è¨ˆ ===
def get_feedback_summary_by_coord(lat, lon, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return "å°šç„¡å›é¥‹è³‡æ–™"
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        # ğŸ”§ è£œä¸Šé€™è¡Œ
        idx = _feedback_indices(header)

        if idx["lat"] is None or idx["lon"] is None:
            return "ï¼ˆè¡¨é ­ç¼ºå°‘ lat/lon æ¬„ä½ï¼‰"

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched.append(r)

        if not matched:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        scores = []
        comments = []

        for r in matched:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                scores.append(float(sc))
            if pp in paper_counts: paper_counts[pp] += 1
            if aa in access_counts: access_counts[aa] += 1
            if idx["comment"] is not None and len(r) > idx["comment"]:
                c = (r[idx["comment"]] or "").strip()
                if c:
                    comments.append(c)

        avg_score = round(sum(scores) / len(scores), 2) if scores else "æœªé æ¸¬"

        summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\n"
        summary += f"ğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg_score}\n"
        summary += f"ğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰'] >= paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        summary += f"â™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰'] >= access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        if comments:
            # ä½ ç¾åœ¨æ‹¿ comments[-1]ï¼Œå› ç‚º _get_header_and_tail å–å°¾å·´ï¼Œ
            # é€šå¸¸æœ€å¾Œä¸€ç­†å°±æ˜¯æœ€æ–°ï¼Œé€™é‚è¼¯ OKã€‚
            summary += f"ğŸ’¬ æœ€æ–°ç•™è¨€ï¼š{comments[-1]}"
        return summary
    except Exception as e:
        logging.error(f"âŒ æŸ¥è©¢å›é¥‹çµ±è¨ˆï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "è®€å–éŒ¯èª¤"

# === æŒ‡ç¤ºç‡ˆç´¢å¼• ===
_feedback_index_cache = {"ts": 0, "data": {}}
_FEEDBACK_INDEX_TTL = 60

def build_feedback_index():
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {}

    global _feedback_index_cache

    now = time.time()
    # âš ï¸ æ³¨æ„é€™è£¡ç”¨çš„æ˜¯ã€Œæœ‰åº•ç·šã€çš„ TTL è®Šæ•¸
    if (now - _feedback_index_cache["ts"] < _FEEDBACK_INDEX_TTL) and _feedback_index_cache["data"]:
        return _feedback_index_cache["data"]

    # å¯èª¿ï¼šæœ€å¤šèšåˆå¤šå°‘å€‹åº§æ¨™é»ï¼Œé¿å… bucket çˆ†æ‰
    try:
        FEEDBACK_INDEX_MAX_KEYS = int(os.getenv("FEEDBACK_INDEX_MAX_KEYS", "800"))
    except Exception:
        FEEDBACK_INDEX_MAX_KEYS = 800

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            _feedback_index_cache = {"ts": now, "data": {}}
            return {}

        idx = _feedback_indices(header)
        i_lat = idx.get("lat"); i_lon = idx.get("lon")
        if i_lat is None or i_lon is None:
            _feedback_index_cache = {"ts": now, "data": {}}
            return {}
        
        bucket = {}
        for r in data:
            # åŸºæœ¬é•·åº¦æª¢æŸ¥
            if max(i_lat, i_lon) >= len(r):
                continue
            try:
                lat_s = norm_coord(r[i_lat])
                lon_s = norm_coord(r[i_lon])
            except Exception:
                continue
            if not lat_s or not lon_s:
                continue

            key = (lat_s, lon_s)

            # æ§åˆ¶ key æ•¸é‡ä¸Šé™ï¼šå·²æœ‰çš„å¯ä»¥ç´¯åŠ ï¼Œæ–° key è¶…éä¸Šé™å°±è·³é
            if key not in bucket and len(bucket) >= FEEDBACK_INDEX_MAX_KEYS:
                continue

            rec = bucket.setdefault(
                key,
                {"paper_has": 0, "paper_no": 0, "acc_has": 0, "acc_no": 0, "sum": 0.0, "n": 0}
            )

            sc, rr, pp, aa = _pred_from_row(r, idx)

            # ç´™å·¾ï¼ç„¡éšœç¤™ç´¯è¨ˆ
            if pp == "æœ‰":
                rec["paper_has"] += 1
            elif pp == "æ²’æœ‰":
                rec["paper_no"] += 1

            if aa == "æœ‰":
                rec["acc_has"] += 1
            elif aa == "æ²’æœ‰":
                rec["acc_no"] += 1

            # åˆ†æ•¸ç´¯è¨ˆ
            if isinstance(sc, (int, float)):
                try:
                    rec["sum"] += float(sc)
                    rec["n"] += 1
                except Exception:
                    pass

        # è¼¸å‡º
        out = {}
        for key, v in bucket.items():
            paper_total = v["paper_has"] + v["paper_no"]
            access_total = v["acc_has"] + v["acc_no"]
            paper = "æœ‰" if (paper_total > 0 and v["paper_has"] >= v["paper_no"]) else ("æ²’æœ‰" if paper_total > 0 else "?")
            access = "æœ‰" if (access_total > 0 and v["acc_has"] >= v["acc_no"]) else ("æ²’æœ‰" if access_total > 0 else "?")
            avg = round(v["sum"] / v["n"], 2) if v["n"] > 0 else None
            out[key] = {"paper": paper, "access": access, "avg": avg}

        _feedback_index_cache = {"ts": now, "data": out}
        return out

    except Exception as e:
        logging.warning(f"å»ºç«‹æŒ‡ç¤ºç‡ˆç´¢å¼•å¤±æ•—ï¼š{e}")
        return {}

def submit_status_update(lat, lon, status_text, user_id="", display_name="", note=""):
    _ensure_sheets_ready()
    if status_ws is None:
        return False
    try:
        row = [
            norm_coord(lat), norm_coord(lon),
            status_text.strip(), user_id or "", display_name or "",
            (note or "").strip(),
            datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        ]
        status_ws.append_row(row, value_input_option="USER_ENTERED")
        _status_index_cache["ts"] = 0  # ç«‹åˆ»å¤±æ•ˆå¿«å–
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥ç‹€æ…‹å¤±æ•—: {e}")
        return False

def _is_close_m(lat1, lon1, lat2, lon2, th=_STATUS_NEAR_M):
    try:
        return haversine(float(lat1), float(lon1), float(lat2), float(lon2)) <= th
    except:
        return False

def build_status_index():
    _ensure_sheets_ready()
    if status_ws is None:
        return {}

    now = time.time()
    # âœ… ä¿®æ­£ï¼šä½¿ç”¨æœ‰åº•ç·šçš„ TTL è®Šæ•¸ï¼ˆä½ å‰é¢å®šç¾©çš„æ˜¯ _STATUS_INDEX_TTLï¼‰
    if (now - _status_index_cache["ts"] < _STATUS_INDEX_TTL) and _status_index_cache["data"]:
        return _status_index_cache["data"]

    # ä¸Šé™ä¿è­·ï¼Œé¿å…å¤§é‡æ–°åº§æ¨™æŠŠè¨˜æ†¶é«”æ’çˆ†ï¼ˆå¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼‰
    try:
        STATUS_INDEX_MAX_KEYS = int(os.getenv("STATUS_INDEX_MAX_KEYS", "800"))
    except Exception:
        STATUS_INDEX_MAX_KEYS = 800

    out = {}
    try:
        header, data = _get_header_and_tail(status_ws, MAX_SHEET_ROWS)
        if not header or not data:
            _status_index_cache.update(ts=now, data={})
            return {}

        idx = {h: i for i, h in enumerate(header)}
        i_lat = idx.get("lat"); i_lon = idx.get("lon")
        i_status = idx.get("status"); i_ts = idx.get("timestamp")
        if None in (i_lat, i_lon, i_status):
            _status_index_cache.update(ts=now, data={})
            return {}

        def fresh(ts_s: str) -> bool:
            if not ts_s:
                return False
            try:
                dt = datetime.strptime(ts_s, "%Y-%m-%d %H:%M:%S")
                return (datetime.utcnow() - dt).total_seconds() <= _STATUS_TTL_HOURS * 3600
            except Exception:
                return False

        # ä»¥ã€Œå·²åˆä½µæ¸…å–®ã€ç¶­è­·ä»£è¡¨é»ï¼›æ¯ç­†è³‡æ–™åªèˆ‡æ—¢æœ‰ä»£è¡¨é»æ¯” 35mï¼ˆ_STATUS_NEAR_Mï¼‰å…§æ˜¯å¦æ›´æ–°
        merged = []
        for r in data:
            # é‚Šç•Œä¿è­·
            if max(i_lat, i_lon, i_status) >= len(r):
                continue

            lat_s, lon_s = norm_coord(r[i_lat]), norm_coord(r[i_lon])
            st = (r[i_status] or "").strip()
            ts = (r[i_ts] if i_ts is not None and i_ts < len(r) else "")

            if not fresh(ts):
                continue

            placed = False
            # å˜—è©¦åˆä½µåˆ°æ—¢æœ‰ä»£è¡¨é»ï¼ˆè·é›¢ <= _STATUS_NEAR_Mï¼‰
            for m in merged:
                if _is_close_m(lat_s, lon_s, m["lat"], m["lon"]):
                    # å–è¼ƒæ–°çš„é‚£ç­†
                    if ts > m["ts"]:
                        m.update(lat=lat_s, lon=lon_s, status=st, ts=ts)
                    placed = True
                    break

            if not placed:
                # ä¸Šé™ä¿è­·ï¼šè¶…éä¸Šé™ä¸å†åŠ å…¥æ–°ç¾¤çµ„ï¼Œä½†ä»å…è¨±æ›´æ–°æ—¢æœ‰ç¾¤çµ„ï¼ˆè¦‹ä¸Šé¢ï¼‰
                if len(merged) < STATUS_INDEX_MAX_KEYS:
                    merged.append({"lat": lat_s, "lon": lon_s, "status": st, "ts": ts})
                else:
                    # å·²æ»¿å°±ç•¥éæ–°ä½ç½®ï¼Œé¿å…ç„¡ä¸Šé™æˆé•·
                    continue

        # è½‰æˆè¼¸å‡ºæ ¼å¼
        for m in merged:
            out[(m["lat"], m["lon"])] = {"status": m["status"], "ts": m["ts"]}

        _status_index_cache.update(ts=now, data=out)
        return out

    except Exception as e:
        logging.warning(f"å»ºç«‹ç‹€æ…‹ç´¢å¼•å¤±æ•—ï¼š{e}")
        return {}

# ==== ç’°å¢ƒè®Šæ•¸ ====
LIFF_ID_STATUS = os.getenv("LIFF_ID_STATUS") or os.getenv("LIFF_ID") or ""
PUBLIC_URL = os.getenv("PUBLIC_URL", "").rstrip("/")

# ==== é é¢ routes ====
@app.route("/achievements_liff")
def achievements_liff_page():
    return render_template("achievements_liff.html", liff_id=LIFF_ID_STATUS, public_url=PUBLIC_URL)

@app.route("/badges_liff")
def badges_liff_page():
    return render_template("badges_liff.html", liff_id=LIFF_ID_STATUS, public_url=PUBLIC_URL)

# ==== å°å·¥å…·ï¼šè®€å–ç‹€æ…‹è¡¨ä¸¦å½™ç¸½ ====
def _read_status_rows():
    try:
        _ensure_sheets_ready()
        ws = status_ws
        if not ws:
            return []
        try:
            header, data = _get_header_and_tail(ws)
        except Exception:
            header, data = _get_header_and_tail(ws, MAX_SHEET_ROWS)
            if not header:
                return []

        ix = {h: i for i, h in enumerate(header)}
        out = []
        for r in data:
            def g(k):
                i = ix.get(k); 
                return (r[i].strip() if (i is not None and i < len(r)) else "")
            out.append({
                "lat": g("lat"), "lon": g("lon"),
                "status": g("status"),
                "user_id": g("user_id"),
                "display_name": g("display_name"),
                "timestamp": g("timestamp"),
            })
        return out
    except Exception as e:
        logging.error(f"_read_status_rows error: {e}")
        return []

def _stats_for_user(uid: str):
    rows = _read_status_rows()
    total = 0
    by_status = {}
    last_ts = None

    for r in rows:
        if uid and r.get("user_id") != uid:
            continue

        total += 1
        s = r.get("status") or ""
        by_status[s] = by_status.get(s, 0) + 1

        ts = r.get("timestamp")
        if ts:
            try:
                # æ¯”è¼ƒæ™‚é–“ï¼Œå–æœ€æ–°çš„
                t = datetime.fromisoformat(ts)
                if last_ts is None or t > last_ts:
                    last_ts = t
            except:
                pass

    return {
        "total": total,
        "by_status": by_status,
        "last_ts": last_ts.isoformat() if last_ts else None
    }

def get_search_count(uid: str) -> int:
    try:
        conn = _get_db()
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM search_log WHERE user_id = ?", (uid,))
        row = cur.fetchone()
        conn.close()
        return int(row[0]) if row and row[0] is not None else 0
    except Exception as e:
        logging.warning(f"æŸ¥è©¢ search_log å¤±æ•—: {e}")
        return 0

# ==== æˆå°± API ====
ACHIEVEMENT_RULES = {
    "first": {
        "goal": 1,
        "counter": "total",
        "desc": "å®Œæˆç¬¬ä¸€æ¬¡ç‹€æ…‹å›å ±"
    },
    "helper10": {
        "goal": 10,
        "counter": "total",
        "desc": "ç´¯ç©å›å ± 10 æ¬¡"
    },
    "pro_reporter": {
        "goal": 20,
        "counter": "total",
        "desc": "ç´¯ç©å›å ± 20 æ¬¡"
    },
    "helper50": {
        "goal": 50,
        "counter": "total",
        "desc": "ç´¯ç©å›å ± 50 æ¬¡"
    },
    "tissue_guard": {
        "goal": 3,
        "counter": "ç¼ºè¡›ç”Ÿç´™",
        "desc": "å›å ±ã€ç¼ºè¡›ç”Ÿç´™ã€æ»¿ 3 æ¬¡"
    },
    "tissue_master": {
        "goal": 10,
        "counter": "ç¼ºè¡›ç”Ÿç´™",
        "desc": "å›å ±ã€ç¼ºè¡›ç”Ÿç´™ã€æ»¿ 10 æ¬¡"
    },
    "queue_scout": {
        "goal": 3,
        "counter": "æœ‰äººæ’éšŠ",
        "desc": "å›å ±ã€æœ‰äººæ’éšŠã€æ»¿ 3 æ¬¡"
    },
    "queue_commander": {
        "goal": 10,
        "counter": "æœ‰äººæ’éšŠ",
        "desc": "å›å ±ã€æœ‰äººæ’éšŠã€æ»¿ 10 æ¬¡"
    },
    "maintenance_watcher": {
        "goal": 3,
        "counter": "æš«åœä½¿ç”¨",
        "desc": "å›å ±ã€æš«åœä½¿ç”¨ã€æ»¿ 3 æ¬¡"
    },
    "good_news": {
        "goal": 5,
        "counter": "æ¢å¾©æ­£å¸¸",
        "desc": "å›å ±ã€æ¢å¾©æ­£å¸¸ã€æ»¿ 5 æ¬¡"
    },
}

@app.route("/api/achievements")
def api_achievements():
    uid = request.args.get("user_id", "").strip()
    stats = _stats_for_user(uid)
    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}

    # ç”¨å’Œå¾½ç« ä¸€æ¨£çš„è§£é–è¦å‰‡
    unlocked_map = _badge_rules(uid)

    out = []
    for cfg in BADGE_CONFIG:
        key = cfg["key"]
        rule = ACHIEVEMENT_RULES.get(key)
        if not rule:
            # å¦‚æœæœ‰åœ¨ BADGE_CONFIG å¢åŠ æ–° key ä½†é‚„æ²’åœ¨ ACHIEVEMENT_RULES å®šç¾©ï¼Œå°±å…ˆè·³é
            continue

        counter_type = rule["counter"]
        if counter_type == "total":
            progress = total
        else:
            # counter_type å°æ‡‰åˆ° by_status è£¡çš„ä¸­æ–‡ keyï¼Œä¾‹å¦‚ã€Œç¼ºè¡›ç”Ÿç´™ã€ã€Œæœ‰äººæ’éšŠã€ç­‰
            progress = int(by.get(counter_type, 0) or 0)

        goal = rule["goal"]

        out.append({
            "key": key,
            "title": cfg["name"],            # å’Œå¾½ç« åç¨±ä¸€è‡´
            "desc": rule.get("desc", ""),    # ä¸Šé¢ ACHIEVEMENT_RULES å®šç¾©çš„æè¿°
            "goal": goal,
            "progress": progress,
            "unlocked": bool(unlocked_map.get(key, False)),
            "icon": cfg.get("icon", ""),     # å¤šå›å‚³ iconï¼Œå‰ç«¯è¦ç”¨ä¹Ÿæ–¹ä¾¿
        })

    return {"ok": True, "achievements": out}, 200

def build_usage_review_text(uid: str) -> str:
    # æ”¹æˆç”¨ DB è£¡çš„ search_log çµ±è¨ˆæŸ¥è©¢æ¬¡æ•¸
    search_times = get_search_count(uid)

    stats = _stats_for_user(uid)  
    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}
    last_ts = stats.get("last_ts") or "å°šç„¡ç´€éŒ„"

    try:
        contribs = get_user_contributions(uid) or []
        num_contribs = len(contribs)
    except Exception:
        num_contribs = 0

    try:
        favs = get_user_favorites(uid) or []
        num_favs = len(favs)
    except Exception:
        num_favs = 0

    unlocked_badges = 0
    try:
        rules = _badge_rules(uid)
        unlocked_badges = sum(1 for v in rules.values() if v)
    except Exception:
        pass

    lines = []
    lines.append(f"ãƒ»ä½ ç¸½å…±æŸ¥è©¢éé™„è¿‘å»æ‰€ï¼š{search_times} æ¬¡")
    lines.append("")
    lines.append("ğŸ“Š ä½¿ç”¨å›é¡§")
    lines.append("")
    # ç‹€æ…‹å›å ±
    if total > 0:
        lines.append(f"ãƒ»ç‹€æ…‹å›å ±æ¬¡æ•¸ï¼š{total} æ¬¡")

        parts = []
        mapping = {
            "æ¢å¾©æ­£å¸¸": "âœ…",
            "æœ‰äººæ’éšŠ": "ğŸŸ¡",
            "ç¼ºè¡›ç”Ÿç´™": "ğŸ§»",
            "æš«åœä½¿ç”¨": "â›”",
        }
        # åªåˆ—å‡ºæœ‰å‡ºç¾éçš„ç‹€æ…‹
        for k, emo in mapping.items():
            c = int(by.get(k, 0) or 0)
            if c > 0:
                parts.append(f"{emo}{k} {c} æ¬¡")
        if parts:
            # æ”¾åœ¨åŒä¸€è¡Œï¼Œé¿å…å¤ªé•·
            lines.append("  â”” ç‹€æ…‹é¡å‹ï¼š" + "ï½œ".join(parts))

        lines.append(f"ãƒ»æœ€è¿‘ä¸€æ¬¡å›å ±æ™‚é–“ï¼š{last_ts}")
    else:
        lines.append("ãƒ»ç›®å‰é‚„æ²’æœ‰ä»»ä½•ç‹€æ…‹å›å ±ç´€éŒ„")

    lines.append("")
    # æ–°å¢å»æ‰€ & æœ€æ„›
    lines.append(f"ãƒ»ä½ æ–°å¢çš„å»æ‰€ï¼š{num_contribs} é–“")
    lines.append(f"ãƒ»ä½ æ”¶è—çš„æœ€æ„›å»æ‰€ï¼š{num_favs} é–“")

    # å¾½ç« æç¤º
    if unlocked_badges > 0:
        lines.append("")
        lines.append(f"ğŸ… å·²è§£é–å¾½ç« æ•¸ï¼š{unlocked_badges} å€‹ï¼ˆå¯è¼¸å…¥ã€Œå¾½ç« ã€æŸ¥çœ‹è©³ç´°ï¼‰")
    else:
        lines.append("")
        lines.append("ğŸ… é‚„æ²’è§£é–å¾½ç« ï¼Œè©¦è‘—å¤šå›å ±å¹¾æ¬¡ç‹€æ…‹å°±æœƒæ…¢æ…¢è§£é–å›‰ï¼")

    lines.append("")
    lines.append("ğŸ” å°æé†’ï¼šå¯ä»¥è¼¸å…¥ã€Œé™„è¿‘å»æ‰€ã€æˆ–å‚³é€ä½ç½®ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€ ğŸš½")

    lines.append("")
    lines.append("ğŸ¤– æŸ¥çœ‹ AI ç‚ºä½ ç”Ÿæˆçš„å€‹äººåŒ–ä½¿ç”¨åˆ†æï¼š")
    lines.append(f"ğŸ‘‰ https://school-i9co.onrender.com/ai_usage_summary_page/{uid}")
    return "\n".join(lines)
def build_ai_usage_summary(uid: str) -> str:
    """
    ç”¨ AI å¹«ä½¿ç”¨è€…åšã€å€‹äººä½¿ç”¨å›é¡§ã€ç¸½çµã€‚
    - æœ‰è³‡æ–™æ™‚ï¼šå‘¼å« OpenAI ç”¢ç”Ÿç²¾ç°¡çš„ Wrapped é¢¨æ ¼æ–‡å­—
    - è³‡æ–™å¤ªå°‘æ™‚ï¼šç›´æ¥å›å›ºå®šæç¤ºï¼Œä¸æµªè²» AI æµé‡
    - æ²’æœ‰ AI client æ™‚ï¼šé€€å›åŸæœ¬çš„æ–‡å­—ç‰ˆä½¿ç”¨å›é¡§
    """
    # å…ˆæ‹¿ä½ åŸæœ¬çš„è³‡æ–™ä¾†æº
    search_times = get_search_count(uid)  # è³‡æ–™è¡¨ search_log
    stats = _stats_for_user(uid)          # ç‹€æ…‹å›å ±çµ±è¨ˆ

    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}
    last_ts = stats.get("last_ts") or "å°šç„¡ç´€éŒ„"

    try:
        contribs = get_user_contributions(uid) or []
        num_contribs = len(contribs)
    except Exception:
        num_contribs = 0

    try:
        favs = get_user_favorites(uid) or []
        num_favs = len(favs)
    except Exception:
        num_favs = 0

    # å¾½ç« æ•¸
    unlocked_badges = 0
    try:
        rules = _badge_rules(uid)
        unlocked_badges = sum(1 for v in rules.values() if v)
    except Exception:
        pass

    # ğŸ”¹ å¦‚æœå¹¾ä¹æ²’æœ‰ä»»ä½•ç´€éŒ„ï¼Œå°±ä¸è¦æµªè²» AIï¼Œç›´æ¥å›å›ºå®šæ–‡å­—
    if (search_times == 0 and total == 0 and
        num_contribs == 0 and num_favs == 0 and
        unlocked_badges == 0):
        return (
            "ç›®å‰é‚„æ²’æœ‰è¶³å¤ çš„ä½¿ç”¨ç´€éŒ„å¯ä»¥ç”¢ç”Ÿ AI ä½¿ç”¨å›é¡§å–”ï½\n"
            "å¯ä»¥å¤šå¤šä½¿ç”¨ã€Œé™„è¿‘å»æ‰€ã€ã€Œç‹€æ…‹å›å ±ã€ã€Œæ–°å¢å»æ‰€ã€ã€Œæ”¶è—æœ€æ„›ã€ï¼Œ\n"
            "ä¹‹å¾Œæˆ‘æœƒå¹«ä½ åšä¸€ä»½å°ˆå±¬çš„ä½¿ç”¨å ±å‘Š ğŸ™Œ"
        )

    # ğŸ”¸ å¦‚æœæ²’æœ‰è¨­å®š AI é‡‘é‘°æˆ– clientï¼Œé€€å›åŸæœ¬çš„æ–‡å­—ç‰ˆä½¿ç”¨å›é¡§
    if client is None:
        return build_usage_review_text(uid)

    # ğŸ”¹ æ¯å€‹ä½¿ç”¨è€…ã€ŒAI ä½¿ç”¨å›é¡§ã€æ¯å¤©æœ€å¤šè§¸ç™¼ AI_DAILY_LIMIT æ¬¡
    ok, used = _ai_quota_check_and_inc(f"usage:{uid or 'anonymous'}")
    if not ok:
        base = build_usage_review_text(uid)
        return base + "\n\nï¼ˆä»Šæ—¥ AI ä½¿ç”¨å›é¡§æ¬¡æ•¸å·²é”ä¸Šé™ï¼Œæ˜å¤©å†ä¾†çœ‹çœ‹æ–°çš„åˆ†æå§ ğŸ™ï¼‰"

    # çµ„æˆçµ¦ AI çš„è³‡æ–™ payloadï¼ˆJSONï¼‰
    payload = {
        "search_times": search_times,
        "status_total": total,
        "status_by_type": by,
        "last_status_time": last_ts,
        "contributions": num_contribs,
        "favorites": num_favs,
        "unlocked_badges": unlocked_badges,
    }

    try:
        import json  # å¦‚æœæª”æ¡ˆè£¡å·²ç¶“æœ‰ import éä¹Ÿæ²’é—œä¿‚
        prompt = f"""
ä½ æ˜¯ä¸€å€‹æº«æš–çš„ç”Ÿæ´»å°åŠ©æ‰‹ï¼Œè¦å¹«ä½¿ç”¨è€…ç¸½çµä»–ä½¿ç”¨ã€Œæ™ºæ…§å»æ‰€åŠ©æ‰‹ã€çš„æƒ…æ³ã€‚

ä¸‹é¢æ˜¯ä¸€ä½ä½¿ç”¨è€…çš„ä½¿ç”¨çµ±è¨ˆè³‡æ–™ï¼ˆJSONï¼‰ï¼š
{json.dumps(payload, ensure_ascii=False)}

è«‹æ ¹æ“šé€™äº›æ•¸æ“šï¼Œå¹«ä»–ç”¢ç”Ÿä¸€æ®µã€Œå€‹äººä½¿ç”¨å›é¡§ã€ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š

- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- æ•´é«”ç¯‡å¹…æ§åˆ¶åœ¨ 4ï½7 è¡Œä»¥å…§
- ç¬¬ä¸€è¡Œçµ¦ä¸€å€‹ç¸½çµå¥ï¼ˆåƒ Spotify Wrapped çš„é–‹å ´ï¼šä¾‹å¦‚ã€Œä½ æ˜¯æœ€å¸¸å›å ±ç¼ºè¡›ç”Ÿç´™çš„äººä¹‹ä¸€ï¼ã€ï¼‰
- æ¥è‘—æ¢åˆ— 3ï½5 é»é‡é»ï¼Œå»ºè­°å¯ä»¥åŒ…å«ï¼š
  - æŸ¥è©¢é™„è¿‘å»æ‰€çš„æ¬¡æ•¸
  - ç‹€æ…‹å›å ±æ¬¡æ•¸ï¼Œå¸¸å‡ºç¾çš„ç‹€æ…‹é¡å‹ï¼ˆä¾‹å¦‚ï¼šç¼ºè¡›ç”Ÿç´™ã€æœ‰äººæ’éšŠã€æ¢å¾©æ­£å¸¸ç­‰ï¼‰
  - ä½ æ–°å¢äº†å¤šå°‘é–“å»æ‰€
  - ä½ æ”¶è—äº†å¤šå°‘é–“æœ€æ„›å»æ‰€
  - è§£é–äº†å¤šå°‘å€‹å¾½ç« ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
- æœ€å¾Œä¸€è¡Œçµ¦ä¸€å€‹ç°¡çŸ­çš„é¼“å‹µæˆ–å»ºè­°ï¼ˆä¾‹å¦‚é¼“å‹µå¤šå¤šå›å ±ã€ä¸€èµ·ç¶­è­·å¥½å»æ‰€ç’°å¢ƒï¼‰

è«‹ç›´æ¥è¼¸å‡ºçµ¦ä½¿ç”¨è€…çœ‹çš„å…§å®¹ï¼Œä¸è¦å†å‡ºç¾ JSON æˆ–æŠ€è¡“æè¿°ã€‚
        """.strip()

        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¹«å¿™åšä½¿ç”¨å›é¡§çš„ç”Ÿæ´»å°åŠ©æ‰‹ï¼Œèªªè©±è¦ªåˆ‡ã€ç°¡æ½”ï¼Œç”¨ç¹é«”ä¸­æ–‡ã€‚"},
                {"role": "user", "content": prompt}
            ],
        )

        summary = (resp.choices[0].message.content or "").strip()
        return summary or build_usage_review_text(uid)

    except Exception as e:
        logging.error(f"AI usage summary error: {e}", exc_info=True)
        # æœ‰å•é¡Œæ™‚ï¼Œä¸è®“ä½¿ç”¨è€…å™´éŒ¯ï¼Œé€€å›åŸæœ¬ç‰ˆæœ¬
        return build_usage_review_text(uid)
    
def build_ai_nearby_recommendation(uid: str, toilets):
    """
    ä¾æ“šé™„è¿‘å»æ‰€æ¸…å–®ï¼Œå‘¼å« OpenAI å¹«å¿™ç”¢ç”Ÿä¸€æ®µæ¨è–¦èªªæ˜æ–‡å­—ã€‚
    - å¦‚æœæ²’æœ‰ AI é‡‘é‘° / æ²’æœ‰å»æ‰€è³‡æ–™ï¼Œå°±ç›´æ¥å›ç©ºå­—ä¸²ï¼Œä¸å½±éŸ¿åŸæœ¬æµç¨‹
    - æ¯ä½ä½¿ç”¨è€…æ¯å¤© AI æ¨è–¦æ¬¡æ•¸æœ‰é™ï¼Œè¶…éå°±å›æç¤ºæ–‡å­—
    """
    if client is None:
        return ""
    if not toilets:
        return ""

    # ğŸ”¹ æ¯å€‹ä½¿ç”¨è€…ã€ŒAI æ¨è–¦é™„è¿‘å»æ‰€ã€æ¯å¤©æœ€å¤šè§¸ç™¼ AI_DAILY_LIMIT æ¬¡
    try:
        quota_key = uid or "anonymous"
        ok, used = _ai_quota_check_and_inc(f"nearby:{quota_key}")
    except Exception as e:
        logging.warning(f"AI nearby quota check failed: {e}")
        ok = True  # quota å£æ‰æ™‚ç•¶ä½œä¸é™åˆ¶

    if not ok:
        # é”åˆ°ä»Šæ—¥ä¸Šé™ï¼šä¸å‘¼å« OpenAIï¼Œåªå›æç¤º
        return (
            "ä»Šå¤© AI æ¨è–¦é™„è¿‘å»æ‰€çš„æ¬¡æ•¸å·²é”æ¯æ—¥ä¸Šé™å–”ï½\n"
            "å¦‚æœé‚„éœ€è¦æŸ¥è©¢ï¼Œå»ºè­°å…ˆé»ä¸‹é¢çš„ã€Œåˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ã€ï¼Œ\n"
            "å†ç”¨ä¸€èˆ¬æ¨¡å¼å¹«ä½ æ‰¾é™„è¿‘çš„å»æ‰€ ğŸ‘"
        )

    try:
        import json

        # æœ€å¤šæ‹¿å‰ 5 é–“ï¼Œé¿å… token å¤ªå¤§
        indicators = build_feedback_index()
        status_map = build_status_index()

        items = []
        for t in toilets[:5]:
            try:
                lat_s = norm_coord(t["lat"])
                lon_s = norm_coord(t["lon"])
            except Exception:
                continue

            key = (lat_s, lon_s)
            ind = indicators.get(key, {})
            st = status_map.get(key, {})

            items.append({
                "name": t.get("name") or t.get("place_hint") or "æœªå‘½åå»æ‰€",
                "distance_m": int(t.get("distance", 0) or 0),
                "paper": ind.get("paper"),          # "æœ‰" / "æ²’æœ‰" / "?"
                "access": ind.get("access"),        # "æœ‰" / "æ²’æœ‰" / "?"
                "avg_score": ind.get("avg"),        # æ¸…æ½”åˆ†æ•¸å¹³å‡
                "status": (st.get("status") or ""), # ä¾‹å¦‚ï¼šæœ‰äººæ’éšŠã€æš«åœä½¿ç”¨ã€æ¢å¾©æ­£å¸¸
            })

        if not items:
            return ""

        payload = {
            "uid": uid,
            "nearby_toilets": items
        }

        prompt = f"""
ä½ æ˜¯ä¸€å€‹ã€Œæ™ºæ…§å»æ‰€åŠ©æ‰‹ã€çš„æ¨è–¦å°å¹«æ‰‹ï¼Œä½¿ç”¨è€…å‰›å‰›å‚³äº†ä»–çš„ä½ç½®ï¼Œæˆ‘å€‘å¹«ä»–æ‰¾åˆ°å¹¾é–“é™„è¿‘çš„å»æ‰€ã€‚

ä¸‹é¢æ˜¯æ•´ç†å¥½çš„é™„è¿‘å»æ‰€è³‡æ–™ï¼ˆJSONï¼‰ï¼š
{json.dumps(payload, ensure_ascii=False)}

è«‹ä½ æ ¹æ“šï¼š
- è·é›¢ï¼ˆdistance_mï¼Œè¶Šå°è¶Šè¿‘ï¼‰
- æ¸…æ½”åˆ†æ•¸ avg_scoreï¼ˆæ•¸å­—è¶Šé«˜ä»£è¡¨è¶Šä¹¾æ·¨ï¼Œå¦‚æœæ˜¯ null ä»£è¡¨ç›®å‰æ²’æœ‰è©•åˆ†ï¼‰
- è¡›ç”Ÿç´™ç‹€æ…‹ paperï¼ˆ"æœ‰"/"æ²’æœ‰"/"?"ï¼‰
- ç„¡éšœç¤™è¨­æ–½ accessï¼ˆ"æœ‰"/"æ²’æœ‰"/"?"ï¼‰
- å³æ™‚ç‹€æ…‹ statusï¼ˆä¾‹å¦‚ï¼šæœ‰äººæ’éšŠã€æš«åœä½¿ç”¨ã€æ¢å¾©æ­£å¸¸ï¼‰

å¹«ä½¿ç”¨è€…åšä¸€æ®µç°¡çŸ­çš„ã€Œæ¨è–¦èªªæ˜ã€ï¼Œè¦æ±‚ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- ç¸½é•·åº¦ 3ï½5 è¡Œ
- ç¬¬ä¸€è¡Œå…ˆè¬›æ•´é«”æƒ…æ³
- æ¥è‘—æ¢åˆ—æ¨è–¦ 1ï½2 é–“ï¼ˆæœ€å¤š 3 é–“ï¼‰å»æ‰€
- æœ€å¾Œä¸€è¡Œçµ¦ä¸€å€‹ç°¡çŸ­å°å»ºè­°

è«‹ç›´æ¥è¼¸å‡ºçµ¦ä½¿ç”¨è€…çœ‹çš„æ–‡å­—ï¼Œä¸è¦å†å‡ºç¾ JSON æˆ–æŠ€è¡“èªªæ˜ã€‚
        """.strip()

        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¹«å¿™æ¨è–¦é™„è¿‘å»æ‰€çš„ç”Ÿæ´»å°åŠ©æ‰‹ï¼Œèªªè©±è¦ªåˆ‡ã€ç°¡æ½”ï¼Œç”¨ç¹é«”ä¸­æ–‡ã€‚"},
                {"role": "user", "content": prompt}
            ],
        )

        text = (resp.choices[0].message.content or "").strip()
        return text

    except Exception as e:
        logging.error(f"AI nearby recommendation error: {e}", exc_info=True)
        return ""

# --- ä¾ä½¿ç”¨è€…çµ±è¨ˆè¨ˆç®—è§£é– ---
def _badge_rules(uid: str):
    s = _stats_for_user(uid)              # {"total":N, "by_status":{...}, "last_ts":...}
    by, total = s.get("by_status", {}), int(s.get("total", 0))
    return {
        "first": total >= 1,                               # ç¬¬ 1 æ¬¡
        "helper10": total >= 10,                           # 10 æ¬¡
        "pro_reporter": total >= 20,                       # 20 æ¬¡
        "helper50": total >= 50,                           # 50 æ¬¡
        "tissue_guard": by.get("ç¼ºè¡›ç”Ÿç´™", 0) >= 3,         # ç¼ºè¡›ç”Ÿç´™ Ã—3
        "tissue_master": by.get("ç¼ºè¡›ç”Ÿç´™", 0) >= 10,       # ç¼ºè¡›ç”Ÿç´™ Ã—10
        "queue_scout": by.get("æœ‰äººæ’éšŠ", 0) >= 3,          # æœ‰äººæ’éšŠ Ã—3
        "queue_commander": by.get("æœ‰äººæ’éšŠ", 0) >= 10,     # æœ‰äººæ’éšŠ Ã—10
        "maintenance_watcher": by.get("æš«åœä½¿ç”¨", 0) >= 3,  # æš«åœä½¿ç”¨ Ã—3
        "good_news": by.get("æ¢å¾©æ­£å¸¸", 0) >= 5,            # æ¢å¾©æ­£å¸¸ Ã—5
    }

# --- åœ–åƒ/åç¨±è¨­å®šï¼ˆæŠŠ icon æª”æ”¾é€² /static/badges/ï¼Œæª”åå¯ä¾ä½ å¯¦éš›ç´ æèª¿æ•´ï¼‰---
BADGE_CONFIG = [
    {"key":"first",               "name":"æ–°æ‰‹å ±åˆ°",     "icon":"/static/badges/first.png"},
    {"key":"helper10",            "name":"å‹¤å‹å°å¹«æ‰‹",   "icon":"/static/badges/helper10.png"},
    {"key":"pro_reporter",        "name":"è³‡æ·±å›å ±å“¡",   "icon":"/static/badges/pro_reporter.png"},
    {"key":"helper50",            "name":"è¶…ç´šå¹«æ‰‹",     "icon":"/static/badges/helper50.png"},
    {"key":"tissue_guard",        "name":"ç´™å·¾å®ˆè­·è€…",   "icon":"/static/badges/tissue_guard.png"},
    {"key":"tissue_master",       "name":"ç´™å·¾ç¸½ç®¡",     "icon":"/static/badges/tissue_master.png"},
    {"key":"queue_scout",         "name":"æ’éšŠåµæŸ¥å“¡",   "icon":"/static/badges/queue_scout.png"},
    {"key":"queue_commander",     "name":"æ’éšŠæŒ‡æ®å®˜",   "icon":"/static/badges/queue_commander.png"},
    {"key":"maintenance_watcher", "name":"ç¶­é‹å®ˆè­·è€…",   "icon":"/static/badges/maintenance_watcher.png"},
    {"key":"good_news",           "name":"å¥½æ¶ˆæ¯åˆ†äº«å“¡", "icon":"/static/badges/good_news.png"},
]

# --- å–ä»£åŸæœ¬çš„ /api/badges è·¯ç”± ---
@app.route("/api/badges")
def api_badges():
    uid = request.args.get("user_id", "").strip()
    unlocked_map = _badge_rules(uid)
    items = []
    for b in BADGE_CONFIG:
        items.append({
            "key": b["key"],
            "name": b["name"],
            "icon": b["icon"],
            "unlocked": bool(unlocked_map.get(b["key"], False)),
        })
    return {"ok": True, "badges": items}, 200

# === èˆŠè·¯ç”±ä¿ç•™===
@app.route("/toilet_feedback/<toilet_name>")
def toilet_feedback(toilet_name):
    _ensure_sheets_ready()
    if worksheet is None or feedback_sheet is None:
        return render_template("toilet_feedback.html", toilet_name=toilet_name,
                               summary="ï¼ˆæš«æ™‚ç„¡æ³•é€£åˆ°é›²ç«¯è³‡æ–™ï¼‰",
                               feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="")
    try:
        address = "æœªçŸ¥åœ°å€"
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) > 1 and row[1] == toilet_name:
                address = (row[2] if len(row) > 2 else "") or "æœªçŸ¥åœ°å€"
                break

        if address == "æœªçŸ¥åœ°å€":
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="è«‹æ”¹ç”¨åº§æ¨™ç‰ˆå…¥å£ï¼ˆå¡ç‰‡ä¸Šçš„ã€æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰ã€ï¼‰ã€‚",
                                   feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="")

        rows_fb = feedback_sheet.get_all_values()
        header = rows_fb[0]; data_fb = rows_fb[1:]
        idx = _feedback_indices(header)
        if idx["address"] is None:
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="ï¼ˆè¡¨é ­ç¼ºå°‘ã€åœ°å€ã€æ¬„ä½ï¼‰", feedbacks=[], address=address,
                                   avg_pred_score="æœªé æ¸¬", lat="", lon="")

        matched = [r for r in data_fb
                   if len(r) > idx["address"] and (r[idx["address"]] or "").strip() == address.strip()]

        fbs = []
        nums = []
        for r in matched:
            def val(k):
                i = idx[k]
                return (r[i] if i is not None and len(r) > i else "").strip()
            sc, rr, pp, aa = _pred_from_row(r, idx)
            try: nums.append(float(sc))
            except: pass
            fbs.append({
                "rating": val("rating"),
                "toilet_paper": val("paper"),
                "accessibility": val("access"),
                "time_of_use": val("time"),
                "comment": safe_html(val("comment")),
                "cleanliness_score": str(sc) if sc is not None else "",
                "created_at": val("created"),
            })
        fbs.sort(key=lambda d: d.get("created_at",""), reverse=True)
        avg_pred_score = round(sum(nums)/len(nums), 2) if nums else "æœªé æ¸¬"

        if matched:
            paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            for r in matched:
                _, _, pp, aa = _pred_from_row(r, idx)
                if pp in paper_counts: paper_counts[pp] += 1
                if aa in access_counts: access_counts[aa] += 1
            avg = avg_pred_score
            summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\nğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg}\nğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰']>=paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\nâ™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰']>=access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        else:
            summary = "å°šç„¡å›é¥‹è³‡æ–™"

        return render_template("toilet_feedback.html",
                               toilet_name=toilet_name, summary=summary,
                               feedbacks=fbs, address=address,
                               avg_pred_score=avg_pred_score, lat="", lon="")
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ–°è·¯ç”± ===
@app.route("/toilet_feedback_by_coord/<lat>/<lon>")
def toilet_feedback_by_coord(lat, lon):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return render_template("toilet_feedback.html",
                               toilet_name=f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰",
                               summary="ï¼ˆæš«æ™‚ç„¡æ³•é€£åˆ°é›²ç«¯è³‡æ–™ï¼‰",
                               feedbacks=[], address=f"{lat},{lon}",
                               avg_pred_score="æœªé æ¸¬", lat=lat, lon=lon)
    try:
        name = f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰"
        summary = get_feedback_summary_by_coord(lat, lon)
        feedbacks = get_feedbacks_by_coord(lat, lon)

        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header:
            header = []
        if not data:
            data = []

        idx = _feedback_indices(header)

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        scores = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                sc, _, _, _ = _pred_from_row(r, idx)
                if isinstance(sc, (int, float)):
                    scores.append(float(sc))
        avg_pred_score = round(sum(scores)/len(scores), 2) if scores else "æœªé æ¸¬"

        return render_template(
            "toilet_feedback.html",
            toilet_name=name,
            summary=summary,
            feedbacks=feedbacks,
            address=f"{lat},{lon}",
            avg_pred_score=avg_pred_score,
            lat=lat,
            lon=lon
        )
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ¸…æ½”åº¦è¶¨å‹¢ï¼ˆåç¨±ç‰ˆåˆ¥åï¼‰ ===
@app.route("/get_clean_trend/<path:toilet_name>")
def get_clean_trend_by_name(toilet_name):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {"success": True, "data": []}, 200

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return {"success": True, "data": []}, 200
        idx = _feedback_indices(header)

        name_idx = idx.get("name")
        lat_idx = idx.get("lat")
        lon_idx = idx.get("lon")
        created_idx = idx.get("created")

        if name_idx is None or lat_idx is None or lon_idx is None:
            # è¡¨é ­ç¼ºå°‘å¿…è¦æ¬„ä½
            return {"success": True, "data": []}, 200

        # æ‰¾å‡ºåŒåçš„æ‰€æœ‰ç´€éŒ„ï¼Œå–å‡ºåº§æ¨™
        matched = [r for r in data if len(r) > name_idx and (r[name_idx] or "").strip() == toilet_name.strip()]
        if not matched:
            return {"success": True, "data": []}, 200

        # ä»¥æœ€æ–°ä¸€ç­†çš„åº§æ¨™ç‚ºä¸»
        if created_idx is not None:
            matched.sort(key=lambda x: (x[created_idx] if len(x) > created_idx else ""), reverse=True)
        ref = matched[0]
        lat = ref[lat_idx] if len(ref) > lat_idx else ""
        lon = ref[lon_idx] if len(ref) > lon_idx else ""

        # è½‰å‘¼å«åº§æ¨™ç‰ˆï¼ˆé‚è¼¯ä¸€è‡´ï¼‰
        return get_clean_trend_by_coord(lat, lon)

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåç¨±ç‰ˆï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === æ¸…æ½”åº¦è¶¨å‹¢ API ===
@app.route("/get_clean_trend_by_coord/<lat>/<lon>")
def get_clean_trend_by_coord(lat, lon):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {"success": True, "data": []}, 200 
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return {"success": True, "data": []}, 200
        
        idx = _feedback_indices(header)

        if idx["lat"] is None or idx["lon"] is None:
            return {"success": False, "data": []}, 200

        # âœ… æ”¾å¯¬æ¯”å°ç²¾åº¦åˆ° 1e-4
        def close(a, b, tol=1e-4):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched_rows = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched_rows.append(r)

        if not matched_rows:
            return {"success": True, "data": []}, 200

        recomputed = []
        for r in matched_rows:
            created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if sc is None:
                sc = _simple_score(rr, pp, aa)
            if isinstance(sc, (int, float)):
                # âœ… é †ä¾¿æŠŠæ™‚é–“ä¹Ÿå›å‡ºå»ï¼Œå‰ç«¯ç•«åœ–æ›´ç©©
                recomputed.append({"t": created, "score": round(float(sc), 2)})

        if not recomputed:
            return {"success": True, "data": []}, 200

        # å¦‚æœå…¨éƒ¨åˆ†æ•¸å®Œå…¨ä¸€æ¨£ï¼Œå†å˜—è©¦ç”¨ç°¡åŒ–ç‰ˆåˆ†æ•¸
        vals = [p["score"] for p in recomputed]
        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            forced = []
            for r in matched_rows:
                created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
                _, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    forced.append({"t": created, "score": round(float(sc2), 2)})
            if forced:
                recomputed = forced

        # âœ… ç¢ºä¿æ™‚é–“æ’åº
        recomputed.sort(key=lambda d: d["t"])
        return {"success": True, "data": recomputed}, 200

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === AI å›é¥‹æ‘˜è¦é é¢ ===
@app.route("/ai_feedback_summary_page/<lat>/<lon>")
def ai_feedback_summary_page(lat, lon):
    """
    é¡¯ç¤ºæŸä¸€å€‹å»æ‰€ï¼ˆç”¨åº§æ¨™è¡¨ç¤ºï¼‰çš„ AI å›é¥‹æ‘˜è¦é é¢ã€‚
    å‰ç«¯æœƒåœ¨é€™å€‹é é¢è£¡ç”¨ JS å‘¼å« /api/ai_feedback_summary/<lat>/<lon>ã€‚
    """
    uid = (request.args.get("uid") or "").strip()

    base = PUBLIC_URL.rstrip("/") if PUBLIC_URL else request.url_root.rstrip("/")
    # çµ¦å‰ç«¯ JS ç”¨çš„ API URLï¼ˆé †ä¾¿æŠŠ uid å¸¶é€²å»ï¼Œç”¨ä¾†åšæ¯æ—¥é¡åº¦æ§åˆ¶ï¼‰
    api_url = f"{base}/api/ai_feedback_summary/{lat}/{lon}"
    if uid:
        api_url += f"?uid={quote(uid)}"

    # é †ä¾¿åšä¸€å€‹ã€Œå»ç•™ä¸‹å›é¥‹ã€çš„é€£çµï¼ˆå°±ç®—æ²’å›é¥‹ä¹Ÿå¯ä»¥ç”¨ï¼‰
    feedback_url = (
        f"{base}/feedback_form/"
        f"{quote('é€™é–“å»æ‰€')}/{quote(lat + ',' + lon)}"
        f"?lat={lat}&lon={lon}&address={quote(lat + ',' + lon)}"
    )

    return render_template(
        "ai_feedback_summary.html",
        lat=lat,
        lon=lon,
        api_url=api_url,
        feedback_url=feedback_url,
        uid=uid,
    )

@app.route("/ai_usage_summary_page/<uid>")
def ai_usage_summary_page(uid):
    text = build_ai_usage_summary(uid)
    return render_template(
        "ai_usage_summary.html",
        uid=uid,
        summary=text
    )

# === AI å›é¥‹æ‘˜è¦ APIï¼ˆæ”¾åœ¨æ¸…æ½”åº¦è¶¨å‹¢ API çš„ä¸‹é¢ï¼‰ ===
AI_MODEL = os.getenv("AI_MODEL", "gpt-4o-mini")
AI_KEY   = os.getenv("OPENAI_API_KEY", "")
client   = OpenAI(api_key=AI_KEY) if AI_KEY else None

# --- AI æ¯æ—¥é¡åº¦æ§åˆ¶ï¼ˆæ–¹æ¡ˆ Dï¼šåŒä¸€ä½¿ç”¨è€…æ¯å¤©æœ€å¤šè§¸ç™¼å¹¾æ¬¡ AIï¼‰ ---
AI_DAILY_LIMIT = int(os.getenv("AI_DAILY_LIMIT", "3"))  # é è¨­ 3 æ¬¡/äºº/å¤©

_ai_quota_lock = threading.Lock()
_ai_quota = {}  # key: (usage_key, date_str) -> count


def _ai_quota_check_and_inc(key: str):
    today = datetime.utcnow().strftime("%Y-%m-%d")

    conn = _get_db()
    cur = conn.cursor()

    cur.execute("SELECT count FROM ai_quota WHERE key=? AND date=?", (key, today))
    row = cur.fetchone()
    cnt = row[0] if row else 0

    if cnt >= AI_DAILY_LIMIT:
        conn.close()
        return False, cnt

    if row:
        cur.execute("UPDATE ai_quota SET count=? WHERE key=? AND date=?", (cnt+1, key, today))
    else:
        cur.execute("INSERT INTO ai_quota (key, date, count) VALUES (?, ?, ?)", (key, today, 1))

    conn.commit()
    conn.close()

    return True, cnt+1

@app.route("/api/ai_feedback_summary/<lat>/<lon>")
def api_ai_feedback_summary(lat, lon):
    """
    ä¾ç…§åº§æ¨™è®€å– feedback_sheet çš„å›é¥‹ç´€éŒ„ï¼Œ
    ä¸Ÿçµ¦ OpenAI åšä¸­æ–‡æ‘˜è¦ï¼Œå›å‚³ JSON çµ¦å‰ç«¯ä½¿ç”¨ã€‚
    """
    try:
        _ensure_sheets_ready()
        if feedback_sheet is None:
            return {"success": False, "message": "feedback_sheet not ready"}, 503

        if client is None:
            return {"success": False, "message": "AI é‡‘é‘°æœªè¨­å®š"}, 500

        # 1. å¾é›²ç«¯å›é¥‹è¡¨æŠ“è³‡æ–™
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            # âœ… é€™è£¡ã€Œç›´æ¥å›æ²’æœ‰è³‡æ–™ã€ï¼Œä¸å‘¼å« AIï¼Œé¿å…æµªè²» token
            return {
                "success": True,
                "summary": "ç›®å‰é‚„æ²’æœ‰ä»»ä½•å›é¥‹è³‡æ–™ï¼Œå¯ä»¥é»ä¸‹é¢çš„æŒ‰éˆ•ä¾†å¹«å¿™ç•™ä¸€ç­†å›é¥‹ ğŸ™",
                "data": [],
                "has_data": False
            }, 200

        idx = _feedback_indices(header)
        if idx["lat"] is None or idx["lon"] is None:
            return {"success": False, "message": "lat/lon æ¬„ä½ç¼ºå°‘"}, 400

        def close(a, b, tol=1e-4):
            try:
                return abs(float(a) - float(b)) <= tol
            except Exception:
                return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if not (close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon)):
                continue

            def v(key):
                i = idx.get(key)
                return (r[i] if i is not None and i < len(r) else "").strip()

            item = {
                "rating":     v("rating"),
                "paper":      v("paper"),
                "access":     v("access"),
                "comment":    v("comment"),
                "created_at": v("created"),
            }
            matched.append(item)

        if not matched:
            # âœ… ä¸€æ¨£ä¸å‘¼å« AIï¼Œç›´æ¥å›ã€Œæ²’æœ‰è³‡æ–™ã€
            return {
                "success": True,
                "summary": "ç›®å‰é‚„æ²’æœ‰ä»»ä½•å›é¥‹è³‡æ–™ï¼Œå¯ä»¥é»ä¸‹é¢çš„æŒ‰éˆ•ä¾†å¹«å¿™ç•™ä¸€ç­†å›é¥‹ ğŸ™",
                "data": [],
                "has_data": False
            }, 200
        
        # ğŸ”¹ ä¾ user_id åšæ¯æ—¥é¡åº¦æ§åˆ¶ï¼ˆè‹¥æ²’æœ‰ uidï¼Œå°±é€€è€Œæ±‚å…¶æ¬¡ç”¨ IPï¼‰
        uid = (request.args.get("uid") or "").strip()
        quota_key = uid or f"ip:{request.remote_addr or 'unknown'}"

        ok, used = _ai_quota_check_and_inc(f"fb:{quota_key}")
        if not ok:
            # å·²é”ä»Šæ—¥ä¸Šé™ï¼šä¸å†å‘¼å« OpenAIï¼Œç›´æ¥å›ç°¡çŸ­æ–‡å­—
            return {
                "success": True,
                "summary": "ä»Šå¤© AI æ‘˜è¦æŸ¥è©¢æ¬¡æ•¸å·²é”ä¸Šé™ï¼Œæ˜å¤©å†ä¾†çœ‹çœ‹æœ€æ–°çš„åˆ†æå§ ğŸ™",
                "data": matched,
                "has_data": True,
                "limit_reached": True
            }, 200
        
        # 2. çµ„ AI Promptï¼Œè«‹æ¨¡å‹åšä¸­æ–‡æ‘˜è¦èˆ‡è¶¨å‹¢åˆ¤æ–·
        prompt = f"""
ä½ æ˜¯ä¸€å€‹å»æ‰€æ¸…æ½”åº¦åˆ†æåŠ©ç†ï¼Œè«‹é–±è®€ä»¥ä¸‹å›é¥‹è³‡æ–™ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œä¸¦è¼¸å‡ºï¼š

1. æœ€è¿‘å¸¸è¦‹çš„ä¸»è¦å•é¡Œï¼ˆä¾‹å¦‚ï¼šè¡›ç”Ÿç´™ä¸è¶³ã€åœ°æ¿æ¿•æ»‘ã€ç•°å‘³ã€è¨­å‚™è€èˆŠç­‰ï¼‰
2. ä½¿ç”¨è€…æ•´é«”æƒ…ç·’å‚¾å‘ï¼ˆæ­£é¢ / ä¸­æ€§ / è² é¢ï¼‰ï¼Œç°¡çŸ­èªªæ˜åŸå› 
3. æ¸…æ½”åº¦ç‹€æ…‹çš„è¶¨å‹¢ï¼ˆè®Šä¹¾æ·¨ / è®Šé«’ / å¤§è‡´æŒå¹³ï¼‰ï¼Œå¦‚æœè³‡æ–™ä¸è¶³è«‹èªªæ˜
4. æœ€å¾Œè«‹ç”¨ä¸‰è¡Œä»¥å…§ï¼Œçµ¦å‡ºä¸€æ®µç¸½çµå»ºè­°

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€æ¢åˆ—å¼æˆ–çŸ­å¥ï¼Œè®“ä¸€èˆ¬ä½¿ç”¨è€…å®¹æ˜“é–±è®€ã€‚

ä»¥ä¸‹æ˜¯å›é¥‹è³‡æ–™ï¼ˆJSONï¼‰ï¼š
{matched}
        """.strip()

        ai_resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹åˆ†æå»æ‰€ä½¿ç”¨å›é¥‹çš„åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )

        summary = (ai_resp.choices[0].message.content or "").strip()

        return {
            "success": True,
            "summary": summary,
            "data": matched,
            "has_data": True
        }, 200

    except Exception as e:
        logging.error(f"AI summary error: {e}", exc_info=True)
        return {"success": False, "message": "AI error"}, 500

# === åŒæ„é é¢ / éš±ç§é  ===
@app.route("/consent", methods=["GET"])
def render_consent_page():
    return render_template("consent.html")

@app.route("/privacy", methods=["GET"])
def render_privacy_page():
    return render_template("privacy_policy.html")

# ç‹€æ…‹ LIFF é é¢
@app.route("/status_liff")
def status_liff():
    liff_id = os.getenv("LIFF_STATUS_ID", "")
    public_url = os.getenv("PUBLIC_URL", "")
    assert liff_id, "LIFF_STATUS_ID not set"
    assert public_url, "PUBLIC_URL not set"
    return render_template("status_liff.html", liff_id=liff_id, public_url=public_url)

# === LIFF åŒæ„ APIï¼ˆæ–°å¢ï¼šå¾®ç¯€æµï¼‹å¤±æ•—å…¥èƒŒæ™¯ä½‡åˆ—ï¼Œå› 200ï¼‰ ===
_last_consent_ts = {}
CONSENT_MIN_INTERVAL = float(os.getenv("CONSENT_MIN_INTERVAL", "1.0"))

@app.route("/api/consent", methods=["POST"])
def api_consent():
    try:
        payload = request.get_json(force=True, silent=False) or {}
        agreed = bool(payload.get("agree"))
        user_id = (payload.get("userId") or "").strip()
        display_name = payload.get("displayName") or ""
        source_type = payload.get("sourceType") or ""
        ua = payload.get("ua") or request.headers.get("User-Agent","")
        ts = payload.get("ts") or datetime.utcnow().isoformat()

        if not user_id:
            logging.warning(f"/api/consent missing userId. payload={payload}")
            return {"ok": False, "message": "ç¼ºå°‘ userId"}, 400

        now = time.time()
        last = _last_consent_ts.get(user_id, 0.0)
        if now - last < CONSENT_MIN_INTERVAL:
            return {"ok": True, "message": "accepted"}, 200
        _last_consent_ts[user_id] = now

        ok = upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
        if not ok:
            def job():
                try:
                    upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
                except Exception:
                    pass
            with _consent_lock:
                if len(_consent_q) < 1000:
                    _consent_q.append(job)
            return {"ok": True, "message": "queued"}, 200

        return {"ok": True}, 200
    except Exception as e:
        logging.error(f"/api/consent å¤±æ•—: {e}")
        return {"ok": False}, 500

@app.route("/_debug_predict")
def _debug_predict():
    try:
        r = int(request.args.get("rating"))
        paper = request.args.get("paper", "æ²’æ³¨æ„")
        acc = request.args.get("access", "æ²’æ³¨æ„")

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        feat = [r, paper_map.get(paper, 0), access_map.get(acc, 0)]
        exp = expected_from_feats([feat])

        return {
            "ok": True,
            "input": {"rating": r, "paper": paper, "access": acc},
            "expected": exp
        }, 200
    except Exception as e:
        logging.error(e)
        return {"ok": False}, 500

def _short_txt(s, n=60):
    try:
        s = (s or "").strip()
        return s if len(s) <= n else (s[:n-1] + "â€¦")
    except Exception:
        return s

# === å»ºç«‹ Flex ===
def create_toilet_flex_messages(toilets, uid=None):
    indicators = build_feedback_index()
    status_map = build_status_index()
    bubbles = []
    for toilet in toilets[:5]:
        actions = []

        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        addr_text = toilet.get('address') or "ï¼ˆç„¡åœ°å€ï¼Œä½¿ç”¨åº§æ¨™ï¼‰"

        title = toilet.get('name') or ""
        if (not title) or title == "ç„¡åç¨±":
            ph = toilet.get("place_hint")
            title = f"{ph}ï¼ˆé™„è¿‘ï¼‰å»æ‰€" if ph else "ï¼ˆæœªå‘½åï¼‰å»æ‰€"

        # åªè®€ä¸‰å€‹æ¬„ä½ï¼ˆå¯èƒ½ç‚ºç©ºï¼‰
        lvl   = (toilet.get("level") or "").strip()
        pos   = (toilet.get("floor_hint") or "").strip()
        hours = (toilet.get("open_hours") or "").strip()

        # é¡å¤–é¡¯ç¤ºè¡Œ
        extra_lines = []
        st_obj = status_map.get((lat_s, lon_s))
        if st_obj and st_obj.get("status"):
            st = st_obj["status"]
            emoji = "ğŸŸ¡" if st == "æœ‰äººæ’éšŠ" else ("ğŸ§»" if st == "ç¼ºè¡›ç”Ÿç´™" else ("â›”" if st == "æš«åœä½¿ç”¨" else "âœ…"))
            extra_lines.append({
                "type": "text",
                "text": _short_txt(f"{emoji} ç‹€æ…‹ï¼š{st}"),
                "size": "sm", "color": "#666666", "wrap": True
            })

        if lvl or pos:
            if lvl and pos and (lvl.strip().lower() != pos.strip().lower()):
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(f"ğŸ· æ¨“å±¤ï¼š{lvl}"),
                    "size": "sm", "color": "#666666", "wrap": True
                })
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(f"ğŸ§­ ä½ç½®ï¼š{pos}"),
                    "size": "sm", "color": "#666666", "wrap": True
                })
            else:
                val = pos or lvl
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(f"ğŸ§­ ä½ç½®/æ¨“å±¤ï¼š{val}"),
                    "size": "sm", "color": "#666666", "wrap": True
                })

        if hours:
            extra_lines.append({
                "type": "text",
                "text": _short_txt(f"ğŸ•’ é–‹æ”¾ï¼š{hours}"),
                "size": "sm", "color": "#666666", "wrap": True
            })

        # æŒ‡ç¤ºç‡ˆæ–‡å­—
        ind = indicators.get((lat_s, lon_s), {"paper": "?", "access": "?", "avg": None})
        star_text = f"â­{ind['avg']}" if ind.get("avg") is not None else "â­â€”"
        paper_text = "ğŸ§»æœ‰" if ind.get("paper") == "æœ‰" else ("ğŸ§»ç„¡" if ind.get("paper") == "æ²’æœ‰" else "ğŸ§»â€”")
        access_text = "â™¿æœ‰" if ind.get("access") == "æœ‰" else ("â™¿ç„¡" if ind.get("access") == "æ²’æœ‰" else "â™¿â€”")

        # æŒ‰éˆ•
        actions.append({
            "type": "uri",
            "label": "å°èˆª",
            "uri": f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"
        })
        actions.append({
            "type": "uri",
            "label": "æŸ¥è©¢å›é¥‹",
            "uri": f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"
        })

        addr_raw = toilet.get('address') or ""
        addr_param = quote(addr_raw or "-")
        actions.append({
            "type": "uri",
            "label": "å»æ‰€å›é¥‹",
            "uri": (
                "https://school-i9co.onrender.com/feedback_form/"
                f"{quote(title)}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
            )
        })

        ai_page_base = "https://school-i9co.onrender.com/ai_feedback_summary_page"
        ai_uri = f"{ai_page_base}/{lat_s}/{lon_s}" + (f"?uid={quote(uid)}" if uid else "")
        actions.append({
            "type": "uri",
            "label": "AI å›é¥‹æ‘˜è¦",
            "uri": ai_uri
        })

        if toilet.get("type") == "favorite" and uid:
            actions.append({
                "type": "postback",
                "label": "ç§»é™¤æœ€æ„›",
                "data": f"remove_fav:{quote(title)}:{lat_s}:{lon_s}"
            })
        elif toilet.get("type") not in ["user", "favorite"] and uid:
            actions.append({
                "type": "postback",
                "label": "åŠ å…¥æœ€æ„›",
                "data": f"add:{quote(title)}:{lat_s}:{lon_s}"
            })

        # ä¸»é«”å…§å®¹
        body_contents = [
            {"type": "text", "text": title, "weight": "bold", "size": "lg", "wrap": True},
            {"type": "text", "text": f"{paper_text}  {access_text}  {star_text}", "size": "sm", "color": "#555555", "wrap": True},
            {"type": "text", "text": addr_text, "size": "sm", "color": "#666666", "wrap": True},
        ] + extra_lines + [
            {"type": "text", "text": f"{int(toilet.get('distance', 0))} å…¬å°º", "size": "sm", "color": "#999999"}
        ]

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": body_contents
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {"type": "button", "style": "primary", "height": "sm", "action": actions[0]}
                ] + [
                    {"type": "button", "style": "secondary", "height": "sm", "action": a}
                    for a in actions[1:]
                ]
            }
        }

        bubbles.append(bubble)

    return {"type": "carousel", "contents": bubbles}

# === åˆ—å‡º æˆ‘çš„è²¢ç» & åˆªé™¤ ===
def get_user_contributions(uid):
    _ensure_sheets_ready()
    if worksheet is None:
        return []
    items = []
    try:
        rows = worksheet.get_all_values()
        if not rows or len(rows) < 2:
            return items
        header = rows[0]; data = rows[1:]
        idx = _toilet_sheet_indices(header)
        for i, r in enumerate(data, start=2):
            if idx["user_id"] is None: break
            if len(r) <= idx["user_id"]: continue
            if r[idx["user_id"]] != uid: continue
            try:
                lat = float(r[idx["lat"]]); lon = float(r[idx["lon"]])
            except:
                continue
            items.append({
                "row_index": i,
                "name": (r[idx["name"]] if idx["name"] is not None and len(r)>idx["name"] else "ç„¡åç¨±"),
                "address": (r[idx["address"]] if idx["address"] is not None and len(r)>idx["address"] else ""),
                "lat": float(norm_coord(lat)),
                "lon": float(norm_coord(lon)),
                "created": (r[idx["created"]] if idx["created"] is not None and len(r)>idx["created"] else ""),
            })
        return items
    except Exception as e:
        logging.error(f"è®€å–æˆ‘çš„è²¢ç»å¤±æ•—ï¼š{e}")
        return items

def create_my_contrib_flex(uid):
    contribs = get_user_contributions(uid)
    if not contribs:
        return None
    bubbles = []
    for it in contribs[:10]:
        lat_s = norm_coord(it["lat"]); lon_s = norm_coord(it["lon"])
        addr_raw = it.get('address','') or ""
        addr_param = quote(addr_raw or "-")
        actions = [
            {"type":"uri","label":"å°èˆª","uri":f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"},
            {"type":"uri","label":"æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰","uri":f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"},
            {"type":"uri","label":"å»æ‰€å›é¥‹",
             "uri":(
                f"https://school-i9co.onrender.com/feedback_form/{quote(it['name'])}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
             )},
            {"type":"postback","label":"åˆªé™¤æ­¤è²¢ç»","data":f"confirm_delete_my_toilet:{it['row_index']}"}
        ]
        bubble = {
            "type":"bubble",
            "body":{
                "type":"box","layout":"vertical","contents":[
                    {"type":"text","text":it["name"],"size":"lg","weight":"bold","wrap":True},
                    {"type":"text","text":it.get("address") or "ï¼ˆç„¡åœ°å€ï¼‰","size":"sm","color":"#666666","wrap":True},
                    {"type":"text","text":it['created'], "size":"xs","color":"#999999"}
                ]
            },
            "footer":{
                "type":"box","layout":"vertical","spacing":"sm",
                "contents":[{"type":"button","style":"primary","height":"sm","action":actions[0]}] + [
                    {"type":"button","style":"secondary","height":"sm","action":a} for a in actions[1:]
                ]
            }
        }
        bubbles.append(bubble)
    return {"type":"carousel","contents":bubbles}

# === Webhook ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

@app.route("/", methods=["GET"])
def home():
    return "Toilet bot is running!", 200

# === å…±ç”¨ç‹€æ…‹ ===
user_locations = {}
pending_delete_confirm = {}
user_search_count = {}
user_loc_mode = {}  # æ–°å¢ï¼šè¨˜éŒ„ä½¿ç”¨è€…ç›®å‰æŸ¥å»æ‰€æ¨¡å¼ï¼ˆ"normal" or "ai"ï¼‰

# å»ºè­°ï¼šé«˜ä½µç™¼æ™‚é¿å…ç«¶æ…‹
_dict_lock = threading.Lock()
def set_user_location(uid, latlon):
    with _dict_lock:
        user_locations[uid] = latlon

def get_user_location(uid):
    with _dict_lock:
        return user_locations.get(uid)

def set_user_loc_mode(uid, mode):
    with _dict_lock:
        user_loc_mode[uid] = mode

def get_user_loc_mode(uid):
    with _dict_lock:
        return user_loc_mode.get(uid, "normal")

# === å…±ç”¨åŸ·è¡Œç·’æ± ï¼ˆé¿å…æ¯æ¬¡è‡¨æ™‚å»ºç«‹ï¼‰ ===
_pool = ThreadPoolExecutor(max_workers=2)

def build_nearby_toilets(uid, lat, lon, radius=500):
    futures = []
    csv_res, sheet_res, osm_res = [], [], []

    try:
        futures.append(("csv",  _pool.submit(query_public_csv_toilets, lat, lon, radius)))
        futures.append(("sheet", _pool.submit(query_sheet_toilets,      lat, lon, radius)))
        futures.append(("osm",  _pool.submit(query_overpass_toilets,    lat, lon, radius)))

        for name, fut in futures:
            try:
                res = fut.result(timeout=LOC_QUERY_TIMEOUT_SEC)
                if   name == "csv":  csv_res  = res or []
                elif name == "sheet": sheet_res = res or []
                else:                 osm_res  = res or []
            except FuturesTimeoutError:
                logging.warning(f"{name} æŸ¥è©¢é€¾æ™‚")
            except Exception as e:
                logging.warning(f"{name} æŸ¥è©¢å¤±æ•—: {e}")
    finally:
        for _, fut in futures:
            if not fut.done():
                fut.cancel()

    quick = _merge_and_dedupe_lists(csv_res, sheet_res, osm_res)
    sort_toilets(quick)
    return quick[:LOC_MAX_RESULTS]

# === TextMessage ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    if _too_old_to_reply(event):
        logging.warning("[handle_text] event too old; skip reply.")
        return
    uid = event.source.user_id
    text_raw = event.message.text or ""
    text = text_raw.strip().lower()

    if is_duplicate_and_mark_event(event):
        return

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    reply_messages = []

    if uid in pending_delete_confirm:
        ...
        # ï¼ˆé€™æ®µç¶­æŒåŸæ¨£ï¼‰
        ...

    elif text == "é™„è¿‘å»æ‰€":
        with _dict_lock:
            user_search_count[uid] = user_search_count.get(uid, 0) + 1
        set_user_loc_mode(uid, "normal")  # æ¨™è¨˜ç‚ºä¸€èˆ¬æ¨¡å¼
        try:
            safe_reply(
                event,
                make_location_quick_reply(
                    "ğŸ“ è«‹é»ä¸‹æ–¹ã€ç™¼é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€",
                    mode="normal"
                )
            )
        except Exception as e:
            logging.error(f"é™„è¿‘å»æ‰€ quick reply å¤±æ•—: {e}")
            safe_reply(event, TextSendMessage(text="âŒ ç³»çµ±éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"))
        return

    elif text == "aiæ¨è–¦é™„è¿‘å»æ‰€":
        # åˆ‡æ›æˆ AI æ¨¡å¼ï¼Œä¹‹å¾Œå‚³ä½ç½®éƒ½èµ° AI
        set_user_loc_mode(uid, "ai")
        try:
            safe_reply(
                event,
                make_location_quick_reply(
                    "ğŸ“ è«‹å‚³é€ä½ ç¾åœ¨çš„ä½ç½®ï¼Œæˆ‘æœƒç”¨ AI å¹«ä½ æŒ‘é™„è¿‘æœ€é©åˆçš„å»æ‰€",
                    mode="ai"
                )
            )
        except Exception as e:
            logging.error(f"AI æ¨è–¦é™„è¿‘å»æ‰€ quick reply å¤±æ•—: {e}")
            safe_reply(event, TextSendMessage(text="âŒ ç³»çµ±éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"))
        return

    elif text == "åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼":
        # ä½¿ç”¨è€…ä¸»å‹•åˆ‡å›ä¸€èˆ¬æ¨¡å¼
        set_user_loc_mode(uid, "normal")
        try:
            safe_reply(
                event,
                make_location_quick_reply(
                    "âœ… å·²åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ï¼Œè«‹é»ã€ç™¼é€æˆ‘çš„ä½ç½®ã€æˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€",
                    mode="normal"
                )
            )
        except Exception as e:
            logging.error(f"åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ quick reply å¤±æ•—: {e}")
            safe_reply(event, TextSendMessage(text="âŒ ç³»çµ±éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"))
        return
    
    # === æˆ‘çš„æœ€æ„› ===
    elif text == "æˆ‘çš„æœ€æ„›":
        favs = get_user_favorites(uid)
        if not favs:
            reply_messages.append(TextSendMessage(text="ä½ å°šæœªæ”¶è—ä»»ä½•å»æ‰€"))
        else:
            loc = get_user_location(uid)
            if loc:
                lat, lon = loc
                for f in favs:
                    f["distance"] = haversine(lat, lon, f["lat"], f["lon"])
            msg = create_toilet_flex_messages(favs, uid=uid)
            reply_messages.append(FlexSendMessage("æˆ‘çš„æœ€æ„›", msg))

    # === æˆ‘çš„è²¢ç» ===
    elif text == "æˆ‘çš„è²¢ç»":
        msg = create_my_contrib_flex(uid)
        if msg:
            reply_messages.append(FlexSendMessage("æˆ‘æ–°å¢çš„å»æ‰€", msg))
        else:
            reply_messages.append(TextSendMessage(text="ä½ é‚„æ²’æœ‰æ–°å¢éå»æ‰€å–”ã€‚"))

    # === æ–°å¢å»æ‰€ ===
    elif text == "æ–°å¢å»æ‰€":
        base = "https://school-i9co.onrender.com/add"
        loc = get_user_location(uid)
        if loc:
            la, lo = loc
            url = f"{base}?uid={quote(uid)}&lat={la}&lon={lo}#openExternalBrowser=1"
        else:
            url = f"{base}?uid={quote(uid)}#openExternalBrowser=1"
        reply_messages.append(TextSendMessage(text=f"è«‹å‰å¾€æ­¤é æ–°å¢å»æ‰€ï¼š\n{url}"))

    # === æ„è¦‹å›é¥‹ ===
    elif text == "æ„è¦‹å›é¥‹":
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdsibz15enmZ3hJsQ9s3BiTXV_vFXLy0llLKlpc65vAoGo_hg/viewform?usp=sf_link"
        reply_messages.append(TextSendMessage(text=f"ğŸ’¡ è«‹é€éä¸‹åˆ—é€£çµå›å ±å•é¡Œæˆ–æä¾›æ„è¦‹ï¼š\n{form_url}"))

    # === åˆä½œä¿¡ç®± ===
    elif text == "åˆä½œä¿¡ç®±":
        email = os.getenv("FEEDBACK_EMAIL", "hello@example.com")
        ig_url = "https://www.instagram.com/toiletmvp?igsh=MWRvMnV2MTNyN2RkMw=="
        reply_messages.append(TextSendMessage(
            text=f"ğŸ“¬ åˆä½œä¿¡ç®±ï¼š{email}\n\n ğŸ“¸ å®˜æ–¹IG: {ig_url}"
        ))

    # === ç‹€æ…‹å›å ± ===
    elif text == "ç‹€æ…‹å›å ±":
        url = _status_liff_url()
        safe_reply(event, TextSendMessage(text=f"âš¡ é–‹å•Ÿç‹€æ…‹å›å ±ï¼š\n{url}"))

    # === æˆå°± ===
    elif text == "æˆå°±":
        reply_url = f"{PUBLIC_URL}/achievements_liff"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æŸ¥çœ‹æˆå°± ğŸ‘‰ {reply_url}"))

    # === å¾½ç«  ===
    elif text == "å¾½ç« ":
        reply_url = f"{PUBLIC_URL}/badges_liff"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æŸ¥çœ‹å¾½ç«  ğŸ‘‰ {reply_url}"))

    # === ä½¿ç”¨å›é¡§ ===
    elif text == "ä½¿ç”¨å›é¡§":
        summary = build_usage_review_text(uid)
        reply_messages.append(TextSendMessage(text=summary))

    if reply_messages:
        safe_reply(event, reply_messages)

# === LocationMessage ===
@handler.add(MessageEvent, message=LocationMessage)
def handle_location(event):
    if _too_old_to_reply(event):
        logging.warning("[handle_location] event too old; skip reply.")
        return
    uid = event.source.user_id
    show_loading(uid, seconds=15)
    lat = event.message.latitude
    lon = event.message.longitude

    # è¨˜éŒ„æŸ¥è©¢æ¬¡æ•¸ï¼ˆå¯« DBï¼‰
    try:
        conn = _get_db()
        cur = conn.cursor()
        cur.execute(
            "INSERT INTO search_log (user_id, lat, lon, ts) VALUES (?,?,?,?)",
            (uid, norm_coord(lat), norm_coord(lon),
             datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"))
        )
        conn.commit()
        conn.close()
    except Exception as e:
        logging.warning(f"è¨˜éŒ„æŸ¥è©¢æ¬¡æ•¸å¤±æ•—: {e}")

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    if is_duplicate_and_mark_event(event):
        return

    # è¨˜ä¸‹ä½¿ç”¨è€…æœ€è¿‘ä¸€æ¬¡çš„ä½ç½®
    set_user_location(uid, (lat, lon))

    if not _try_acquire_loc_slot():
        safe_reply(event, make_retry_location_text())
        return

    try:
        toilets = build_nearby_toilets(uid, lat, lon)

        if toilets:
            # å…ˆç”¢å‡ºåŸæœ¬çš„å»æ‰€ carousel
            msg = create_toilet_flex_messages(toilets, uid=uid)

            # çœ‹ç›®å‰æ˜¯ä¸€èˆ¬æ¨¡å¼é‚„æ˜¯ AI æ¨¡å¼
            mode = get_user_loc_mode(uid)

            if mode == "ai":
                # ğŸ§  AI æ¨¡å¼ï¼šæŠŠ AI æ¨è–¦æ–‡å­—å¡æˆã€Œç¬¬ä¸€å€‹ bubbleã€
                ai_text = build_ai_nearby_recommendation(uid, toilets)

                if ai_text:
                    ai_bubble = {
                        "type": "bubble",
                        "body": {
                            "type": "box",
                            "layout": "vertical",
                            "contents": [
                                {
                                    "type": "text",
                                    "text": "ğŸ¤– AI æ¨è–¦åˆ†æ",
                                    "weight": "bold",
                                    "size": "lg",
                                    "wrap": True,
                                },
                                {
                                    "type": "text",
                                    "text": ai_text,
                                    "size": "sm",
                                    "color": "#444444",
                                    "wrap": True,
                                },
                            ]
                        }
                    }
                    try:
                        # å®‰å…¨æ’å…¥åˆ° carousel æœ€å‰é¢
                        if isinstance(msg, dict) and msg.get("type") == "carousel":
                            msg.setdefault("contents", [])
                            contents = msg.get("contents")
                            if isinstance(contents, list):
                                contents.insert(0, ai_bubble)
                    except Exception as e:
                        logging.warning(f"æ’å…¥ AI bubble å¤±æ•—: {e}")

                # ğŸ‘‰ è¨Šæ¯æ•¸é‡ï¼š1 å‰‡ Flex + 1 å‰‡ quick-reply æ–‡å­—
                messages = [
                    FlexSendMessage("é™„è¿‘å»æ‰€ï¼ˆAI æ¨¡å¼ï¼‰", msg),
                    make_location_quick_reply("æƒ³ç”¨ AI å†åˆ†æå…¶ä»–ä½ç½®å—ï¼Ÿ"),
                ]

            else:
                # âš¡ ä¸€èˆ¬æ¨¡å¼ï¼šåŸæœ¬è¡Œç‚ºä¸è®Š
                messages = [
                    FlexSendMessage("é™„è¿‘å»æ‰€", msg),
                    make_location_quick_reply("æƒ³æ›å€‹åœ°é»å†æ‰¾å—ï¼Ÿ"),
                ]

            safe_reply(event, messages)

    except Exception as e:
        logging.error(f"nearby error: {e}", exc_info=True)
        safe_reply(event, TextSendMessage(text="ç³»çµ±å¿™ç·šä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™"))
    finally:
        _release_loc_slot()

# === Postback ===
@handler.add(PostbackEvent)
def handle_postback(event):
    uid = event.source.user_id
    data = event.postback.data or ""

    if is_duplicate_and_mark_event(event):
        return

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg); return

    try:
        if data == "ask_location":
            mode = get_user_loc_mode(uid)  # ç›®å‰æ˜¯ normal é‚„æ˜¯ ai
            safe_reply(
                event,
                make_location_quick_reply(
                    "ğŸ“ è«‹é»ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘ç«‹åˆ»å¹«ä½ æ‰¾å»æ‰€",
                    mode=mode
                )
            )
            return

        if data == "ask_ai_location":
            set_user_loc_mode(uid, "ai")
            safe_reply(
                event,
                make_location_quick_reply(
                    "ğŸ“ è«‹é»ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘æœƒç”¨ AI å¹«ä½ æŒ‘é™„è¿‘çš„å»æ‰€",
                    mode="ai"
                )
            )
            return

        if data.startswith("add:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            toilet = {
                "name": name,
                "lat": float(lat),
                "lon": float(lon),
                "address": f"{lat},{lon}",
                "distance": 0,
                "type": "sheet"
            }
            add_to_favorites(uid, toilet)
            safe_reply(event, TextSendMessage(text=f"âœ… å·²æ”¶è— {name}"))

        elif data.startswith("remove_fav:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            success = remove_from_favorites(uid, name, lat, lon)
            msg = "âœ… å·²ç§»é™¤æœ€æ„›" if success else "âŒ ç§»é™¤å¤±æ•—"
            safe_reply(event, TextSendMessage(text=msg))

        elif data.startswith("confirm_delete:"):
            _, qname, qaddr, lat, lon = data.split(":", 4)
            name = unquote(qname)
            pending_delete_confirm[uid] = {
                "mode": "favorite",
                "name": name,
                "lat": norm_coord(lat),
                "lon": norm_coord(lon)
            }
            safe_reply(event, [
                TextSendMessage(text=f"âš ï¸ ç¢ºå®šè¦åˆªé™¤ {name} å—ï¼Ÿï¼ˆç›®å‰åˆªé™¤ç‚ºç§»é™¤æœ€æ„›ï¼‰"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])

        elif data.startswith("confirm_delete_my_toilet:"):
            _, row_str = data.split(":", 1)
            pending_delete_confirm[uid] = {
                "mode": "sheet_row",
                "row": int(row_str)
            }
            safe_reply(event, [
                TextSendMessage(text="âš ï¸ ç¢ºå®šè¦åˆªé™¤æ­¤ã€ä½ æ–°å¢çš„å»æ‰€ã€å—ï¼Ÿæ­¤å‹•ä½œæœƒå¾ä¸»è³‡æ–™è¡¨åˆªé™¤è©²åˆ—ã€‚"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])
        elif data.startswith("ai_summary:"):
            # data å½¢å¼ï¼šai_summary:<lat>:<lon>
            try:
                _, lat, lon = data.split(":", 2)
            except ValueError:
                safe_reply(event, TextSendMessage(text="æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•æŸ¥è©¢ AI æ‘˜è¦"))
                return

            try:
                # å‘¼å«è‡ªå·±å¾Œç«¯çš„ AI APIï¼ˆç”¨ PUBLIC_URL ç•¶ baseï¼‰
                base = PUBLIC_URL.rstrip("/") if PUBLIC_URL else ""
                q_uid = quote(uid)
                url = f"{base}/api/ai_feedback_summary/{lat}/{lon}?uid={q_uid}"
                resp = requests.get(url, timeout=15)

                if resp.status_code == 200:
                    js = resp.json()
                    if js.get("success") and js.get("summary"):
                        msg = js["summary"]
                    else:
                        msg = js.get("message", "æš«æ™‚ç„¡æ³•å–å¾— AI æ‘˜è¦")
                else:
                    msg = "AI æ‘˜è¦æœå‹™æš«æ™‚å¿™ç¢Œï¼Œè«‹ç¨å¾Œå†è©¦ï½"
            except Exception as e:
                logging.error(f"AI summary postback error: {e}")
                msg = "AI æ‘˜è¦ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"

            safe_reply(event, TextSendMessage(text=msg))

    except Exception as e:
        logging.error(f"âŒ è™•ç† postback å¤±æ•—: {e}")

# === æ–°å¢å»æ‰€é é¢ ===
@app.route("/add", methods=["GET"])
def render_add_page():
    uid = request.args.get("uid", "")
    lat = request.args.get("lat", "")
    lon = request.args.get("lon", "")
    preset_address = ""

    if lat and lon:
        try:
            ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
            url = f"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat={lat}&lon={lon}&addressdetails=1"
            headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                a = data.get("address", {})
                pretty = " ".join(filter(None, [
                    a.get("country", ""),
                    a.get("state", a.get("region", "")),
                    a.get("city", a.get("town", a.get("village", a.get("county", "")))),
                    a.get("suburb", a.get("neighbourhood", "")),
                    a.get("road", ""),
                    a.get("house_number", ""),
                    a.get("postcode", "")
                ])).strip()
                preset_address = pretty or data.get("display_name", "")
        except Exception as e:
            logging.warning(f"reverse geocode å¤±æ•—: {e}")

    return render_template(
        "submit_toilet.html",
        preset_address=preset_address,
        preset_lat=lat,
        preset_lon=lon
    )

# === Sheets å¯«å…¥ä¿è­·ï¼šè¶…é 1e7 cells å°± fallback åˆ°æœ¬æ©Ÿå„²å­˜ ===
_toilet_sheet_over_quota = False
_toilet_sheet_over_quota_ts = 0

def _fallback_store_toilet_row_locally(row_values):
    # CSV + SQLite éƒ½ä¸æ˜¯ thread-safeï¼Œéœ€è¦é–ä½æ•´æ®µ
    with _fallback_lock:

        # 1) é™„åŠ åˆ° public_toilets.csv
        try:
            if not os.path.exists(TOILETS_FILE_PATH):
                with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(PUBLIC_HEADERS)

            header = ensure_toilet_sheet_header(worksheet)
            idx = {h:i for i,h in enumerate(header)}

            def v(col):
                try:
                    return row_values[idx[col]]
                except Exception:
                    return ""

            name = v("name")
            addr = v("address")
            lat_s = v("lat")
            lon_s = v("lon")

            with open(TOILETS_FILE_PATH, "a", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "00000","0000000","æœªçŸ¥é‡Œ","USERADD",
                    name, addr, "ä½¿ç”¨è€…è£œå……",
                    lat_s, lon_s,
                    "æ™®é€šç´š","å…¬å…±å ´æ‰€","æœªçŸ¥","ä½¿ç”¨è€…","0"
                ])

        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³æœ¬åœ° CSV å¤±æ•—ï¼š{e}")

        # 2) å¯«å…¥ SQLite
        try:
            conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
            cur = conn.cursor()
            cur.execute("""
            CREATE TABLE IF NOT EXISTS user_toilets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT, name TEXT, address TEXT,
                lat TEXT, lon TEXT,
                level TEXT, floor_hint TEXT, entrance_hint TEXT,
                access_note TEXT, open_hours TEXT, timestamp TEXT
            )
            """)

            header = ensure_toilet_sheet_header(worksheet)
            idx = {h:i for i,h in enumerate(header)}

            def v(col):
                try:
                    return row_values[idx[col]]
                except:
                    return ""

            cur.execute("""
                INSERT INTO user_toilets (
                    user_id, name, address, lat, lon,
                    level, floor_hint, entrance_hint,
                    access_note, open_hours, timestamp
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                v("user_id"), v("name"), v("address"),
                v("lat"), v("lon"),
                v("level"), v("floor_hint"), v("entrance_hint"),
                v("access_note"), v("open_hours"),
                v("timestamp")
            ))

            conn.commit()
            conn.close()

        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³ SQLite å¤±æ•—ï¼š{e}")

def _append_toilet_row_safely(ws, row_values):
    global _toilet_sheet_over_quota, _toilet_sheet_over_quota_ts

    if _toilet_sheet_over_quota:
        _fallback_store_toilet_row_locally(row_values)
        return ("fallback", "Google è©¦ç®—è¡¨å·²é”å„²å­˜ä¸Šé™ï¼Œæ”¹ç‚ºæš«å­˜æœ¬æ©Ÿã€‚")

    try:
        with _gsheet_lock:
            ws.append_row(row_values, value_input_option="USER_ENTERED")
        return ("ok", "å·²å¯«å…¥ Google è©¦ç®—è¡¨")

    except Exception as e:
        s = str(e)
        if "10000000" in s or "above the limit" in s:
            logging.error("ğŸ§± Google è©¦ç®—è¡¨é”åˆ° 1e7 cells ä¸Šé™ï¼Œå•Ÿç”¨æœ¬æ©Ÿæš«å­˜ã€‚")
            _toilet_sheet_over_quota = True
            _toilet_sheet_over_quota_ts = time.time()
            _fallback_store_toilet_row_locally(row_values)
            return ("fallback", "Google è©¦ç®—è¡¨å·²é”å„²å­˜ä¸Šé™ï¼Œæ”¹ç‚ºæš«å­˜æœ¬æ©Ÿã€‚")

        raise

def _get_db():
    return sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)

def _ensure_pending_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pending_gsheet (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        payload_json TEXT NOT NULL,
        created_ts REAL
    )
    """)
    conn.commit(); conn.close()

_ensure_pending_table()

# === æŸ¥è©¢ç´€éŒ„ search_log ===
def _ensure_search_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS search_log (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id TEXT,
        lat TEXT,
        lon TEXT,
        ts TEXT
    )
    """)
    conn.commit()
    conn.close()

_ensure_search_table()

def _ensure_search_index():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("CREATE INDEX IF NOT EXISTS idx_search_user ON search_log(user_id)")
    conn.commit()
    conn.close()

_ensure_search_index()
# === æŸ¥è©¢ç´€éŒ„ search_log ===
def _ensure_ai_quota_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS ai_quota (
        key TEXT,
        date TEXT,
        count INTEGER,
        PRIMARY KEY(key, date)
    )
    """)
    conn.commit()
    conn.close()

_ensure_ai_quota_table()

def _queue_pending_row(row_values):
    try:
        conn = _get_db(); cur = conn.cursor()
        cur.execute("INSERT INTO pending_gsheet (payload_json, created_ts) VALUES (?, ?)",
                    (json.dumps(row_values, ensure_ascii=False), time.time()))
        conn.commit(); conn.close()
    except Exception as e:
        logging.warning(f"queue pending failed: {e}")

def _drain_pending(limit=200):
    _ensure_sheets_ready()
    if worksheet is None:
        return 0, "worksheet not ready"

    conn = _get_db(); cur = conn.cursor()
    cur.execute("SELECT id, payload_json FROM pending_gsheet ORDER BY id ASC LIMIT ?", (limit,))
    rows = cur.fetchall()
    if not rows:
        conn.close(); return 0, "empty"

    ok = 0
    for row_id, payload in rows:
        try:
            vals = json.loads(payload)
            with _gsheet_lock:
                worksheet.append_row(vals, value_input_option="USER_ENTERED")
            cur.execute("DELETE FROM pending_gsheet WHERE id=?", (row_id,))
            ok += 1
        except Exception as e:
            logging.warning(f"backfill append failed: {e}")
            break
    conn.commit(); conn.close()
    return ok, "done"

@app.route("/admin/backfill", methods=["POST","GET"])
def admin_backfill():
    n, note = _drain_pending(limit=500)
    return {"ok": True, "written": n, "note": note}, 200

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ API ===
@app.route("/submit_toilet", methods=["POST"])
def submit_toilet():
    _ensure_sheets_ready()
    if worksheet is None:
        return {"success": False, "message": "é›²ç«¯è¡¨æ ¼æš«æ™‚ç„¡æ³•é€£ç·šï¼Œè«‹ç¨å¾Œå†è©¦"}, 503
    try:
        data = request.get_json(force=True, silent=False) or {}
        logging.info(f"ğŸ“¥ æ”¶åˆ°è¡¨å–®è³‡æ–™: {data}")

        uid   = (data.get("user_id") or "web").strip()
        name  = (data.get("name") or "").strip()
        addr  = (data.get("address") or "").strip()

        level          = (data.get("level") or "").strip()
        floor_hint     = (data.get("floor_hint") or "").strip()
        entrance_hint  = (data.get("entrance_hint") or "").strip()
        access_note    = (data.get("access_note") or "").strip()
        open_hours     = (data.get("open_hours") or "").strip()

        lat_in = (data.get("lat") or "").strip()
        lon_in = (data.get("lon") or "").strip()

        # å¿…å¡«æª¢æŸ¥
        if not name or not addr:
            return {"success": False, "message": "è«‹æä¾›ã€å»æ‰€åç¨±ã€èˆ‡ã€åœ°å€ã€"}, 400

        # ä½ç½®æè¿°åŸºæœ¬æª¢æŸ¥
        if floor_hint and len(floor_hint) < 4:
            return {"success": False, "message": "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—"}, 400

        # æœªæä¾›ä½ç½®æè¿°å‰‡å˜—è©¦ç”±åç¨±æ¨æ–·
        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        # åº§æ¨™è§£æèˆ‡åœ°ç†ç·¨ç¢¼
        lat_f, lon_f = (None, None)
        if lat_in and lon_in:
            lat_f, lon_f = _parse_lat_lon(lat_in, lon_in)
        if lat_f is None or lon_f is None:
            lat_f, lon_f = geocode_address(addr)
        if lat_f is None or lon_f is None:
            return {"success": False, "message": "åœ°å€è½‰æ›å¤±æ•—ï¼Œè«‹ä¿®æ­£åœ°å€æˆ–æä¾›åº§æ¨™"}, 400

        lat_s, lon_s = norm_coord(lat_f), norm_coord(lon_f)

        # ä½ˆå±€è¡¨é ­ & å¯«å…¥æ¬„ä½
        header = ensure_toilet_sheet_header(worksheet)
        idx = {h: i for i, h in enumerate(header)}

        row_values = [""] * len(header)
        def put(col, val):
            if col in idx:
                row_values[idx[col]] = val

        put("user_id", uid)
        put("name", name)
        put("address", addr)
        put("lat", lat_s)
        put("lon", lon_s)
        put("level", level)
        put("floor_hint", floor_hint)
        put("entrance_hint", entrance_hint)
        put("access_note", access_note)
        put("open_hours", open_hours)
        put("timestamp", datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"))

        # âœ… å®‰å…¨å¯«å…¥ï¼ˆSheets æ»¿æ ¼è‡ªå‹• fallback åˆ°æœ¬æ©Ÿ CSV/SQLiteï¼‰
        status, note = _append_toilet_row_safely(worksheet, row_values)
        logging.info(f"ğŸ“ submit_toilet å¯«å…¥ç‹€æ…‹: {status} ({note}) name={name}")

        if status == "ok":
            return {"success": True, "message": f"âœ… å·²æ–°å¢å»æ‰€ {name}"}
        else:
            # fallbackï¼šè³‡æ–™å·²è½åœ°æœ¬æ©Ÿï¼Œä¹‹å¾Œå¯æ‰¹æ¬¡è£œå¯«åˆ°æ–°è©¦ç®—è¡¨
            return {"success": True, "message": f"âœ… å·²æš«å­˜ {name}ï¼ˆé›²ç«¯è¡¨å·²æ»¿ï¼Œç¨å¾Œå¯æ‰¹æ¬¡è£œå¯«ï¼‰"}

    except Exception as e:
        logging.error(f"âŒ æ–°å¢å»æ‰€éŒ¯èª¤:\n{traceback.format_exc()}")
        return {"success": False, "message": "ä¼ºæœå™¨éŒ¯èª¤"}, 500

# === èƒŒæ™¯æ’ç¨‹ï¼ˆé ç•™ï¼‰ ===
def auto_predict_cleanliness_background():
    while True:
        try:
            logging.info("ğŸŒ€ èƒŒæ™¯æ’ç¨‹å•Ÿå‹•ä¸­ï¼ˆæœªä¾†å¯åŠ å…¥è‡ªå‹•çµ±è¨ˆï¼‰")
        except Exception as e:
            logging.error(f"âŒ èƒŒæ™¯ä»»å‹™å‡ºéŒ¯ï¼š{e}")
        time.sleep(1800)

# === å•Ÿå‹• ===
if __name__ == "__main__":
    threading.Thread(target=auto_predict_cleanliness_background, daemon=True).start()
    threading.Thread(target=_self_keepalive_background, daemon=True).start()

    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port)