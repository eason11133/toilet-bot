import os
import csv
import json
import logging
import sqlite3
import requests
import traceback
import heapq
import math
from collections import OrderedDict
from math import radians, cos, sin, asin, sqrt
from flask_cors import CORS
from flask import Flask, request, abort, render_template, redirect, url_for, Response
from dotenv import load_dotenv
from urllib.parse import quote, unquote, parse_qs
import urllib.parse
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import (
    MessageEvent, TextMessage, LocationMessage,
    TextSendMessage, FlexSendMessage,
    QuickReply, QuickReplyButton, LocationAction, MessageAction,
    PostbackEvent, PostbackAction   
)
from linebot.models import QuickReply, QuickReplyButton
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timezone, timedelta
from openai import OpenAI
import html
import joblib
import threading
import time
import statistics
from difflib import SequenceMatcher
import random
import re

load_dotenv()
try:
    import pandas as pd
except Exception:
    pd = None

# === å…¨åŸŸè¨­å®š ===
def _try_acquire_loc_slot() -> bool:
    try:
        return _LOC_SEM.acquire(blocking=False)
    except Exception:
        return False

def _release_loc_slot():
    try:
        _LOC_SEM.release()
    except Exception:
        pass

# === reply_token ä½¿ç”¨è¨˜éŒ„ï¼ˆæ–°å¢ï¼‰ ===
_USED_REPLY_TOKENS = set()
_USED_REPLY_LOCK = threading.Lock()
_MAX_USED_TOKENS = 50000  # é˜²æ­¢é›†åˆç„¡é™æˆé•·
CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")

def show_loading(uid, seconds=10):
    url = "https://api.line.me/v2/bot/chat/loading/start"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {CHANNEL_ACCESS_TOKEN}"
    }
    payload = {
        "chatId": uid,
        "loadingSeconds": max(5, min(seconds, 60))
    }

    resp = requests.post(url, headers=headers, json=payload)
    logging.info(f"[loading] {resp.status_code} {resp.text}")

def _mark_token_used(tok: str):
    try:
        if not tok:
            return
        with _USED_REPLY_LOCK:
            _USED_REPLY_TOKENS.add(tok)
            if len(_USED_REPLY_TOKENS) > _MAX_USED_TOKENS:
                _USED_REPLY_TOKENS.clear()  # ç°¡å–®æ¸…ç†
    except Exception:
        pass


def _is_token_used(tok: str) -> bool:
    if not tok:
        return False
    try:
        with _USED_REPLY_LOCK:
            return tok in _USED_REPLY_TOKENS
    except Exception:
        return False

def grid_coord(v, g=0.0005):
    """
    åº§æ¨™æ ¼é»åŒ–ï¼š
    g=0.0005 â‰ˆ 50 å…¬å°º
    """
    try:
        return round(float(v) / g) * g
    except Exception:
        return v

class SimpleLRU(OrderedDict):
    def __init__(self, maxsize=500):
        super().__init__()
        self.maxsize = maxsize
    def get(self, key, default=None):
        if key in self:
            self.move_to_end(key)
            return super().get(key)
        return default
    def set(self, key, value):
        super().__setitem__(key, value)
        self.move_to_end(key)
        while len(self) > self.maxsize:
            self.popitem(last=False)

def _in_bbox(lat, lon, clat, clon, radius_m):
    """
    ç²—ç•¥çŸ©å½¢ç¯©é¸ï¼Œå…ˆæ“‹æ‰ä¸å¯èƒ½åœ¨åŠå¾‘å…§çš„é»
    """
    try:
        lat = float(lat); lon = float(lon)
        clat = float(clat); clon = float(clon)
    except Exception:
        return False

    dlat = radius_m / 111000.0
    dlon = radius_m / (111000.0 * math.cos(math.radians(clat)))
    return (
        clat - dlat <= lat <= clat + dlat and
        clon - dlon <= lon <= clon + dlon
    )

CMD_NEARBY = "nearby"
CMD_HELP   = "help"

def infer_cmd_from_text(text: str):
    if not text:
        return None
    t = text.lower().strip()

    # nearby toilets intent (fuzzy)
    if (("nearby" in t and ("toilet" in t or "restroom" in t)) or
        ("toilet" in t and "near" in t)):
        return CMD_NEARBY

    if t in ["help", "usage", "instructions"]:
        return CMD_HELP

    return None

# ------ çµ±ä¸€è¨­å®šï¼ˆå¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼›è‹¥ä½ å·²åœ¨åˆ¥è™•å®šç¾©ï¼Œè«‹ä»¥é€™è£¡ç‚ºæº–ï¼‰------

LOC_MAX_CONCURRENCY = int(os.getenv("LOC_MAX_CONCURRENCY", "3"))      # åŒæ™‚æœ€å¤šå¹¾å€‹ä½¿ç”¨è€…åœ¨è·‘é™„è¿‘æŸ¥è©¢
LOC_QUERY_TIMEOUT_SEC = float(os.getenv("LOC_QUERY_TIMEOUT_SEC", "3.0"))  # å„è³‡æ–™æºé€¾æ™‚ï¼ˆç§’ï¼‰
LOC_MAX_RESULTS = int(os.getenv("LOC_MAX_RESULTS", "4"))             # æœ€å¤šå›å¹¾å€‹

SHOW_SEARCHING_BUBBLE = False
_LOC_SEM = threading.Semaphore(LOC_MAX_CONCURRENCY)
ENRICH_MAX_ITEMS    = int(os.getenv("ENRICH_MAX_ITEMS", "60"))
OVERPASS_MAX_ITEMS  = int(os.getenv("OVERPASS_MAX_ITEMS", "60"))
ENRICH_LRU_SIZE     = int(os.getenv("ENRICH_LRU_SIZE", "300"))
NEARBY_LRU_SIZE     = int(os.getenv("NEARBY_LRU_SIZE", "300"))

FEEDBACK_INDEX_TTL  = int(os.getenv("FEEDBACK_INDEX_TTL", "180"))  # ç”± 60 â†’ 180
STATUS_INDEX_TTL    = int(os.getenv("STATUS_INDEX_TTL", "180"))    # ç”± 60 â†’ 180
MAX_SHEET_ROWS      = int(os.getenv("MAX_SHEET_ROWS", "4000"))     # åªè®€å°¾ç«¯ N åˆ—

# === internal TTL aliases (single source of truth) ===
_FEEDBACK_INDEX_TTL = int(os.getenv("FEEDBACK_INDEX_TTL_SEC", str(FEEDBACK_INDEX_TTL)))
_STATUS_INDEX_TTL   = int(os.getenv("STATUS_INDEX_TTL_SEC",   str(STATUS_INDEX_TTL)))

# ------ å°‡åŸæœ¬çš„ dict æ›æˆ LRUï¼ˆâš ï¸ åˆ¥åœ¨æª”æ¡ˆå…¶ä»–åœ°æ–¹å†è³¦å€¼è¦†è“‹å®ƒå€‘ï¼‰------
_ENRICH_CACHE = SimpleLRU(maxsize=ENRICH_LRU_SIZE)
_CACHE        = SimpleLRU(maxsize=NEARBY_LRU_SIZE)

# ï¼ˆå¯é¸ï¼‰å•Ÿå‹•æ™‚å°å‡ºå¿«å–å‹åˆ¥ï¼Œæ–¹ä¾¿æª¢æŸ¥æ²’æœ‰è¢«è¦†è“‹å› dict
try:
    logging.info(f"ğŸ” ENRICH_CACHE={_ENRICH_CACHE.__class__.__name__} NEARBY_CACHE={_CACHE.__class__.__name__}")
except Exception:
    pass

# ======================== Sheets å®‰å…¨å¤–æ›å±¤ï¼ˆæ²¿ç”¨ä½ ç¾æœ‰çš„è¨­å®šå³å¯ï¼‰ ========================
SHEETS_MAX_CONCURRENCY = int(os.getenv("SHEETS_MAX_CONCURRENCY", "4"))
SHEETS_RETRY_MAX = int(os.getenv("SHEETS_RETRY_MAX", "6"))
SHEETS_READ_TTL_SEC = int(os.getenv("SHEETS_READ_TTL_SEC", "45"))
SHEETS_CACHE_MAX_ROWS = int(os.getenv("SHEETS_CACHE_MAX_ROWS", "20000"))

_sheets_sem = threading.Semaphore(SHEETS_MAX_CONCURRENCY)
_read_cache = {}            # key: (sheet_id, ws_title, op) -> {ts, val}
_cache_lock = threading.Lock()
_gsheet_lock = threading.Lock()
_fallback_lock = threading.Lock()

def _is_quota_or_retryable(exc: Exception) -> bool:
    s = str(exc).lower()
    return ("429" in s or "quota" in s or "rate limit" in s or
            "timeout" in s or "timed out" in s or "503" in s or "500" in s)

def delay_request():
    delay_time = random.uniform(0.5, 1.5)  # éš¨æ©Ÿå»¶é²æ™‚é–“ï¼Œæ ¹æ“šéœ€æ±‚èª¿æ•´
    time.sleep(delay_time)

def _with_retry(func, *args, **kwargs):
    backoff = 0.7
    last_exc = None
    for i in range(SHEETS_RETRY_MAX):
        try:
            with _sheets_sem:
                return func(*args, **kwargs)
        except Exception as e:
            last_exc = e
            if _is_quota_or_retryable(e):
                delay_request()
                sleep_s = backoff * (2 ** i) + random.uniform(0, 0.25*i)
                time.sleep(sleep_s)
                continue
            raise
    raise last_exc if last_exc else RuntimeError("Sheets retry exhausted")

def batch_query_sheets(query_keys):
    # åŒæ™‚æŸ¥è©¢å¤šå€‹å¿«å–çš„è³‡æ–™
    results = []
    for key in query_keys:
        cached_data = get_cached_data(key)
        if cached_data:
            results.append(cached_data)
        else:
            results.append(None)  # è‹¥ç„¡å¿«å–ï¼Œæœƒå†é€²è¡Œ API è«‹æ±‚
    return results

def retry_request(func, *args, **kwargs):
    retries = 3
    for i in range(retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if i < retries - 1:
                time.sleep(2 ** i)  # Exponential backoff
                continue
            else:
                raise e

class SafeWS:
    def __init__(self, ws, sheet_id: str, name: str):
        self._ws = ws
        self._sheet_id = sheet_id
        self._name = name

    # ---------- è®€å–ï¼ˆå«å¿«å–ï¼‰ ----------
    def get_all_values(self):
        key = (self._sheet_id, self._name, "get_all_values")
        now = time.time()
        with _cache_lock:
            c = _read_cache.get(key)
            if c and now - c["ts"] < SHEETS_READ_TTL_SEC:
                return c["val"]

        def _do():
            return self._ws.get_all_values()

        val = _with_retry(_do)
        # åªå¿«å–åˆç†å¤§å°ï¼Œé¿å…æŠŠæ•´å€‹è¶…å¤§è¡¨å¡é€²è¨˜æ†¶é«”
        if isinstance(val, list) and len(val) <= SHEETS_CACHE_MAX_ROWS:
            with _cache_lock:
                _read_cache[key] = {"ts": now, "val": val}
        return val

    def row_values(self, i):
        return _with_retry(self._ws.row_values, i)

    # âœ… æ–°å¢ï¼šçµ¦ _get_header_and_tail / è¼•é‡ä¼°ç®—ç¸½åˆ—æ•¸ç”¨
    def col_values(self, i):
        return _with_retry(self._ws.col_values, i)

    # âœ… æ–°å¢ï¼šçµ¦å€æ®µè®€å–ï¼ˆå¦‚ "A2:AZ100"ï¼‰
    def get(self, rng):
        return _with_retry(self._ws.get, rng)

    # ---------- å¯«å…¥ï¼ˆæˆåŠŸå¾Œå¤±æ•ˆå¿«å–ï¼‰ ----------
    def _invalidate(self):
        key = (self._sheet_id, self._name, "get_all_values")
        with _cache_lock:
            _read_cache.pop(key, None)

    def update(self, rng, values):
        def _do():
            return self._ws.update(rng, values)
        out = _with_retry(_do)
        self._invalidate()
        return out

    def append_row(self, values, value_input_option="RAW"):
        def _do():
            return self._ws.append_row(values, value_input_option=value_input_option)
        out = _with_retry(_do)
        self._invalidate()
        return out

    def delete_rows(self, index):
        def _do():
            return self._ws.delete_rows(index)
        out = _with_retry(_do)
        self._invalidate()
        return out

    # ---------- å…¶ä»– ----------
    def worksheet(self, title):
        # å–å¾—åŒè©¦ç®—è¡¨å…§çš„å…¶ä»–å·¥ä½œè¡¨ï¼ŒæŒçºŒæ²¿ç”¨ SafeWS åŒ…è£
        return self.__class__(self._ws.worksheet(title), self._sheet_id, title)

    @property
    def title(self):
        return self._ws.title

# ä½¿ç”¨è€…èªè¨€ï¼ˆè¨˜æ†¶é«”ç‰ˆï¼Œä¹‹å¾Œå¯æ› DBï¼‰
user_lang = {}

def set_user_lang(uid: str, lang: str):
    try:
        if not uid:
            return
        lang = "en" if (lang or "").lower() == "en" else "zh"
        conn = _get_db()
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO user_lang (user_id, lang)
            VALUES (?, ?)
            ON CONFLICT(user_id) DO UPDATE SET lang=excluded.lang
        """, (uid, lang))
        conn.commit()
        conn.close()
    except Exception as e:
        logging.warning(f"set_user_lang failed: {e}")

def get_user_lang(uid: str) -> str:
    try:
        if not uid:
            return "zh"
        conn = _get_db()
        cur = conn.cursor()
        cur.execute("SELECT lang FROM user_lang WHERE user_id=?", (uid,))
        row = cur.fetchone()
        conn.close()
        if row and row[0] == "en":
            return "en"
        return "zh"
    except Exception as e:
        logging.warning(f"get_user_lang failed: {e}")
        return "zh"


TEXTS = {
    "nearby_toilet": {
        "zh": "é™„è¿‘å»æ‰€",
        "en": "Nearby toilets"
    },
    "ask_location": {
        "zh": "è«‹å‚³é€ä½ çš„ä½ç½®",
        "en": "Please share your location"
    },
    "no_result": {
        "zh": "é™„è¿‘æ²’æœ‰æ‰¾åˆ°å»æ‰€",
        "en": "No toilets found nearby"
    },
    "loading": {
        "zh": "æŸ¥è©¢ä¸­ï¼Œè«‹ç¨å€™â€¦",
        "en": "Searching, please waitâ€¦"
    },
    "added_favorite": {
        "zh": "å·²åŠ å…¥æœ€æ„› â­",
        "en": "Added to favorites â­"
    },
    "removed_favorite": {
        "zh": "å·²ç§»é™¤æœ€æ„›",
        "en": "Removed from favorites"
    },
}

TEXTS.update({
    "ask_location_normal": {
        "zh": "ğŸ“ è«‹é»ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘ç«‹åˆ»å¹«ä½ æ‰¾å»æ‰€",
        "en": "ğŸ“ Please share your location and Iâ€™ll find nearby toilets for you"
    },
    "ask_location_ai": {
        "zh": "ğŸ“ è«‹é»ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘æœƒç”¨ AI å¹«ä½ æŒ‘é™„è¿‘çš„å»æ‰€",
        "en": "ğŸ“ Please share your location and Iâ€™ll use AI to recommend nearby toilets"
    },
    "added_fav_ok": {
        "zh": "âœ… å·²æ”¶è— {name}",
        "en": "âœ… Added {name} to favorites"
    },
    "removed_fav_ok": {
        "zh": "âœ… å·²ç§»é™¤æœ€æ„›",
        "en": "âœ… Removed from favorites"
    },
    "removed_fav_fail": {
        "zh": "âŒ ç§»é™¤å¤±æ•—",
        "en": "âŒ Failed to remove"
    },
    "confirm_delete": {
        "zh": "âš ï¸ ç¢ºå®šè¦åˆªé™¤ {name} å—ï¼Ÿï¼ˆç›®å‰åˆªé™¤ç‚ºç§»é™¤æœ€æ„›ï¼‰",
        "en": "âš ï¸ Are you sure you want to remove {name} from favorites?"
    },
    "confirm_hint": {
        "zh": "è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€",
        "en": "Please type â€œConfirm deleteâ€ or â€œCancelâ€"
    }

    ,
    "busy_try_later": {
        "zh": "ç³»çµ±å¿™ç·šä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™",
        "en": "System is busy. Please try again later ğŸ™"
    },
    "lang_switch_fail": {
        "zh": "âŒ åˆ‡æ›èªè¨€å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦",
        "en": "âŒ Failed to switch language. Please try again later."
    },
    "menu_switched": {
        "zh": "âœ… å·²åˆ‡æ›é¸å–®",
        "en": "âœ… Menu switched"
    },
    "lang_switched_en": {
        "zh": "âœ… å·²åˆ‡æ›ç‚ºè‹±æ–‡",
        "en": "âœ… Language switched to English"
    },
    "lang_switched_zh": {
        "zh": "âœ… å·²åˆ‡æ›ç‚ºä¸­æ–‡",
        "en": "âœ… Language switched to Chinese"
    },
    "ai_summary_limit": {
        "zh": "ä½ ä»Šå¤©çš„ AI æ‘˜è¦æ¬¡æ•¸å·²ç”¨å®Œï¼Œæ˜å¤©å†è©¦è©¦çœ‹ ğŸ™",
        "en": "Youâ€™ve reached todayâ€™s AI summary limit. Please try again tomorrow ğŸ™"
    },
    "help_text": {
        "zh": "ğŸ“Œ ä½¿ç”¨èªªæ˜ï¼š\nâ€¢ é»ã€é™„è¿‘å»æ‰€ã€æˆ–ç›´æ¥å‚³ä½ç½®\nâ€¢ ä½ å¯ä»¥æ”¶è—æœ€æ„›ã€ç•™ä¸‹å›é¥‹ã€æŸ¥çœ‹ AI æ‘˜è¦\nâ€¢ ä¹Ÿå¯ä»¥åˆ‡æ›åˆ° AI æ¨è–¦æ¨¡å¼",
        "en": "ğŸ“Œ Help:\nâ€¢ Tap 'Nearby Toilets' or send location\nâ€¢ Add favorites, leave feedback, view AI summary\nâ€¢ You can also switch to AI recommendation mode"
    }
})


# =========================
# âœ… çµ±ä¸€èªè¨€/ç¿»è­¯å…¥å£ï¼ˆå”¯ä¸€å…¥å£ï¼‰
# - LINEï¼šç”¨ uid æ±ºå®šèªè¨€ï¼ˆget_user_langï¼‰
# - APIï¼šç”¨ ?lang=en æ±ºå®šèªè¨€ï¼ˆrequest.argsï¼‰
# - èˆŠå‡½å¼ t/L/_api_L/_api_T ä»ä¿ç•™ï¼Œä½†å…¨éƒ¨æ”¹èµ°é€™è£¡
# =========================

def _api_lang():
    # API æ²’æœ‰ LINE uid æ™‚ï¼Œç”¨ querystring æ§åˆ¶èªè¨€ï¼š?lang=en
    lang = (request.args.get("lang") or "").strip().lower()
    return "en" if lang == "en" else "zh"

def resolve_lang(uid=None, lang=None):
    # 1) æ˜ç¢ºæŒ‡å®š langï¼ˆæœ€å„ªå…ˆï¼‰
    if (lang or "").lower() == "en":
        return "en"
    if (lang or "").lower() == "zh":
        return "zh"

    # 2) æœ‰ uid â†’ èµ°ä½¿ç”¨è€…èªè¨€
    if uid:
        try:
            return "en" if get_user_lang(uid) == "en" else "zh"
        except Exception:
            return "zh"

    # 3) ç„¡ uid â†’ è¦–ç‚º API â†’ èµ° querystring
    return _api_lang()

def T(key_or_zh, uid=None, en=None, lang=None, **fmt):
    """
    âœ… çµ±ä¸€ç¿»è­¯å‡½å¼ï¼ˆå…¨æ¡ˆå”¯ä¸€å…¥å£ï¼‰
    ç”¨æ³•ï¼š
    1) key æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰ï¼šT("no_result", uid=uid)  â†’ å¾ TEXTS æŠ“ zh/en
    2) zh/en æ¨¡å¼ï¼ˆç›¸å®¹èˆŠç¢¼ï¼‰ï¼šT("é™„è¿‘æ²’æœ‰å»æ‰€", uid=uid, en="No toilets nearby")
    3) API æ¨¡å¼ï¼šT("missing_params", lang=_api_lang())
    4) æ”¯æ´ formatï¼šT("added_fav_ok", uid=uid, name="xxx")
    """
    l = resolve_lang(uid=uid, lang=lang)

    # key æ¨¡å¼ï¼šen is Noneï¼Œä¸” key åœ¨ TEXTS
    if en is None and isinstance(key_or_zh, str) and key_or_zh in TEXTS:
        s = TEXTS[key_or_zh].get(l, TEXTS[key_or_zh].get("zh", "")) or ""
    else:
        # zh/en æ¨¡å¼ï¼ˆç›¸å®¹ï¼‰
        s = (en if l == "en" else key_or_zh) if en is not None else (key_or_zh or "")

    # formatï¼ˆå®¹éŒ¯ï¼‰
    try:
        return s.format(**fmt)
    except Exception:
        return s

# ---- èˆŠå‡½å¼ç›¸å®¹å±¤ï¼ˆå…¨éƒ¨å°åˆ° Tï¼‰----

def t(key, uid):
    return T(key, uid=uid)

def L(uid, zh_or_key, en=None):
    # èˆŠ L(uid, "key") æˆ– L(uid, "ä¸­æ–‡", "English") éƒ½èƒ½ç”¨
    return T(zh_or_key, uid=uid, en=en)

def _api_L(zh, en):
    # èˆŠ API ç¿»è­¯ï¼ˆç›¸å®¹ï¼‰
    return T(zh, lang=_api_lang(), en=en)

# âœ… æŠŠ API_TEXTS ä½µå…¥ TEXTSï¼ˆé¿å…å†å¤šä¸€å¥—å­—å…¸ï¼‰
API_TEXTS = {
    "missing_params": ("ç¼ºå°‘åƒæ•¸", "Missing parameters"),
    "invalid_params": ("åƒæ•¸éŒ¯èª¤", "Invalid parameters"),
    "not_found": ("æ‰¾ä¸åˆ°è³‡æ–™", "Data not found"),
    "write_failed": ("å¯«å…¥å¤±æ•—", "Write failed"),
    "server_error": ("ä¼ºæœå™¨éŒ¯èª¤", "Server error"),
}
for k, (zh, en) in API_TEXTS.items():
    if k not in TEXTS:
        TEXTS[k] = {"zh": zh, "en": en}

def _api_T(key: str):
    # èˆŠ _api_Tï¼ˆç›¸å®¹ï¼‰
    return T(key, lang=_api_lang())


# === consent èƒŒæ™¯æ’éšŠï¼ˆ429 æ™‚ä¸å› 500ï¼‰ ===
_consent_q = []                    
_consent_lock = threading.Lock()    

def _start_consent_worker():
    def loop():
        while True:
            job = None
            try:
                # å–å‡ºä¸€å€‹å·¥ä½œ
                with _consent_lock:
                    if _consent_q:
                        job = _consent_q.pop(0)
            except Exception as e:
                logging.error(f"Consent worker dequeue error: {e}")

            if not job:
                time.sleep(0.2)
                continue

            try:
                job()  # åŸ·è¡Œè£œå¯«
            except Exception as e:
                logging.error(f"Consent worker error: {e}")

    t = threading.Thread(target=loop, name="consent-worker", daemon=True)
    t.start()

_start_consent_worker()

def make_location_quick_reply(prompt_text, mode="normal", uid=None):
    """
    prompt_text: ä¸»è¨Šæ¯æ–‡å­—ï¼ˆå»ºè­°å‘¼å«å‰å°±ç”¨ L(uid, zh, en) ç”¢å¥½ï¼‰
    mode: "normal" or "ai"
    uid: LINE user idï¼ˆç”¨ä¾†åˆ¤æ–·èªè¨€ï¼‰
    """

    # é˜²å‘†ï¼šå¦‚æœæ²’å‚³ uidï¼Œå°±ç”¨ä¸­æ–‡
    def _L(zh, en):
        return L(uid, zh, en) if uid else zh

    items = [
        QuickReplyButton(
            action=LocationAction(
                label=_L("å‚³é€æˆ‘çš„ä½ç½®", "Share location")
            )
        )
    ]

    if mode == "normal":
        # ğŸ‘‰ åˆ‡æ›åˆ° AI æ¨¡å¼ï¼ˆèµ° postbackï¼Œä¸å†é€æ–‡å­—ï¼‰
        items.append(
            QuickReplyButton(
                action=PostbackAction(
                    label=_L("AI æ¨è–¦é™„è¿‘å»æ‰€", "AI nearby"),
                    data="ask_ai_location",
                    display_text=_L("åˆ‡æ›æˆ AI æ¨è–¦æ¨¡å¼", "Switch to AI mode")
                )
            )
        )
    else:  # mode == "ai"
        # ğŸ‘‰ åˆ‡å›ä¸€èˆ¬æ¨¡å¼
        items.append(
            QuickReplyButton(
                action=PostbackAction(
                    label=_L("åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼", "Normal mode"),
                    data="ask_location",
                    display_text=_L("åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼", "Switch to normal mode")
                )
            )
        )

    return TextSendMessage(
        text=prompt_text,
        quick_reply=QuickReply(items=items)
    )

def make_retry_location_text(uid=None):
    return TextSendMessage(
        text=L(uid,
               "ç¾åœ¨æŸ¥è©¢äººæ•¸æœ‰é»å¤šï¼Œæˆ‘æ’ä¸€ä¸‹éšŠï¼›ä½ å¯å†å‚³ä¸€æ¬¡ä½ç½®æˆ–ç¨å€™å¹¾ç§’ï½",
               "Too many requests now. Please send your location again or try in a few seconds."),
        quick_reply=QuickReply(items=[
            QuickReplyButton(action=LocationAction(label=L(uid, "å‚³é€æˆ‘çš„ä½ç½®", "Share location")))
        ])
    )

def make_no_toilet_quick_reply(uid, lat=None, lon=None):
    return TextSendMessage(
        text=L(uid, "é™„è¿‘æ²’æœ‰å»æ‰€ ğŸ˜¥ è¦ä¸è¦è£œä¸Šä¸€é–“ï¼Ÿ",
                  "No toilets nearby ğŸ˜¥ Want to add one?"),
        quick_reply=QuickReply(items=[
            QuickReplyButton(action=LocationAction(label=L(uid, "å‚³é€æˆ‘çš„ä½ç½®", "Share location"))),
            QuickReplyButton(action=MessageAction(label=L(uid, "æ–°å¢å»æ‰€", "Add toilet"),
                                                  text=L(uid, "æ–°å¢å»æ‰€", "Add toilet")))
        ])
    )

# === åˆå§‹åŒ– ===
logging.basicConfig(level=logging.INFO)
app = Flask(__name__)
CORS(app)

class _NoHealthzFilter(logging.Filter):
    def filter(self, record):
        try:
            msg = record.getMessage()
        except Exception:
            return True
        return "/healthz" not in msg

# === å®‰å…¨æ¨™é ­èˆ‡å¿«å–ç­–ç•¥ï¼ˆæ–°å¢ï¼‰ ===
@app.after_request
def add_security_headers(resp):
    """å®‰å…¨æ¨™é ­èˆ‡å¿«å–ç­–ç•¥
    - ä¸€èˆ¬é é¢ï¼šç¦æ­¢è¢« iframeï¼ˆXFO=DENY + frame-ancestors 'none'ï¼‰
    - LIFF/åŒæ„/å›é¥‹ç­‰é é¢ï¼šéœ€è¦åœ¨ LINE/LIFF WebView è£¡é–‹å•Ÿï¼Œå¿…é ˆæ”¾å¯¬ frame-ancestors èˆ‡ script/connect ç™½åå–®
    """
    try:
        resp.headers.setdefault("Cache-Control", "no-store")
        resp.headers.setdefault("Pragma", "no-cache")
        resp.headers.setdefault("X-Content-Type-Options", "nosniff")
        resp.headers.setdefault("Referrer-Policy", "strict-origin-when-cross-origin")

        path = (request.path or "").lower()

        # éœ€è¦åœ¨ LIFF WebView / LINE å…§åµŒé–‹å•Ÿçš„é é¢ï¼ˆè«‹ä¾ä½ çš„å¯¦éš›è·¯ç”±å†å¢æ¸›ï¼‰
        is_liff_page = (
            path.startswith("/status_liff")
            or path.startswith("/toilet_feedback_by_coord")
            or path.startswith("/feedback_form")
            or path.startswith("/add")
            or path.startswith("/consent")
        )

        if is_liff_page:
            # âœ… LIFF éœ€è¦å…è¨±è¢« LINE/LIFF å…§åµŒ
            # X-Frame-Options å»ºè­°ä¸è¦ç”¨ DENYï¼ˆæœƒæ“‹ iframe / webviewï¼‰ï¼Œæ”¹æˆ SAMEORIGINï¼ˆæˆ–ä¹¾è„†ä¸è¨­ï¼‰
            resp.headers["X-Frame-Options"] = "SAMEORIGIN"

            # âœ… CSPï¼šå…è¨± LIFF SDKã€Chart.jsã€ä»¥åŠ LIFF å¯èƒ½ç”¨åˆ°çš„ API/é€£ç·š
            csp = [
                "default-src 'self'",
                "img-src 'self' data: https:",
                "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://static.line-scdn.net https://cdn.jsdelivr.net https://cdnjs.cloudflare.com https://unpkg.com",
                "style-src 'self' 'unsafe-inline'",
                "connect-src 'self' https: https://api.line.me https://access.line.me",
                "font-src 'self' data: https:",
                # å…è¨± LINE/LIFF å…§åµŒï¼ˆå¦‚éœ€ä¹Ÿå¯åŠ ä¸Šç‰¹å®š domainï¼‰
                "frame-ancestors 'self' https://access.line.me https://liff.line.me",
            ]
            resp.headers["Content-Security-Policy"] = "; ".join(csp) + ";"
        else:
            # âœ… é LIFF é é¢ï¼šæ›´åš´æ ¼
            resp.headers.setdefault("X-Frame-Options", "DENY")
            csp = [
                "default-src 'self'",
                "img-src 'self' data: https:",
                "script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net https://cdnjs.cloudflare.com https://unpkg.com",
                "style-src 'self' 'unsafe-inline'",
                "connect-src 'self' https:",
                "font-src 'self' data: https:",
                "frame-ancestors 'none'",
            ]
            resp.headers["Content-Security-Policy"] = "; ".join(csp) + ";"
    except Exception as e:
        logging.debug(f"add_security_headers skipped: {e}")
    return resp

# === å°±ç·’æª¢æŸ¥ç«¯é»ï¼ˆæ–°å¢ï¼‰ ===
@app.route("/readyz", methods=["GET", "HEAD"])
def readyz():
    _ensure_sheets_ready()
    ok = (worksheet is not None) and (feedback_sheet is not None) and (consent_ws is not None)
    status = 200 if ok else 503
    msg = "ready" if ok else "not-ready"
    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-store",
        "X-Robots-Tag": "noindex",
    }
    if request.method == "HEAD":
        return Response(status=204 if ok else 503, headers=headers)
    return Response(msg, status=status, headers=headers)

logging.getLogger("werkzeug").addFilter(_NoHealthzFilter())

# === å¥åº·æª¢æŸ¥ç«¯é» ===
@app.route("/healthz", methods=["GET", "HEAD"])
def healthz():
    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-store",
        "X-Robots-Tag": "noindex",
    }
    if request.method == "HEAD":
        return Response(status=204, headers=headers)
    return Response("ok", status=200, headers=headers)

# === è‡ªæˆ‘æ¿€æ´»è¨­å®š ===
KEEPALIVE_URL = (
    os.getenv("KEEPALIVE_URL")
    or (os.getenv("PUBLIC_URL") and os.getenv("PUBLIC_URL").rstrip("/") + "/healthz")
    or (os.getenv("RENDER_EXTERNAL_URL") and os.getenv("RENDER_EXTERNAL_URL").rstrip("/") + "/healthz")
)
KEEPALIVE_ENABLE = os.getenv("KEEPALIVE_ENABLE", "1") == "1"
KEEPALIVE_INTERVAL_SECONDS = int(os.getenv("KEEPALIVE_INTERVAL_SECONDS", "600"))
KEEPALIVE_JITTER_SECONDS   = int(os.getenv("KEEPALIVE_JITTER_SECONDS", "60"))

def _self_keepalive_background():
    if not KEEPALIVE_ENABLE or not KEEPALIVE_URL:
        logging.info("â­ï¸ keepalive disabled (no URL or disabled by env).")
        return
    headers = {"User-Agent": f"SelfKeepalive/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}
    while True:
        try:
            requests.head(KEEPALIVE_URL, timeout=8, headers=headers)
            logging.debug("âœ… keepalive ok")
        except Exception as e:
            logging.debug(f"âš ï¸ keepalive failed: {e}")
        sleep_for = KEEPALIVE_INTERVAL_SECONDS + random.randint(0, KEEPALIVE_JITTER_SECONDS)
        time.sleep(sleep_for)

line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

# === å…±ç”¨ base urlï¼ˆé¿å…ç¡¬å¯« domainï¼‰===
def _base_url():
    # PUBLIC_URL å„ªå…ˆï¼Œæ²’è¨­å®šå°±ç”¨ request.url_root
    try:
        if PUBLIC_URL:
            return PUBLIC_URL.rstrip("/")
        return request.url_root.rstrip("/")
    except Exception:
        # ä¿åº•ï¼šè‡³å°‘ä¸è¦å™´éŒ¯
        return (PUBLIC_URL or "").rstrip("/")


def _append_uid_lang(url: str, uid: str, lang: str = None, extra: dict = None) -> str:
    """æŠŠ uid/lang å®‰å…¨åœ°åŠ åˆ° URL querystringï¼ˆé¿å… LIFF é é¢æ‹¿ä¸åˆ°èªè¨€ï¼‰"""
    try:
        if not uid and not lang and not extra:
            return url
        parsed = urllib.parse.urlparse(url)
        qs = dict(urllib.parse.parse_qsl(parsed.query, keep_blank_values=True))
        if uid:
            qs.setdefault("uid", uid)
        if lang:
            qs.setdefault("lang", "en" if (lang or '').lower().startswith('en') else "zh")
        if extra:
            for k, v in extra.items():
                if v is None:
                    continue
                qs.setdefault(str(k), str(v))
        new_q = urllib.parse.urlencode(qs)
        return urllib.parse.urlunparse(parsed._replace(query=new_q))
    except Exception:
        return url

def _user_lang_q(uid: str) -> str:
    try:
        return "en" if get_user_lang(uid) == "en" else "zh"
    except Exception:
        return "zh"

def get_nearby_toilets(uid, lat, lon):
    key = f"{lat},{lon}"
    cached = _CACHE.get(key)
    if cached is not None:
        return cached
    toilets = query_public_csv_toilets(lat, lon)
    _CACHE.set(key, toilets)
    return toilets

# === æª”æ¡ˆ ===
DATA_DIR = os.path.join(os.getcwd(), "data")
TOILETS_FILE_PATH = os.path.join(DATA_DIR, "public_toilets.csv")
FAVORITES_FILE_PATH = os.path.join(DATA_DIR, "favorites.txt")
_FAV_LOCK = threading.Lock()
os.makedirs(DATA_DIR, exist_ok=True)

if not os.path.exists(FAVORITES_FILE_PATH):
    open(FAVORITES_FILE_PATH, "a", encoding="utf-8").close()

PUBLIC_HEADERS = [
    "country","city","village","number","name","address","administration",
    "latitude","longitude","grade","type2","type","exec","diaper"
]
if not os.path.exists(TOILETS_FILE_PATH):
    with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(PUBLIC_HEADERS)

# === Google Sheets è¨­å®š ===
GSHEET_SCOPE = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
GSHEET_CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON")
TOILET_SPREADSHEET_ID = "1Vg3tiqlXcXjcic2cAWCG-xTXfNzcI7wegEnZx8Ak7ys"
FEEDBACK_SPREADSHEET_ID = "15Ram7EZ9QMN6SZAVYQFNpL5gu4vTaRn4M5mpWUKmmZk"

# === åŒæ„æ›¸è¨­å®š ===
CONSENT_SHEET_TITLE = "consent"
CONSENT_PAGE_URL = os.getenv("CONSENT_PAGE_URL", "https://school-i9co.onrender.com/consent")

gc = worksheet = feedback_sheet = consent_ws = None

# === ç‹€æ…‹å›å ±è¨­å®š ===
STATUS_SHEET_TITLE = "status"
status_ws = None

# è¿‘é»/å¿«å–/æœ‰æ•ˆæœŸ
_STATUS_NEAR_M = 35
_STATUS_TTL_HOURS = 6
_status_index_cache = {"ts": 0, "data": {}}
# _STATUS_INDEX_TTL is defined in global config section (see above)
# MAX_SHEET_ROWS is defined in global config section (see above)
def _a1_col(n: int) -> str:
    if n <= 0:
        return "A"
    out = []
    while n > 0:
        n, r = divmod(n - 1, 26)
        out.append(chr(65 + r))
    return "".join(reversed(out))


def _get_header_and_tail(ws, max_rows: int = MAX_SHEET_ROWS):
    try:
        max_rows = int(max_rows)
        if max_rows <= 0:
            max_rows = 1
    except Exception:
        max_rows = 1000  

    try:
        header = ws.row_values(1) or []
        if not header:
            return [], []

        col_a = ws.col_values(1) or []
        last_row = len(col_a)
        if last_row < 2:  
            return header, []

        start_row = max(2, last_row - max_rows + 1)

        end_col = _a1_col(max(1, len(header)))
        rng = f"A{start_row}:{end_col}{last_row}"

        data = ws.get(rng) or []
        return header, data

    except Exception as e:
        logging.warning(f"_get_header_and_tail primary path failed: {e}")

        # === Fallbackï¼šä¸€æ¬¡æŠ“ï¼Œç„¶å¾Œåªä¿ç•™å°¾ç«¯ max_rowsï¼Œé¿å…ä½”è¨˜æ†¶é«” ===
        try:
            rows = ws.get_all_values() or []
            if not rows:
                return [], []
            header = rows[0]
            data = rows[1:]
            if len(data) > max_rows:
                data = data[-max_rows:]
            return header, data
        except Exception as e2:
            logging.warning(f"_get_header_and_tail fallback failed: {e2}")
            return [], []

# === è¼‰å…¥æ¨¡å‹ ===
BASE_DIR = os.path.abspath(os.path.dirname(__file__))

def load_cleanliness_model():
    try:
        model_path = os.path.join(BASE_DIR, 'models', 'clean_model.pkl')
        model = joblib.load(model_path)
        logging.info("âœ… æ¸…æ½”åº¦æ¨¡å‹å·²è¼‰å…¥")
        return model
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def load_label_encoder():
    try:
        encoder_path = os.path.join(BASE_DIR, 'models', 'label_encoder.pkl')
        encoder = joblib.load(encoder_path)
        logging.info("âœ… LabelEncoder å·²è¼‰å…¥")
        return encoder
    except Exception as e:
        logging.error(f"âŒ LabelEncoder è¼‰å…¥å¤±æ•—: {e}")
        return None

cleanliness_model = load_cleanliness_model()
label_encoder = load_label_encoder()

# === åƒæ•¸ ===
LAST_N_HISTORY = 5

# === å·¥å…·ï¼šåº§æ¨™æ¨™æº–åŒ–ï¼è§£æ ===
def norm_coord(x, ndigits=6):
    try:
        return f"{round(float(x), ndigits):.{ndigits}f}"
    except:
        return str(x)
    
def safe_html(s):
    return html.escape(s or "")

def _parse_lat_lon(lat_s, lon_s):
    try:
        lat = float(str(lat_s).strip())
        lon = float(str(lon_s).strip())
    except Exception:
        return None, None
    if abs(lat) > 90 and abs(lon) <= 90:
        lat, lon = lon, lat
    if not (-90 <= lat <= 90 and -180 <= lon <= 180):
        return None, None
    return lat, lon

# === LIFF è¨­å®š ===
PUBLIC_URL = (os.getenv("PUBLIC_URL") or "").rstrip("/")
LIFF_STATUS_ID = os.getenv("LIFF_STATUS_ID", "")

def _status_liff_url(lat=None, lon=None, uid=None):
    """å›å‚³ç‹€æ…‹å›å ± LIFF é é¢ç¶²å€ã€‚

    âœ… é‡è¦ï¼šLIFF ç¶²é æœ¬èº«ä¸æœƒè‡ªå‹•çŸ¥é“ä½ åœ¨ LINE è£¡åˆ‡åˆ°å“ªå€‹èªè¨€ï¼Œæ‰€ä»¥æˆ‘å€‘åœ¨ URL ä¸Šå¸¶ï¼š
      - uidï¼šè®“å¾Œç«¯å¯ä»¥æŸ¥ get_user_lang(uid)
      - langï¼šè®“å‰ç«¯ï¼ˆæˆ–å¾Œç«¯ redirectï¼‰å¯ä»¥ç›´æ¥ç”¨ ?lang=en åˆ‡èªè¨€
    è‹¥æ²’å¸¶åº§æ¨™ï¼Œè®“ LIFF è‡ªå·±å–å®šä½ã€‚
    """
    if not PUBLIC_URL:
        return None

    base = f"{PUBLIC_URL}/status_liff"

    params = {}
    # è®“ LIFF èƒ½çŸ¥é“æ˜¯èª°ï¼ˆä¹Ÿæ–¹ä¾¿å¾Œç«¯åšé è¨­èªè¨€ï¼‰
    if uid:
        params["uid"] = uid
        try:
            params["lang"] = "en" if get_user_lang(uid) == "en" else "zh"
        except Exception:
            params["lang"] = "zh"

    if lat is not None and lon is not None:
        params["lat"] = norm_coord(lat)
        params["lon"] = norm_coord(lon)

    if not params:
        return base
    return base + "?" + urllib.parse.urlencode(params)


# === æ¨“å±¤æ¨æ–· ===
def _floor_from_tags(tags: dict):
    if not tags:
        return None
    level = tags.get("level") or tags.get("level:ref") or tags.get("addr:floor")
    loc = (tags.get("location") or "").lower()
    try:
        if level is not None and str(level).strip() != "":
            lv_str = str(level).strip().replace("F","").replace("f","")
            lv = int(float(lv_str))
            if lv < 0:
                return f"åœ°ä¸‹{abs(lv)}F"
            if lv == 0:
                return "åœ°é¢"
            return f"{lv}F"
    except Exception:
        pass
    if loc == "underground":
        return "åœ°ä¸‹"
    if loc == "overground":
        return "åœ°é¢"
    return None

_ZH_DIGIT = {"é›¶":0,"ã€‡":0,"ä¸€":1,"äºŒ":2,"å…©":2,"ä¸‰":3,"å››":4,"äº”":5,"å…­":6,"ä¸ƒ":7,"å…«":8,"ä¹":9}

def _zh_to_int_word(word: str):
    if not word:
        return None
    w = word.replace("ä¸¤","å…©")
    if "å" not in w:
        return _ZH_DIGIT.get(w)
    left, _, right = w.partition("å")
    tens = 10 if left == "" else (_ZH_DIGIT.get(left, 0) * 10)
    ones = 0 if right == "" else _ZH_DIGIT.get(right, 0)
    val = tens + ones
    return val if val > 0 else None

def _normalize_floor_label(n: int, underground: bool=False):
    try:
        n = int(n)
    except Exception:
        return None
    if underground:
        return f"åœ°ä¸‹{abs(n)}F"
    if n == 0:
        return "åœ°é¢"
    return f"{n}F"

def _floor_from_name(name: str):
    if not name:
        return None
    s = str(name).strip()
    s_lower = s.lower()

    if re.search(r'(?:^|[^a-z])g\s*/?\s*f(?:[^a-z]|$)', s_lower) or re.search(r'ground\s*floor', s_lower):
        return "åœ°é¢"

    m = re.search(r'(?:^|[^a-z])[bï¼¢]\s*-?\s*(\d{1,2})\s*(?:f|æ¨“|å±¤)?(?:[^0-9]|$)', s_lower)
    if m:
        n = int(m.group(1))
        if n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'åœ°ä¸‹\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶\d]{1,3})\s*(?:æ¨“|å±¤|f)?', s_lower)
    if m:
        token = m.group(1)
        n = int(token) if token.isdigit() else _zh_to_int_word(token)
        if n and n > 0:
            return _normalize_floor_label(n, underground=True)

    m = re.search(r'(\d{1,3})\s*(?:f|æ¨“|å±¤)(?:[^a-z0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    m = re.search(r'ç¬¬?\s*([ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åã€‡é›¶]{1,3})\s*(?:æ¨“|å±¤)', s_lower)
    if m:
        n = _zh_to_int_word(m.group(1))
        if n:
            return _normalize_floor_label(n)

    m = re.search(r'(?:^|[^a-z])l\s*(\d{1,3})(?:[^0-9]|$)', s_lower)
    if m:
        return _normalize_floor_label(int(m.group(1)))

    return None

# === ä¾é™„è¿‘å ´é¤¨å‘½å ===
_ENRICH_TTL = 120

def enrich_nearby_places(lat, lon, radius=500):
    # ğŸ”Œ ç¸½é–‹é—œï¼šé è¨­é—œé–‰ï¼ˆENV å¯è¨­ ENRICH_ENABLE=1 é–‹å•Ÿï¼‰
    enabled = globals().get("ENRICH_ENABLE", None)
    if enabled is None:
        try:
            enabled = int(os.getenv("ENRICH_ENABLE", "0"))
        except Exception:
            enabled = 0
    if not enabled:
        return []

    key = f"{round(lat,4)},{round(lon,4)}:{radius}"
    now = time.time()
    cached = _ENRICH_CACHE.get(key)
    if cached and (now - cached[0] < _ENRICH_TTL):
        return cached[1]

    q = f"""
    [out:json][timeout:25];
    (
      node(around:{radius},{lat},{lon})["name"]["building"];
      way(around:{radius},{lat},{lon})["name"]["building"];
      node(around:{radius},{lat},{lon})["name"]["shop"];
      way(around:{radius},{lat},{lon})["name"]["shop"];
      node(around:{radius},{lat},{lon})["name"]["amenity"];
      way(around:{radius},{lat},{lon})["name"]["amenity"];
    );
    out center tags;
    """
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]
    headers = {"User-Agent": f"ToiletBot/1.0 (+{os.getenv('CONTACT_EMAIL','you@example.com')})"}

    for url in endpoints:
        try:
            resp = requests.post(url, data=q, headers=headers, timeout=30)
            if resp.status_code == 200 and "json" in (resp.headers.get("Content-Type","").lower()):
                els = resp.json().get("elements", [])
                out = []
                for e in els:
                    if e.get("type") == "node":
                        clat, clon = e.get("lat"), e.get("lon")
                    else:
                        c = e.get("center") or {}
                        clat, clon = c.get("lat"), c.get("lon")
                    if clat is None or clon is None:
                        continue
                    nm = (e.get("tags", {}) or {}).get("name")
                    if nm:
                        try:
                            d = haversine(float(lat), float(lon), float(clat), float(clon))
                        except Exception:
                            d = 9e9
                        out.append({"name": nm, "lat": float(clat), "lon": float(clon), "_d": d})

                # è·é›¢æ’åº + æˆªæ–·ï¼Œé¿å…è¨˜æ†¶é«”æš´è¡
                if out:
                    out.sort(key=lambda x: x["_d"])
                    # ä½¿ç”¨å…¨åŸŸ/ENV çš„ ENRICH_MAX_ITEMSï¼ˆè‹¥ç„¡å‰‡é è¨­ 60ï¼‰
                    max_items = globals().get("ENRICH_MAX_ITEMS", None)
                    if max_items is None:
                        try:
                            max_items = int(os.getenv("ENRICH_MAX_ITEMS", "60"))
                        except Exception:
                            max_items = 60
                    out = out[:max_items]
                    for o in out:
                        o.pop("_d", None)

                _ENRICH_CACHE.set(key, (now, out))
                return out
        except Exception:
            continue

    _ENRICH_CACHE.set(key, (now, []))
    return []

# === å¯æ‰¾æ€§åˆ†æ•¸ + æ’åº ===
def _findability_bonus(t):
    b = 0.0
    if t.get("place_hint"): b += 0.5
    if t.get("floor_hint"): b += 0.3
    return b

def sort_toilets(toilets):
    toilets.sort(key=lambda x: (int(x.get("distance", 1e9)), -_findability_bonus(x)))
    return toilets

# === åˆå§‹åŒ– Google Sheetsï¼ˆåŒ… SafeWSï¼›å…¶é¤˜ä¸è®Šï¼‰ ===
def init_gsheet():
    global gc, worksheet, feedback_sheet, consent_ws, status_ws
    try:
        if not GSHEET_CREDENTIALS_JSON:
            logging.critical("âŒ ç¼ºå°‘ GSHEET_CREDENTIALS_JSON")
            return  # ä¸ raiseï¼Œè®“æœå‹™å…ˆæ´»è‘—
        creds_dict = json.loads(GSHEET_CREDENTIALS_JSON)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, GSHEET_SCOPE)
        gc = gspread.authorize(creds)

        worksheet_raw = gc.open_by_key(TOILET_SPREADSHEET_ID).sheet1
        fb_spread = gc.open_by_key(FEEDBACK_SPREADSHEET_ID)
        feedback_raw = fb_spread.sheet1

        try:
            consent_raw = fb_spread.worksheet(CONSENT_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            consent_raw = fb_spread.add_worksheet(title=CONSENT_SHEET_TITLE, rows=1000, cols=10)
            consent_raw.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])

        worksheet = SafeWS(worksheet_raw, TOILET_SPREADSHEET_ID, worksheet_raw.title)
        feedback_sheet = SafeWS(feedback_raw, FEEDBACK_SPREADSHEET_ID, feedback_raw.title)
        consent_ws = SafeWS(consent_raw, FEEDBACK_SPREADSHEET_ID, consent_raw.title)
        
        try:
            status_raw = fb_spread.worksheet(STATUS_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            status_raw = fb_spread.add_worksheet(title=STATUS_SHEET_TITLE, rows=1000, cols=10)
            status_raw.update("A1:G1", [["lat","lon","status","user_id","display_name","note","timestamp"]])

        status_ws = SafeWS(status_raw, FEEDBACK_SPREADSHEET_ID, status_raw.title)

        logging.info("âœ… Sheets åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logging.critical(f"âŒ Sheets åˆå§‹åŒ–å¤±æ•—ï¼ˆæ”¹ç‚ºå»¶å¾Œå†è©¦ï¼‰: {e}")
        return

def _ensure_sheets_ready():
    if any(x is None for x in (worksheet, feedback_sheet, consent_ws)):
        try:
            init_gsheet()
        except Exception:
            # ä¿æŒéœé»˜ï¼Œå‘¼å«ç«¯è¦è‡ªå·±å®¹éŒ¯ï¼ˆä¾‹å¦‚å›ç©ºçµæœ / å„ªé›…é™ç´šï¼‰
            pass

init_gsheet()

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
TOILET_REQUIRED_HEADER = [
    "user_id", "name", "address", "lat", "lon",
    "level", "floor_hint", "entrance_hint", "access_note", "open_hours",
    "timestamp"
]

def ensure_toilet_sheet_header(ws):
    _ensure_sheets_ready()
    if ws is None:
        return TOILET_REQUIRED_HEADER[:]
    try:
        header = ws.row_values(1) or []
        if not header:
            ws.update("A1", [TOILET_REQUIRED_HEADER])
            return TOILET_REQUIRED_HEADER[:]

        changed = False
        for col in TOILET_REQUIRED_HEADER:
            if col not in header:
                header.append(col)
                changed = True
        if changed:
            ws.update("A1", [header])
        return header
    except Exception as e:
        logging.error(f"ensure_toilet_sheet_header å¤±æ•—ï¼š{e}")
        return header if 'header' in locals() and header else TOILET_REQUIRED_HEADER[:]

# === è¨ˆç®—è·é›¢ ===
def haversine(lat1, lon1, lat2, lon2):
    try:
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
        return 2 * asin(sqrt(a)) * 6371000  # m
    except Exception as e:
        logging.error(f"è¨ˆç®—è·é›¢å¤±æ•—: {e}")
        return 0

# === é˜²é‡è¤‡ï¼ˆç°¡å–®ç‰ˆï¼šé¿å…åŒä¸€ webhook åœ¨çŸ­æ™‚é–“å…§é‡è¤‡è™•ç†ï¼‰===
DEDUPE_WINDOW = int(os.getenv("DEDUPE_WINDOW", "10"))
_DEDUPE_SIMPLE_LOCK = threading.Lock()
_RECENT_EVENTS_SIMPLE = {}

def is_duplicate_and_mark(key: str, window: int = DEDUPE_WINDOW) -> bool:
    """ç°¡å–®é˜²é‡ï¼šåŒä¸€ key åœ¨ window ç§’å…§è¦–ç‚ºé‡è¤‡ã€‚

    é€™æ®µé‚è¼¯ä¿ç•™çµ¦èˆŠæµç¨‹ä½¿ç”¨ï¼›ä¸‹æ–¹å¦æœ‰æ›´ç²¾æº–çš„äº‹ä»¶å»é‡ï¼ˆ_event_type_and_keyï¼‰ã€‚
    """
    now = time.time()
    if not key:
        return False
    try:
        with _DEDUPE_SIMPLE_LOCK:
            ts = _RECENT_EVENTS_SIMPLE.get(key)
            if ts is not None and (now - ts) < window:
                logging.info(f"ğŸ” skip duplicate: {key}")
                return True
            _RECENT_EVENTS_SIMPLE[key] = now
            # è¼•é‡æ¸…ç†ï¼Œé¿å… dict ç„¡é™æˆé•·
            if len(_RECENT_EVENTS_SIMPLE) > 5000:
                cutoff = now - window
                for k, tstamp in list(_RECENT_EVENTS_SIMPLE.items()):
                    if tstamp < cutoff:
                        _RECENT_EVENTS_SIMPLE.pop(k, None)
        return False
    except Exception:
        return False


def is_redelivery(event) -> bool:
    try:
        dc = getattr(event, "delivery_context", None)
        return bool(getattr(dc, "is_redelivery", False))
    except Exception:
        return False

LINE_REPLY_MAX = 5

# push fallback å»é‡ï¼ˆé¿å…é‡é€ / é‡è©¦é€ æˆé‡è¤‡æ¨æ’­ï¼‰
_PUSH_DEDUPE = getattr(globals(), "_PUSH_DEDUPE", {})
_PUSH_LOCK = threading.Lock()
PUSH_FALLBACK_DEDUPE_WINDOW = int(os.getenv("PUSH_FALLBACK_DEDUPE_WINDOW", "180"))

def safe_reply(event, messages):
    """
    âœ… å®‰å…¨å›è¦†ï¼š
    - å„ªå…ˆä½¿ç”¨ reply_messageï¼ˆç¬¦åˆ LINE è¦å‰‡ï¼šreply_token åªèƒ½ç”¨ä¸€æ¬¡ï¼‰
    - è‹¥ reply_token éæœŸ/ç„¡æ•ˆï¼ˆå¸¸è¦‹æ–¼å†·å•Ÿå‹•/é‡é€ï¼‰ï¼Œæ”¹ç”¨ push_message è£œé€
    - ä»ä¿ç•™æœ€å¤š 5 å‰‡è¨Šæ¯é™åˆ¶ï¼Œé¿å… LINE API æ‹’çµ•
    """
    # normalize messages to list
    if messages is None:
        return
    if not isinstance(messages, list):
        messages = [messages]
    messages = [m for m in messages if m is not None]
    if not messages:
        return

    # âœ… æœ€å¤š 5 å‰‡ï¼Œå¤šçš„ç æ‰ï¼ˆæˆ–è‡ªè¡Œæ”¹æˆåˆä½µæ–‡å­—ï¼‰
    if len(messages) > LINE_REPLY_MAX:
        logging.warning(f"[safe_reply] messages too many ({len(messages)}), truncating to {LINE_REPLY_MAX}.")
        messages = messages[:LINE_REPLY_MAX]

    # å˜—è©¦ reply
    try:
        line_bot_api.reply_message(event.reply_token, messages)
        return
    except LineBotApiError as e:
        # è§£æéŒ¯èª¤è¨Šæ¯
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)

        # é‡é€ï¼ˆredeliveryï¼‰ä¸€å¾‹ä¸åš pushï¼ˆé¿å…é‡è¤‡åˆ·ï¼‰
        if is_redelivery(event):
            logging.warning(f"[safe_reply] redelivery detected; skip push. err={msg_txt}")
            return

        # reply_token ç„¡æ•ˆæˆ–å·²éæœŸ â†’ ç”¨ push è£œå›è¦†ï¼ˆé¿å…ä½¿ç”¨è€…ç„¡å›æ‡‰ï¼‰
        if "Invalid reply token" in msg_txt:
            try:
                uid = getattr(getattr(event, "source", None), "user_id", None)
                # âœ… å…ˆåšã€Œäº‹ä»¶ç´šã€å»é‡ï¼šåŒä¸€äº‹ä»¶å°±ç®—é‡è©¦å¤šæ¬¡ï¼Œä¹Ÿåª push ä¸€æ¬¡
                try:
                    _, ek, _ = _event_type_and_key(event)  # type: ignore
                except Exception:
                    ek = None
                now_ts = time.time()
                if ek:
                    with _PUSH_LOCK:
                        last = _PUSH_DEDUPE.get(ek)
                        if last is not None and (now_ts - last) < PUSH_FALLBACK_DEDUPE_WINDOW:
                            logging.warning(f"[safe_reply] invalid reply token but already pushed recently; skip. key={ek}")
                            return
                        _PUSH_DEDUPE[ek] = now_ts

                if uid:
                    line_bot_api.push_message(uid, messages)
                    logging.warning(f"[safe_reply] invalid reply token -> pushed to uid={uid}")
                else:
                    logging.warning("[safe_reply] invalid reply token and no uid -> skip")
            except Exception as e2:
                logging.error(f"[safe_reply] push fallback failed: {e2}", exc_info=True)
            return

        # å…¶ä»–éŒ¯èª¤åªè¨˜éŒ„
        logging.warning(f"[safe_reply] reply_message failed. err={msg_txt}")
    except Exception as ex:
        logging.error(f"[safe_reply] unexpected error: {ex}", exc_info=True)

# === æ›´ç²¾æº–çš„é˜²é‡è¤‡ï¼ˆæ–°ï¼‰ ===
_DEDUPE_LOCK = threading.Lock()

# äº‹ä»¶é¡å‹å°ˆå±¬æ™‚é–“çª—ï¼ˆç§’ï¼‰â€” å¯ç”¨ç’°å¢ƒè®Šæ•¸èª¿æ•´
TEXT_DEDUPE_WINDOW = int(os.getenv("TEXT_DEDUPE_WINDOW", "15"))
LOC_DEDUPE_WINDOW  = int(os.getenv("LOC_DEDUPE_WINDOW",  "10"))
PB_DEDUPE_WINDOW   = int(os.getenv("PB_DEDUPE_WINDOW",   "120"))

# å®šä½äº‹ä»¶çŸ­æ™‚é–“é‡è¤‡çš„è·é›¢é–¾å€¼ï¼ˆå…¬å°ºï¼‰
LOC_DEDUPE_DISTANCE_M = float(os.getenv("LOC_DEDUPE_DISTANCE_M", "8"))

# æœ€è¿‘è™•ç†äº‹ä»¶æ™‚é–“ç´¢å¼•
_RECENT_EVENTS = getattr(globals(), "_RECENT_EVENTS", {})  # è‹¥å‰é¢å·²æœ‰åŒå dictï¼Œæ²¿ç”¨

def _now():
    return time.time()

def _purge_expired(now_ts: float):
    """è¼•é‡æ¸…ç†ï¼šç§»é™¤è¶…éæœ€å¤§å»é‡çª—çš„èˆŠè¨˜éŒ„ï¼Œé¿å… dict ç„¡é™æˆé•·"""
    max_win = max(TEXT_DEDUPE_WINDOW, LOC_DEDUPE_WINDOW, PB_DEDUPE_WINDOW, 180)
    cutoff = now_ts - float(max_win)
    for k, ts in list(_RECENT_EVENTS.items()):
        if ts < cutoff:
            _RECENT_EVENTS.pop(k, None)

def _event_type_and_key(event):
    """å›å‚³ (etype, key, window_sec)

    âœ… å»é‡ key å„ªå…ˆé †åºï¼š
    1) webhook_event_idï¼ˆè‹¥ SDK æœ‰å¸¶ï¼‰
    2) message.idï¼ˆMessageEventï¼‰
    3) fallbackï¼šuser_id + payload + timestampï¼ˆåŒä¸€äº‹ä»¶é‡é€ timestamp é€šå¸¸ç›¸åŒï¼‰
    """
    uid = getattr(getattr(event, "source", None), "user_id", "") or ""
    ts = getattr(event, "timestamp", 0) or 0  # ms
    weid = getattr(event, "webhook_event_id", None) or getattr(event, "webhookEventId", None)

    # Message id
    mid = None
    try:
        mid = getattr(getattr(event, "message", None), "id", None)
    except Exception:
        pass

    # Text
    if isinstance(getattr(event, "message", None), TextMessage):
        etype = "text"
        window = TEXT_DEDUPE_WINDOW
        txt = (getattr(event.message, "text", "") or "").strip().lower()
        if weid:
            key = f"weid:{weid}"
        elif mid:
            key = f"mid:{mid}"
        else:
            key = f"text|{uid}|{txt}|ts:{ts}"
        return etype, key, window

    # Location
    if isinstance(getattr(event, "message", None), LocationMessage):
        etype = "loc"
        window = LOC_DEDUPE_WINDOW
        lat = getattr(event.message, "latitude", None)
        lon = getattr(event.message, "longitude", None)
        base = f"loc|{uid}|{norm_coord(lat)}:{norm_coord(lon)}|ts:{ts}"
        if weid:
            key = f"weid:{weid}"
        elif mid:
            key = f"mid:{mid}"
        else:
            key = base
        return etype, key, window

    # Postbackï¼ˆæ²’æœ‰ messageï¼‰
    etype = "pb"
    window = PB_DEDUPE_WINDOW
    data = getattr(getattr(event, "postback", None), "data", "") or ""
    if weid:
        key = f"weid:{weid}"
    else:
        key = f"pb|{uid}|{data}|ts:{ts}"
    return etype, key, window

def is_duplicate_and_mark_event(event) -> bool:
    now_ts = _now()
    etype, key, window = _event_type_and_key(event)

    # ç‚º Location åŠ ä¸Šã€Œè·é›¢ + æ™‚é–“ã€è¦å‰‡
    if etype == "loc":
        try:
            uid = event.source.user_id
            lat = float(event.message.latitude)
            lon = float(event.message.longitude)
            last = get_user_location(uid)
        except Exception:
            last = None
        else:
            if last:
                try:
                    d = haversine(lat, lon, float(last[0]), float(last[1]))
                except Exception:
                    d = 1e9
                with _DEDUPE_LOCK:
                    last_ts = _RECENT_EVENTS.get(f"loc_ts|{uid}", 0.0)
                    if (now_ts - last_ts) < LOC_DEDUPE_WINDOW and d <= LOC_DEDUPE_DISTANCE_M:
                        logging.info(f"ğŸ” skip duplicate loc: uid={uid} d={int(d)}m Î”t={round(now_ts-last_ts,2)}s")
                        return True
                    _RECENT_EVENTS[f"loc_ts|{uid}"] = now_ts  # æ›´æ–°æœ€å¾Œå®šä½æ™‚é–“

    # ä¸€èˆ¬è·¯å¾‘ï¼škey + window
    with _DEDUPE_LOCK:
        last_ts = _RECENT_EVENTS.get(key)
        if last_ts is not None and (now_ts - last_ts) < window:
            logging.info(f"ğŸ” skip duplicate {etype}: key={key}")
            return True
        _RECENT_EVENTS[key] = now_ts
        _purge_expired(now_ts)

    return False

def _too_old_to_reply(event, limit_seconds=None):
    try:
        if limit_seconds is None:
            limit_seconds = int(os.getenv("MAX_EVENT_AGE_SEC", "1800"))

        evt_ms = int(getattr(event, "timestamp", 0))
        if evt_ms <= 0:
            return False

        now_ms = int(time.time() * 1000)
        return (now_ms - evt_ms) > (limit_seconds * 1000)
    except Exception:
        return False

def reply_only(event, messages):
    try:
        line_bot_api.reply_message(event.reply_token, messages)
    except LineBotApiError as e:
        msg_txt = ""
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)
        logging.warning(f"reply_message å¤±æ•—ï¼ˆä¸åš pushï¼‰ï¼š{msg_txt}")
    except Exception as ex:
        logging.error(f"reply_only åŸ·è¡ŒéŒ¯èª¤ï¼š{ex}")

# === åŒæ„å·¥å…· ===
def _booly(v):
    s = str(v).strip().lower()
    return s in ["1", "true", "yes", "y", "åŒæ„"]

# ï¼ˆå¯é¸å¾®å„ªåŒ–ï¼‰æœ¬æ©ŸåŒæ„å¿«å–ï¼ŒTTL é è¨­ 10 åˆ†é˜ï¼›å¤±æ•—æ™‚ç•¶æœªåŒæ„ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰
_consent_cache = {}   # user_id -> (ts, bool)
_CONSENT_TTL = int(os.getenv("CONSENT_TTL_SEC", "600"))

def has_consented(user_id: str) -> bool:
    _ensure_sheets_ready()
    if not user_id or consent_ws is None:
        return False
    try:
        if not user_id or consent_ws is None:
            return False
        now = time.time()
        hit = _consent_cache.get(user_id)
        if hit and (now - hit[0] < _CONSENT_TTL):
            return hit[1]

        rows = consent_ws.get_all_values()
        if not rows or len(rows) < 2:
            _consent_cache[user_id] = (now, False)
            return False
        header = rows[0]; data = rows[1:]
        try:
            i_uid = header.index("user_id")
            i_ag  = header.index("agreed")
        except ValueError:
            _consent_cache[user_id] = (now, False)
            return False
        ok = False
        for r in data:
            if len(r) <= max(i_uid, i_ag):
                continue
            if (r[i_uid] or "").strip() == user_id and _booly(r[i_ag]):
                ok = True
                break
        _consent_cache[user_id] = (now, ok)
        return ok
    except Exception as e:
        logging.warning(f"æŸ¥è©¢åŒæ„å¤±æ•—: {e}")
        return False

def upsert_consent(user_id: str, agreed: bool, display_name: str, source_type: str, ua: str, ts_iso: str):
    _ensure_sheets_ready()
    if consent_ws is None:
        return False
    try:
        rows = consent_ws.get_all_values()
        if not rows:
            consent_ws.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])
            rows = [["user_id","agreed","display_name","source_type","ua","timestamp"]]
        header = rows[0]; data = rows[1:]

        idx = {h:i for i,h in enumerate(header)}
        for k in ["user_id","agreed","display_name","source_type","ua","timestamp"]:
            if k not in idx:
                header.append(k); idx[k] = len(header)-1
        if len(header) != len(rows[0]):
            consent_ws.update("A1", [header])

        row_to_update = None
        for i, r in enumerate(data, start=2):
            if len(r) > idx["user_id"] and (r[idx["user_id"]] or "").strip() == user_id:
                row_to_update = i
                break

        row_values = [""] * len(header)
        row_values[idx["user_id"]] = user_id or ""
        row_values[idx["agreed"]] = "true" if agreed else "false"
        row_values[idx["display_name"]] = display_name or ""
        row_values[idx["source_type"]] = source_type or ""
        row_values[idx["ua"]] = ua or ""
        row_values[idx["timestamp"]] = ts_iso or datetime.utcnow().isoformat()

        if row_to_update:
            consent_ws.update(f"A{row_to_update}", [row_values])
        else:
            consent_ws.append_row(row_values, value_input_option="USER_ENTERED")
        # æ›´æ–°æœ¬æ©Ÿå¿«å–
        _consent_cache[user_id] = (time.time(), bool(agreed))
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥/æ›´æ–°åŒæ„å¤±æ•—: {e}")
        return False

def ensure_consent_or_prompt(user_id: str):
    if has_consented(user_id):
        return None
    tip = (
        "ğŸ›¡ï¸ ä½¿ç”¨å‰è«‹å…ˆå®ŒæˆåŒæ„ï¼š\n"
        f"{CONSENT_PAGE_URL}\n\n"
        "è‹¥ä¸åŒæ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡ç„¡æ³•æä¾›ã€‚"
    )
    return TextSendMessage(text=tip)

# === å¾ Google Sheets æŸ¥ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
# è¨­å®š SQLite è³‡æ–™åº«ä½ç½®
CACHE_DB_PATH = "cache.db"

# å»ºç«‹ SQLite é€£ç·š
def create_cache_db():
    if not os.path.exists(CACHE_DB_PATH):
        conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
        cursor = conn.cursor()
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS sheets_cache (
            query_key TEXT PRIMARY KEY,
            data TEXT,
            timestamp REAL
        )
        """)
        conn.commit()
        conn.close()

# === SQLite åƒæ•¸å¼·åŒ–ï¼ˆæ–°å¢ï¼‰ ===
def tune_sqlite_for_concurrency():
    try:
        conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
        cur = conn.cursor()
        # å•Ÿç”¨ WAL æé«˜å¤šåŸ·è¡Œç·’è®€/å¯«ä¸¦è¡Œèƒ½åŠ›
        cur.execute("PRAGMA journal_mode=WAL;")
        # è¨­å®š busy timeoutï¼ˆæ¯«ç§’ï¼‰ï¼Œé¿å…çŸ­æš«é–è¡çªç›´æ¥æ‹‹éŒ¯
        cur.execute("PRAGMA busy_timeout=3000;")
        conn.commit()
        conn.close()
        logging.info("âœ… SQLite tuned: WAL + busy_timeout")
    except Exception as e:
        logging.warning(f"SQLite tuning skipped: {e}")

# ç¢ºèªå¿«å–æ˜¯å¦æœ‰æ•ˆ
def get_cached_data(query_key, ttl_sec=60*5):
    conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("SELECT data, timestamp FROM sheets_cache WHERE query_key = ?", (query_key,))
    result = cursor.fetchone()
    conn.close()

    if result:
        data, timestamp = result
        if time.time() - timestamp < ttl_sec:
            return json.loads(data)
    return None

# å„²å­˜å¿«å–
def save_cache(query_key, data):
    conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("""
    INSERT OR REPLACE INTO sheets_cache (query_key, data, timestamp)
    VALUES (?, ?, ?)
    """, (query_key, json.dumps(data), time.time()))
    conn.commit()
    conn.close()

# å¿«å–åˆå§‹åŒ–
create_cache_db()
tune_sqlite_for_concurrency()

# æŸ¥è©¢å»æ‰€è³‡æ–™
def query_sheet_toilets(user_lat, user_lon, radius=500):
    _ensure_sheets_ready()
    if worksheet is None:
        return []

    try:
        SHEET_MAX_ITEMS = int(os.getenv("SHEET_MAX_ITEMS", "120"))
    except Exception:
        SHEET_MAX_ITEMS = 120

    toilets_heap = []

    try:
        header, data = _get_header_and_tail(worksheet, MAX_SHEET_ROWS)
        if not header or not data:
            return []

        idx = _toilet_sheet_indices(header)
        if idx.get("lat") is None or idx.get("lon") is None:
            return []

        lat = float(user_lat)
        lon = float(user_lon)
        dlat = radius / 111000.0
        dlon = radius / (111000.0 * max(0.1, math.cos(math.radians(lat))))

        min_lat, max_lat = lat - dlat, lat + dlat
        min_lon, max_lon = lon - dlon, lon + dlon

        for row in data:
            if len(row) <= max(idx["lat"], idx["lon"]):
                continue

            try:
                t_lat = float(row[idx["lat"]])
                t_lon = float(row[idx["lon"]])
            except Exception:
                continue

            if not (min_lat <= t_lat <= max_lat and min_lon <= t_lon <= max_lon):
                continue

            dist = haversine(lat, lon, t_lat, t_lon)
            if dist > radius:
                continue

            name = (
                row[idx["name"]].strip()
                if idx["name"] is not None and len(row) > idx["name"]
                else "ç„¡åç¨±"
            )
            address = (
                row[idx["address"]].strip()
                if idx["address"] is not None and len(row) > idx["address"]
                else ""
            )

            floor_hint = _floor_from_name(name)

            item = {
                "name": name,
                "lat": float(norm_coord(t_lat)),
                "lon": float(norm_coord(t_lon)),
                "address": address,
                "distance": dist,
                "type": "sheet",
                "floor_hint": floor_hint,
            }

            heapq.heappush(toilets_heap, (-dist, item))
            if len(toilets_heap) > SHEET_MAX_ITEMS:
                heapq.heappop(toilets_heap)

        toilets = [item for _, item in sorted(toilets_heap, key=lambda x: -x[0])]
        return toilets

    except Exception as e:
        logging.error(f"è®€å– Google Sheets å»æ‰€ä¸»è³‡æ–™éŒ¯èª¤: {e}")
        return []

# === OSM Overpass ===
def query_overpass_toilets(lat, lon, radius=500):
    overall_deadline = time.time() + 8.0

    def _left():
        return max(1.0, overall_deadline - time.time())

    ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
    headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]

    # è®€å–é™åˆ¶å€¼
    try:
        max_items = int(os.getenv("OVERPASS_MAX_ITEMS", "80"))
    except Exception:
        max_items = 80
    try:
        enrich_on = int(os.getenv("ENRICH_ENABLE", "0")) == 1
    except Exception:
        enrich_on = False

    # å…ˆå°åŠå¾‘å†åŸåŠå¾‘
    for r in (300, radius):
        if time.time() >= overall_deadline:
            break

        query = f"""
        [out:json][timeout:25];
        (
          node["amenity"="toilets"](around:{r},{lat},{lon});
          way["amenity"="toilets"](around:{r},{lat},{lon});
          relation["amenity"="toilets"](around:{r},{lat},{lon});
        );
        out center tags;
        """

        last_err = None
        for idx, url in enumerate(endpoints):
            if time.time() >= overall_deadline:
                break
            try:
                resp = requests.post(
                    url,
                    data=query,
                    headers=headers,
                    timeout=min(8, _left())
                )
                ctype = (resp.headers.get("Content-Type") or "").lower()
                if resp.status_code != 200 or "json" not in ctype:
                    last_err = RuntimeError(f"overpass non-json {resp.status_code}")
                    continue

                data = resp.json()
                elements = data.get("elements", [])

                toilets = []

                # æœ€å¤šè™•ç† 4 * max_itemsï¼ˆé¿å… elements å¤ªå¤šï¼‰
                hard_cap = max(40, max_items * 4)
                processed = 0

                for elem in elements:
                    if processed >= hard_cap:
                        break
                    processed += 1

                    if "center" in elem:
                        t_lat = elem["center"].get("lat")
                        t_lon = elem["center"].get("lon")
                    elif elem.get("type") == "node":
                        t_lat = elem.get("lat")
                        t_lon = elem.get("lon")
                    else:
                        continue

                    if t_lat is None or t_lon is None:
                        continue

                    if not _in_bbox(t_lat, t_lon, lat, lon, r):
                        continue

                    tags = elem.get("tags", {}) or {}
                    name = tags.get("name", "ç„¡åç¨±")
                    address = (
                        tags.get("addr:full")
                        or tags.get("addr:street")
                        or ""
                    )

                    floor_hint = _floor_from_tags(tags) or _floor_from_name(name)

                    try:
                        dist = haversine(
                            float(lat), float(lon),
                            float(t_lat), float(t_lon)
                        )
                    except Exception:
                        continue

                    if dist > r:
                        continue

                    toilets.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": address,
                        "distance": dist,
                        "type": "osm",
                        "floor_hint": floor_hint,
                        "level": tags.get("level") or tags.get("addr:floor") or "",
                        "open_hours": tags.get("opening_hours") or "",
                        "entrance_hint": tags.get("entrance") or "",
                    })

                if not toilets:
                    continue

                # enrichï¼ˆä¿æŒä½ åŸæœ¬é‚è¼¯ï¼Œä¸å‹•ï¼‰
                if enrich_on:
                    try:
                        nearby_named = enrich_nearby_places(lat, lon, radius=500)
                        if nearby_named:
                            for t in toilets:
                                if (not t.get("name")) or t["name"] == "ç„¡åç¨±":
                                    best = None
                                    best_d = 61.0
                                    for p in nearby_named:
                                        d = haversine(
                                            t["lat"], t["lon"],
                                            p["lat"], p["lon"]
                                        )
                                        if d < best_d:
                                            best_d = d
                                            best = p
                                    if best:
                                        t["place_hint"] = best["name"]
                    except Exception:
                        pass

                toilets = heapq.nsmallest(
                    max_items,
                    toilets,
                    key=lambda x: x["distance"]
                )
                return toilets

            except Exception as e:
                last_err = e
                logging.warning(f"Overpass API æŸ¥è©¢å¤±æ•—ï¼ˆendpoint {idx}ï¼‰: {e}")

        logging.warning(f"Overpass åŠå¾‘ {r} å¤±æ•—ï¼š{last_err}")

    return []

# === è®€å– public_toilets.csv ===
def query_public_csv_toilets(user_lat, user_lon, radius=500):
    if not os.path.exists(TOILETS_FILE_PATH):
        return []

    heap = []  
    limit = LOC_MAX_RESULTS

    try:
        with open(TOILETS_FILE_PATH, "r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)

            for row in reader:
                try:
                    t_lat = float(row.get("latitude"))
                    t_lon = float(row.get("longitude"))
                except Exception:
                    continue

                if not _in_bbox(t_lat, t_lon, user_lat, user_lon, radius):
                    continue

                dist = haversine(user_lat, user_lon, t_lat, t_lon)
                if dist > radius:
                    continue

                name = (row.get("name") or "ç„¡åç¨±").strip()
                addr = (row.get("address") or "").strip()
                floor_hint = _floor_from_name(name)

                item = {
                    "name": name,
                    "lat": float(norm_coord(t_lat)),
                    "lon": float(norm_coord(t_lon)),
                    "address": addr,
                    "distance": dist,
                    "type": "public_csv",
                    "grade": row.get("grade", ""),
                    "category": row.get("type2", ""),
                    "floor_hint": floor_hint,
                }

                heapq.heappush(heap, (-dist, id(item), item))   
                if len(heap) > limit:
                    heapq.heappop(heap)

    except Exception as e:
        logging.error(f"è®€ public_toilets.csv å¤±æ•—ï¼š{e}")
        return []

    return [item for _, _, item in sorted(heap, key=lambda x: -x[0])]

# === åˆä½µ + å»é‡ ===
def _merge_and_dedupe_lists(*lists, dist_th=35, name_sim_th=0.55):
    all_pts = []
    for l in lists:
        if l: all_pts.extend(l)
    all_pts.sort(key=lambda x: x["distance"])

    merged = []
    for p in all_pts:
        dup = False
        for q in merged:
            try:
                near = haversine(p["lat"], p["lon"], q["lat"], q["lon"]) <= dist_th
            except Exception:
                near = False
            sim = SequenceMatcher(None, (p.get("name") or "").lower(), (q.get("name") or "").lower()).ratio()
            if near and sim >= name_sim_th:
                dup = True
                break
        if not dup:
            merged.append(p)
    return merged

# === æœ€æ„›ç®¡ç† ===
# favorites.txt æ˜¯ç´”æ–‡å­—/CSV æª”ï¼Œæ–¼å¤šåŸ·è¡Œç·’ç’°å¢ƒä¸‹éœ€è¦é–é¿å…åŒæ™‚è®€å¯«é€ æˆç ´æª”
# ï¼ˆä¾‹å¦‚åŒä¸€æ™‚é–“å¤šä½ä½¿ç”¨è€…é»æ”¶è—/å–æ¶ˆæ”¶è—ï¼‰
_FAV_LOCK = threading.Lock()

def add_to_favorites(uid, toilet):
    try:
        if not uid or not toilet:
            return
        lat_s = norm_coord(toilet.get("lat"))
        lon_s = norm_coord(toilet.get("lon"))
        name  = (toilet.get("name") or "").strip()
        addr  = toilet.get("address", "") or ""
        if not name:
            return

        with _FAV_LOCK:
            with open(FAVORITES_FILE_PATH, "a", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([uid, name, lat_s, lon_s, addr])
    except Exception as e:
        logging.error(f"åŠ å…¥æœ€æ„›å¤±æ•—: {e}")

def remove_from_favorites(uid, name, lat, lon):
    try:
        if not uid or not name:
            return False
        lat_s = norm_coord(lat)
        lon_s = norm_coord(lon)

        with _FAV_LOCK:
            rows = []
            changed = False
            with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
                reader = csv.reader(f)
                for row in reader:
                    if len(row) < 5:
                        rows.append(row)
                        continue
                    if not (row[0] == uid and row[1] == name and row[2] == lat_s and row[3] == lon_s):
                        rows.append(row)
                    else:
                        changed = True

            if changed:
                with open(FAVORITES_FILE_PATH, "w", encoding="utf-8", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerows(rows)
        return changed
    except Exception as e:
        logging.error(f"ç§»é™¤æœ€æ„›å¤±æ•—: {e}")
        return False

def get_user_favorites(uid):
    favs = []
    if not uid:
        return favs
    try:
        with _FAV_LOCK:
            with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
                reader = csv.reader(f)
                for row in reader:
                    if len(row) < 5:
                        continue
                    if row[0] != uid:
                        continue
                    favs.append({
                        "user_id": row[0],
                        "name": row[1],
                        "lat": row[2],
                        "lon": row[3],
                        "address": row[4],
                    })
        return favs
    except Exception as e:
        logging.error(f"è®€å–æœ€æ„›å¤±æ•—: {e}")
        return favs

def geocode_address(address):
    try:
        ua_email = os.getenv("CONTACT_EMAIL", "school-toilet-bot@gmail.com")

        url = (
            "https://nominatim.openstreetmap.org/search"
            f"?format=json&q={quote(address)}"
        )

        headers = {
            "User-Agent": f"ToiletBot/1.0 (+{ua_email})"
        }

        resp = requests.get(url, headers=headers, timeout=10)

        # â‘  HTTP ç‹€æ…‹ç¢¼æª¢æŸ¥
        if resp.status_code != 200:
            logging.error(
                f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: HTTP {resp.status_code}, text={resp.text[:200]}"
            )
            return None, None

        # â‘¡ ç©ºå›æ‡‰æª¢æŸ¥
        if not resp.text or not resp.text.strip():
            logging.error("åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: å›å‚³å…§å®¹ç‚ºç©º")
            return None, None

        # â‘¢ JSON è§£æä¿è­·
        try:
            data = resp.json()
        except Exception:
            logging.error(
                f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: é JSON å›æ‡‰, text={resp.text[:200]}"
            )
            return None, None

        # â‘£ è³‡æ–™å…§å®¹æª¢æŸ¥
        if not data:
            logging.warning(f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: æŸ¥ç„¡çµæœ address={address}")
            return None, None

        # â‘¤ æ­£å¸¸å›å‚³
        lat = float(data[0].get("lat"))
        lon = float(data[0].get("lon"))
        return lat, lon

    except Exception as e:
        logging.error(f"åœ°å€è½‰ç¶“ç·¯åº¦ä¾‹å¤–éŒ¯èª¤: {e}", exc_info=True)

    return None, None

# === é™„è¿‘å»æ‰€ API ===
@app.route("/nearby_toilets", methods=["GET"])
def nearby_toilets():
    user_lat = request.args.get('lat')
    user_lon = request.args.get('lon')
    if not user_lat or not user_lon:
        return {"error": _api_L("ç¼ºå°‘ä½ç½®åƒæ•¸", "Missing location parameters")}, 400

    user_lat = float(user_lat)
    user_lon = float(user_lon)

    public_csv_toilets = query_public_csv_toilets(user_lat, user_lon, radius=500) or []
    sheet_toilets = query_sheet_toilets(user_lat, user_lon, radius=500) or []
    osm_toilets = query_overpass_toilets(user_lat, user_lon, radius=500) or []

    all_toilets = _merge_and_dedupe_lists(public_csv_toilets, sheet_toilets, osm_toilets)
    sort_toilets(all_toilets)

    if not all_toilets:
        return {"message": _api_L("é™„è¿‘æ‰¾ä¸åˆ°å»æ‰€", "No nearby toilets found")}, 404
    return {"toilets": all_toilets}, 200

# === é¡¯ç¤ºå›é¥‹è¡¨å–® ===
@app.route("/feedback_form/<toilet_name>/", defaults={'address': ''})
@app.route("/feedback_form/<toilet_name>/<path:address>")
def feedback_form(toilet_name, address):
    address = address or request.args.get("address", "")
    return render_template(
        "feedback_form.html",
        toilet_name=toilet_name,
        address=address,
        lat=request.args.get("lat", ""),
        lon=request.args.get("lon", "")
    )

# === å°é½Š ===
def _norm_h(s):
    return (s or "").strip().lower()

def _find_idx(header, candidates):
    hmap = {_norm_h(h): i for i, h in enumerate(header)}
    for c in candidates:
        if _norm_h(c) in hmap:
            return hmap[_norm_h(c)]
    return None

def _feedback_indices(header):
    return {
        "name": _find_idx(header, ["åç¨±", "name", "toilet_name"]),
        "address": _find_idx(header, ["åœ°å€", "address"]),
        "rating": _find_idx(header, ["æ¸…æ½”åº¦è©•åˆ†", "æ¸…æ½”è©•åˆ†", "rating", "score"]),
        "paper": _find_idx(header, ["æ˜¯å¦æœ‰è¡›ç”Ÿç´™", "toilet_paper", "è¡›ç”Ÿç´™", "ç´™"]),
        "access": _find_idx(header, ["æ˜¯å¦æœ‰ç„¡éšœç¤™è¨­æ–½", "accessibility", "ç„¡éšœç¤™"]),
        "time": _find_idx(header, ["ä½¿ç”¨æ™‚é–“", "time_of_use", "time"]),
        "comment": _find_idx(header, ["ç•™è¨€", "comment", "å‚™è¨»"]),
        "pred": _find_idx(header, ["é æ¸¬åˆ†æ•¸", "é æ¸¬è©•åˆ†", "cleanliness_score", "predicted_score"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["created_at", "å»ºç«‹æ™‚é–“", "æ™‚é–“", "timestamp"]),
        "floor": _find_idx(header, ["floor", "æ¨“å±¤", "floor_hint", "level", "ä½ç½®æ¨“å±¤"]),
    }

def _toilet_sheet_indices(header):
    return {
        "user_id": _find_idx(header, ["user_id", "uid", "ä½¿ç”¨è€…"]),
        "name": _find_idx(header, ["name", "åç¨±"]),
        "address": _find_idx(header, ["address", "åœ°å€"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["timestamp", "created_at", "å»ºç«‹æ™‚é–“"]),
        "level": _find_idx(header, ["level", "æ¨“å±¤"]),
        "floor_hint": _find_idx(header, ["floor_hint", "ä½ç½®æ¨“å±¤", "æ¨“å±¤èªªæ˜"]),
        "open_hours": _find_idx(header, ["open_hours", "é–‹æ”¾æ™‚é–“", "ç‡Ÿæ¥­æ™‚é–“"]),
    }

# === æ¸…æ½”åº¦é æ¸¬ ===
def expected_from_feats(feats):
    try:
        if not feats or cleanliness_model is None:
            return None
        if pd is not None:
            df = pd.DataFrame(feats, columns=["rating","toilet_paper","accessibility"])
            probs = cleanliness_model.predict_proba(df)
        else:
            probs = cleanliness_model.predict_proba(feats)

        try:
            classes_enc = cleanliness_model.classes_
            labels = label_encoder.inverse_transform(classes_enc)
            labels = [float(x) for x in labels]
        except Exception:
            labels = [float(c) + 1.0 for c in cleanliness_model.classes_]

        exps = [sum(float(p)*float(l) for p, l in zip(p_row, labels)) for p_row in probs]
        return round(sum(exps)/len(exps), 2) if exps else None
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦é æ¸¬éŒ¯èª¤: {e}")
        return None

def _simple_score(rr, paper, acc):
    try:
        base = 1.0 + 4.0 * (int(rr) - 1) / 9.0
    except Exception:
        return None
    bonus = (0.25 if (paper == "æœ‰") else 0.0) + (0.25 if (acc == "æœ‰") else 0.0)
    score = base + bonus
    if score < 1.0: score = 1.0
    if score > 5.0: score = 5.0
    return round(score, 2)

def _pred_from_row(r, idx):
    paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
    access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}

    rr = None
    if idx["rating"] is not None and len(r) > idx["rating"]:
        try:
            rr = int((r[idx["rating"]] or "").strip())
        except:
            rr = None
    pp = (r[idx["paper"]] or "").strip() if idx["paper"] is not None and len(r) > idx["paper"] else "æ²’æ³¨æ„"
    aa = (r[idx["access"]] or "").strip() if idx["access"] is not None and len(r) > idx["access"] else "æ²’æ³¨æ„"

    score = None
    if rr is not None and cleanliness_model is not None:
        try:
            feat = [rr, paper_map.get(pp, 0), access_map.get(aa, 0)]
            score = expected_from_feats([feat])
        except Exception:
            score = None
    if score is None and idx["pred"] is not None and len(r) > idx["pred"]:
        try:
            score = float((r[idx["pred"]] or "").strip())
        except:
            score = None
    if score is None:
        score = _simple_score(rr, pp, aa)
    return (score, rr, pp, aa)

# === å³æ™‚é æ¸¬ / 95% CI ===
def compute_nowcast_ci(lat, lon, k=LAST_N_HISTORY, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return None

    # k ä¸Šé™ï¼Œé¿å…ä¸€æ¬¡åƒå¤ªå¤šåˆ—
    try:
        NOWCAST_MAX_K = int(os.getenv("NOWCAST_MAX_K", "8"))
    except Exception:
        NOWCAST_MAX_K = 8
    if k is None or not isinstance(k, int) or k <= 0:
        k = LAST_N_HISTORY
    k = min(k, NOWCAST_MAX_K)

    # ç›®æ¨™åº§æ¨™è½‰ç‚º floatï¼Œç”¨æ–¼æ¯”è¼ƒ
    try:
        target_lat = float(lat)
        target_lon = float(lon)
    except Exception:
        return None

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return None

        idx = _feedback_indices(header)
        i_lat, i_lon = idx.get("lat"), idx.get("lon")
        if i_lat is None or i_lon is None:
            return None

        def close(a, b):
            try:
                return abs(float(a) - float(b)) <= tol
            except Exception:
                return False

        # åªä¿ç•™åŒåº§æ¨™çš„æœ€è¿‘ k ç­†
        same_rows = []
        for r in data:
            # é•·åº¦æª¢æŸ¥
            if max(i_lat, i_lon) >= len(r):
                continue
            if close(r[i_lat], target_lat) and close(r[i_lon], target_lon):
                same_rows.append(r)
                if len(same_rows) >= k * 3:
                    # å¤šæŠ“ä¸€é»å‚™ç”¨ï¼Œç¨å¾ŒæŒ‰æ™‚é–“å–å‰ k
                    break

        if not same_rows:
            return None

        # è‹¥æœ‰ created æ¬„ä½å°±æŒ‰æ™‚é–“æ–°åˆ°èˆŠæ’ï¼Œå†å–å‰ k ç­†
        i_created = idx.get("created")
        if i_created is not None:
            try:
                same_rows.sort(key=lambda x: (x[i_created] if len(x) > i_created else ""), reverse=True)
            except Exception:
                pass

        recent = same_rows[:k]
        if not recent:
            return None

        # ä¸€æ¬¡èµ°è¨ªï¼ŒåŒæ™‚è¨ˆç®—æ¨¡å‹åˆ†æ•¸èˆ‡å‚™ç”¨ç°¡åŒ–åˆ†æ•¸
        vals_model = []
        vals_simple = []
        for r in recent:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                try:
                    vals_model.append(float(sc))
                except Exception:
                    pass
            # ç°¡åŒ–åˆ†æ•¸éš¨æ‰‹å‚™è‘—ï¼Œé¿å…ä¹‹å¾Œå†è·‘ä¸€æ¬¡
            s2 = _simple_score(rr, pp, aa)
            if isinstance(s2, (int, float)):
                vals_simple.append(float(s2))

        # æ²’æœ‰æ¨¡å‹åˆ†æ•¸å°±ç”¨ç°¡åŒ–åˆ†æ•¸
        vals = vals_model[:] if vals_model else vals_simple[:]
        if not vals:
            return None

        # è‹¥æ¨¡å‹åˆ†æ•¸å…¨ç›¸åŒï¼ˆæ¥µå¸¸è¦‹æ–¼å°‘é‡æ¨£æœ¬ï¼‰ï¼Œæ”¹ç”¨ç°¡åŒ–åˆ†æ•¸ä»¥æ‰“é–‹åˆ†ä½ˆ
        if vals_model and len(vals_model) >= 2:
            try:
                if max(vals_model) - min(vals_model) < 1e-6 and vals_simple:
                    vals = vals_simple[:]
            except Exception:
                pass

        n = len(vals)
        mean = round(sum(vals) / n, 2)

        if n == 1:
            return {"mean": mean, "lower": mean, "upper": mean, "n": 1}

        try:
            s = statistics.stdev(vals)
        except statistics.StatisticsError:
            s = 0.0

        se = s / (n ** 0.5)
        lower = max(1.0, round(mean - 1.96 * se, 2))
        upper = min(5.0, round(mean + 1.96 * se, 2))
        return {"mean": mean, "lower": lower, "upper": upper, "n": n}

    except Exception as e:
        logging.error(f"âŒ compute_nowcast_ci å¤±æ•—: {e}")
        return None

# === Nowcast API ===
@app.route("/get_nowcast_by_coord/<lat>/<lon>")
def get_nowcast_by_coord(lat, lon):
    try:
        res = compute_nowcast_ci(lat, lon)
        if not res:
            return {"success": True, "n": 0}, 200
        res["success"] = True
        return res, 200
    except Exception as e:
        logging.error(f"âŒ Nowcast API éŒ¯èª¤: {e}")
        return {"success": False}, 500

# ==== ç‹€æ…‹ï¼šå€™é¸ä¸‰é–“ï¼ˆé  build_nearby_toiletsï¼‰====
@app.route("/api/status_candidates")
def api_status_candidates():
    try:
        lat = float(request.args.get("lat"))
        lon = float(request.args.get("lon"))
    except Exception:
        return {"ok": False, "message": "ç¼ºå°‘æˆ–éŒ¯èª¤çš„åº§æ¨™"}, 400

    try:
        # åŠå¾‘æ”¾å¯¬ä¸€é»ï¼Œæé«˜å‘½ä¸­ç‡ï¼›å·²å…§å»ºå¿«å–/å»é‡/æ’åº
        items = build_nearby_toilets("status", lat, lon, radius=700) or []
        out = []
        for t in items[:3]:
            out.append({
                "title": t.get("name") or t.get("place_hint") or "ï¼ˆæœªå‘½åï¼‰å»æ‰€",
                "address": t.get("address") or "",
                # ç”¨ norm_coordï¼ˆå­—ä¸²ï¼‰è®“ä¹‹å¾Œæ¯”å°è©¦ç®—è¡¨åº§æ¨™æ›´ç©©å®š
                "lat": norm_coord(t["lat"]),
                "lon": norm_coord(t["lon"]),
                "distance": int(t.get("distance", 0))
            })
        return {"ok": True, "candidates": out}, 200
    except Exception as e:
        logging.error(f"/api/status_candidates å¤±æ•—: {e}")
        return {"ok": False, "message": "server error"}, 500

# ==== ç‹€æ…‹ï¼šå›å ±ï¼ˆé  submit_status_update å¯«å…¥ status åˆ†é ï¼‰====
@app.route("/api/status_report", methods=["POST"])
def api_status_report():
    try:
        payload = request.get_json(force=True)
        lat = float(payload["lat"])
        lon = float(payload["lon"])
        status_text = (payload.get("status") or "").strip()
        user_id = (payload.get("user_id") or "").strip()
        display_name = (payload.get("display_name") or "").strip()
        note = (payload.get("note") or "").strip()
    except Exception:
        return {"ok": False, "message": _api_L("åƒæ•¸éŒ¯èª¤", "Invalid parameters")}, 400

    allowed = {"æœ‰äººæ’éšŠ", "ç¼ºè¡›ç”Ÿç´™", "æš«åœä½¿ç”¨", "æ¢å¾©æ­£å¸¸"}
    if status_text not in allowed:
        return {"ok": False, "message": _api_L("ä¸æ”¯æ´çš„ç‹€æ…‹", "Unsupported status")}, 400

    try:
        ok = submit_status_update(lat, lon, status_text, user_id, display_name, note)
        return ({"ok": True}, 200) if ok else ({"ok": False, "message": _api_L("å¯«å…¥å¤±æ•—", "Write failed")}, 500)
    except Exception as e:
        logging.error(f"/api/status_report å¯«å…¥å¤±æ•—: {e}")
        return {"ok": False, "message": "server error"}, 500

# === å›é¥‹ ===
@app.route("/submit_feedback", methods=["POST"])
def submit_feedback():
    _ensure_sheets_ready()
    logging.info(f"[submit_feedback] content_type={request.content_type}")
    logging.info(f"[submit_feedback] form={request.form.to_dict(flat=True)}")
    logging.info(f"[submit_feedback] args={request.args.to_dict(flat=True)}")

    try:
        payload_json = request.get_json(silent=True)
        if payload_json and isinstance(payload_json, dict) and len(payload_json) > 0:
            data = payload_json
            src = "json"
            getv = lambda k, d="": (data.get(k) if data.get(k) is not None else d)
            debug_dump = str(data)
        else:
            data = request.form
            src = "form"
            getv = lambda k, d="": (data.get(k, d) if data.get(k, d) is not None else d)
            try:
                debug_dump = str(data.to_dict(flat=True))
            except Exception:
                debug_dump = "<form>"

        # âœ… åŸºæœ¬æ¬„ä½ï¼ˆçµ±ä¸€ç”¨ getvï¼‰
        name = (getv("name", "") or "").strip()
        address = (getv("address", "") or "").strip()

        # âœ… ä¿®æ­£é‡é»ï¼šlat/lon ä¹Ÿçµ±ä¸€ç”¨ getvï¼Œä¸¦å…è¨±å¾ args è£œæ•‘
        lat_raw = ((getv("lat", "") or request.args.get("lat") or "")).strip()
        lon_raw = ((getv("lon", "") or request.args.get("lon") or "")).strip()

        lat_f, lon_f = _parse_lat_lon(lat_raw, lon_raw)
        if lat_f is None or lon_f is None:
            return (
                "åº§æ¨™æ ¼å¼éŒ¯èª¤\n"
                f"src={src}\n"
                f"lat_raw={lat_raw}\n"
                f"lon_raw={lon_raw}\n"
                f"payload={debug_dump}"
            ), 400

        lat = norm_coord(lat_f)
        lon = norm_coord(lon_f)

        # âœ… å…¶ä»–æ¬„ä½ï¼ˆçµ±ä¸€ç”¨ getvï¼‰
        rating = ((getv("rating", "") or "")).strip()
        toilet_paper = ((getv("toilet_paper", "") or "")).strip()
        accessibility = ((getv("accessibility", "") or "")).strip()
        time_of_use = ((getv("time_of_use", "") or "")).strip()
        comment = ((getv("comment", "") or "")).strip()
        floor_hint = ((getv("floor_hint", "") or "")).strip()

        # âœ… å¿…å¡«æª¢æŸ¥ï¼ˆèˆ‡å‰ç«¯ required å°é½Šï¼‰
        missing = []
        if not name: missing.append("name")
        if not rating: missing.append("rating")
        if not lat_raw: missing.append("lat")
        if not lon_raw: missing.append("lon")
        if not toilet_paper: missing.append("toilet_paper")
        if not accessibility: missing.append("accessibility")

        if missing:
            return (
                "ç¼ºå°‘å¿…è¦æ¬„ä½ï¼ˆéœ€è¦ï¼šnameã€ratingã€toilet_paperã€accessibilityã€latã€lonï¼‰\n"
                f"missing={missing}\n"
                f"src={src}\n"
                f"æ”¶åˆ°ï¼šname={name}, rating={rating}, paper={toilet_paper}, access={accessibility}, lat={lat_raw}, lon={lon_raw}\n"
                f"payload={debug_dump}"
            ), 400

        # âœ… rating æª¢æŸ¥
        try:
            r = int(rating)
            if r < 1 or r > 10:
                return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆåœ¨ 1 åˆ° 10 ä¹‹é–“", 400
        except ValueError:
            return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆæ˜¯æ•¸å­—", 400

        if floor_hint and len(floor_hint) < 1:
            return "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—", 400

        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        cur_feat = [r, paper_map.get(toilet_paper, 0), access_map.get(accessibility, 0)]

        hist_feats = []
        try:
            rows = feedback_sheet.get_all_values()
            header = rows[0]; data_rows = rows[1:]
            idx = _feedback_indices(header)

            def close(a, b, tol=1e-6):
                try: return abs(float(a) - float(b)) <= tol
                except: return False

            same_coord = []
            for row in data_rows:
                if idx["lat"] is None or idx["lon"] is None:
                    break
                if len(row) <= max(idx["lat"], idx["lon"]):
                    continue
                if close(row[idx["lat"]], lat) and close(row[idx["lon"]], lon):
                    same_coord.append(row)

            if idx["created"] is not None:
                same_coord.sort(key=lambda x: x[idx["created"]], reverse=True)
            recent = same_coord[:LAST_N_HISTORY]

            if idx["rating"] is not None:
                for row in recent:
                    try:
                        rr = int((row[idx["rating"]] or "").strip())
                    except:
                        continue
                    pp = (row[idx["paper"]] or "").strip() if idx["paper"] is not None else "æ²’æ³¨æ„"
                    aa = (row[idx["access"]] or "").strip() if idx["access"] is not None else "æ²’æ³¨æ„"
                    hist_feats.append([rr, paper_map.get(pp,0), access_map.get(aa,0)])
        except Exception as e:
            logging.warning(f"è®€æ­·å²å›é¥‹å¤±æ•—ï¼Œåƒ…ç”¨å–®ç­†ç‰¹å¾µé æ¸¬ï¼š{e}")

        pred_with_hist = expected_from_feats([cur_feat] + hist_feats) or expected_from_feats([cur_feat]) or "æœªé æ¸¬"

        feedback_sheet.append_row([
            name, address, rating, toilet_paper, accessibility, time_of_use,
            comment, pred_with_hist, lat, lon, datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            floor_hint
        ], value_input_option="USER_ENTERED")

        uid = (request.args.get("uid") or "").strip()
        lang = (request.args.get("lang") or "").strip().lower()
        target = f"/toilet_feedback_by_coord/{lat}/{lon}"
        if uid:
            target = _append_uid_lang(target, uid, (lang if lang in ("en","zh") else _user_lang_q(uid)))
        return redirect(target)

    except Exception as e:
        logging.error(f"âŒ æäº¤å›é¥‹è¡¨å–®éŒ¯èª¤: {e}", exc_info=True)
        return "æäº¤å¤±æ•—", 500

# === è®€åº§æ¨™çš„å›é¥‹æ¸…å–® ===
def get_feedbacks_by_coord(lat, lon, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return []
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return []

        # ğŸ”§ è£œä¸Šé€™è¡Œ
        idx = _feedback_indices(header)

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        out = []
        for r in data:
            if idx["lat"] is None or idx["lon"] is None:
                break
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                def val(key):
                    i = idx[key]
                    return (r[i] if i is not None and len(r) > i else "").strip()
                out.append({
                    "rating": val("rating"),
                    "toilet_paper": val("paper"),
                    "accessibility": val("access"),
                    "time_of_use": val("time"),
                    "comment": safe_html(val("comment")),
                    "cleanliness_score": val("pred"),
                    "created_at": val("created"),
                })
        out.sort(key=lambda d: d.get("created_at", ""), reverse=True)
        return out
    except Exception as e:
        logging.error(f"âŒ è®€å–å›é¥‹åˆ—è¡¨ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return []

# === åº§æ¨™èšåˆçµ±è¨ˆ ===
def get_feedback_summary_by_coord(lat, lon, tol=1e-6):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return "å°šç„¡å›é¥‹è³‡æ–™"
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        # ğŸ”§ è£œä¸Šé€™è¡Œ
        idx = _feedback_indices(header)

        if idx["lat"] is None or idx["lon"] is None:
            return "ï¼ˆè¡¨é ­ç¼ºå°‘ lat/lon æ¬„ä½ï¼‰"

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched.append(r)

        if not matched:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        scores = []
        comments = []

        for r in matched:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                scores.append(float(sc))
            if pp in paper_counts: paper_counts[pp] += 1
            if aa in access_counts: access_counts[aa] += 1
            if idx["comment"] is not None and len(r) > idx["comment"]:
                c = (r[idx["comment"]] or "").strip()
                if c:
                    comments.append(c)

        avg_score = round(sum(scores) / len(scores), 2) if scores else "æœªé æ¸¬"

        summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\n"
        summary += f"ğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg_score}\n"
        summary += f"ğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰'] >= paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        summary += f"â™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰'] >= access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        if comments:
            # ä½ ç¾åœ¨æ‹¿ comments[-1]ï¼Œå› ç‚º _get_header_and_tail å–å°¾å·´ï¼Œ
            # é€šå¸¸æœ€å¾Œä¸€ç­†å°±æ˜¯æœ€æ–°ï¼Œé€™é‚è¼¯ OKã€‚
            summary += f"ğŸ’¬ æœ€æ–°ç•™è¨€ï¼š{comments[-1]}"
        return summary
    except Exception as e:
        logging.error(f"âŒ æŸ¥è©¢å›é¥‹çµ±è¨ˆï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "è®€å–éŒ¯èª¤"

# === æŒ‡ç¤ºç‡ˆç´¢å¼• ===
_feedback_index_cache = {"ts": 0, "data": {}}
# _FEEDBACK_INDEX_TTL is defined in global config section (see above)
def build_feedback_index():
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {}

    global _feedback_index_cache

    now = time.time()
    # âš ï¸ æ³¨æ„é€™è£¡ç”¨çš„æ˜¯ã€Œæœ‰åº•ç·šã€çš„ TTL è®Šæ•¸
    if (now - _feedback_index_cache["ts"] < _FEEDBACK_INDEX_TTL) and _feedback_index_cache["data"]:
        return _feedback_index_cache["data"]

    # å¯èª¿ï¼šæœ€å¤šèšåˆå¤šå°‘å€‹åº§æ¨™é»ï¼Œé¿å… bucket çˆ†æ‰
    try:
        FEEDBACK_INDEX_MAX_KEYS = int(os.getenv("FEEDBACK_INDEX_MAX_KEYS", "800"))
    except Exception:
        FEEDBACK_INDEX_MAX_KEYS = 800

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            _feedback_index_cache = {"ts": now, "data": {}}
            return {}

        idx = _feedback_indices(header)
        i_lat = idx.get("lat"); i_lon = idx.get("lon")
        if i_lat is None or i_lon is None:
            _feedback_index_cache = {"ts": now, "data": {}}
            return {}
        
        bucket = {}
        for r in data:
            # åŸºæœ¬é•·åº¦æª¢æŸ¥
            if max(i_lat, i_lon) >= len(r):
                continue
            try:
                lat_s = norm_coord(r[i_lat])
                lon_s = norm_coord(r[i_lon])
            except Exception:
                continue
            if not lat_s or not lon_s:
                continue

            key = (lat_s, lon_s)

            # æ§åˆ¶ key æ•¸é‡ä¸Šé™ï¼šå·²æœ‰çš„å¯ä»¥ç´¯åŠ ï¼Œæ–° key è¶…éä¸Šé™å°±è·³é
            if key not in bucket and len(bucket) >= FEEDBACK_INDEX_MAX_KEYS:
                continue

            rec = bucket.setdefault(
                key,
                {"paper_has": 0, "paper_no": 0, "acc_has": 0, "acc_no": 0, "sum": 0.0, "n": 0}
            )

            sc, rr, pp, aa = _pred_from_row(r, idx)

            # ç´™å·¾ï¼ç„¡éšœç¤™ç´¯è¨ˆ
            if pp == "æœ‰":
                rec["paper_has"] += 1
            elif pp == "æ²’æœ‰":
                rec["paper_no"] += 1

            if aa == "æœ‰":
                rec["acc_has"] += 1
            elif aa == "æ²’æœ‰":
                rec["acc_no"] += 1

            # åˆ†æ•¸ç´¯è¨ˆ
            if isinstance(sc, (int, float)):
                try:
                    rec["sum"] += float(sc)
                    rec["n"] += 1
                except Exception:
                    pass

        # è¼¸å‡º
        out = {}
        for key, v in bucket.items():
            paper_total = v["paper_has"] + v["paper_no"]
            access_total = v["acc_has"] + v["acc_no"]
            paper = "æœ‰" if (paper_total > 0 and v["paper_has"] >= v["paper_no"]) else ("æ²’æœ‰" if paper_total > 0 else "?")
            access = "æœ‰" if (access_total > 0 and v["acc_has"] >= v["acc_no"]) else ("æ²’æœ‰" if access_total > 0 else "?")
            avg = round(v["sum"] / v["n"], 2) if v["n"] > 0 else None
            out[key] = {"paper": paper, "access": access, "avg": avg}

        _feedback_index_cache = {"ts": now, "data": out}
        return out

    except Exception as e:
        logging.warning(f"å»ºç«‹æŒ‡ç¤ºç‡ˆç´¢å¼•å¤±æ•—ï¼š{e}")
        _feedback_index_cache["ts"] = now
        _feedback_index_cache["data"] = {}
        return {}

def submit_status_update(lat, lon, status_text, user_id="", display_name="", note=""):
    _ensure_sheets_ready()
    if status_ws is None:
        return False
    try:
        row = [
            norm_coord(lat), norm_coord(lon),
            status_text.strip(), user_id or "", display_name or "",
            (note or "").strip(),
            datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        ]
        status_ws.append_row(row, value_input_option="USER_ENTERED")
        _status_index_cache["ts"] = 0  # ç«‹åˆ»å¤±æ•ˆå¿«å–
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥ç‹€æ…‹å¤±æ•—: {e}")
        return False

def _is_close_m(lat1, lon1, lat2, lon2, th=_STATUS_NEAR_M):
    try:
        return haversine(float(lat1), float(lon1), float(lat2), float(lon2)) <= th
    except:
        return False

def build_status_index():
    _ensure_sheets_ready()
    if status_ws is None:
        return {}

    now = time.time()
    # âœ… ä¿®æ­£ï¼šä½¿ç”¨æœ‰åº•ç·šçš„ TTL è®Šæ•¸ï¼ˆä½ å‰é¢å®šç¾©çš„æ˜¯ _STATUS_INDEX_TTLï¼‰
    if (now - _status_index_cache["ts"] < _STATUS_INDEX_TTL) and _status_index_cache["data"]:
        return _status_index_cache["data"]

    # ä¸Šé™ä¿è­·ï¼Œé¿å…å¤§é‡æ–°åº§æ¨™æŠŠè¨˜æ†¶é«”æ’çˆ†ï¼ˆå¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼‰
    try:
        STATUS_INDEX_MAX_KEYS = int(os.getenv("STATUS_INDEX_MAX_KEYS", "800"))
    except Exception:
        STATUS_INDEX_MAX_KEYS = 800

    out = {}
    try:
        header, data = _get_header_and_tail(status_ws, MAX_SHEET_ROWS)
        if not header or not data:
            _status_index_cache.update(ts=now, data={})
            return {}

        idx = {h: i for i, h in enumerate(header)}
        i_lat = idx.get("lat"); i_lon = idx.get("lon")
        i_status = idx.get("status"); i_ts = idx.get("timestamp")
        if None in (i_lat, i_lon, i_status):
            _status_index_cache.update(ts=now, data={})
            return {}

        def fresh(ts_s: str) -> bool:
            if not ts_s:
                return False
            try:
                dt = datetime.strptime(ts_s, "%Y-%m-%d %H:%M:%S")
                return (datetime.utcnow() - dt).total_seconds() <= _STATUS_TTL_HOURS * 3600
            except Exception:
                return False

        # ä»¥ã€Œå·²åˆä½µæ¸…å–®ã€ç¶­è­·ä»£è¡¨é»ï¼›æ¯ç­†è³‡æ–™åªèˆ‡æ—¢æœ‰ä»£è¡¨é»æ¯” 35mï¼ˆ_STATUS_NEAR_Mï¼‰å…§æ˜¯å¦æ›´æ–°
        merged = []
        for r in data:
            # é‚Šç•Œä¿è­·
            if max(i_lat, i_lon, i_status) >= len(r):
                continue

            lat_s, lon_s = norm_coord(r[i_lat]), norm_coord(r[i_lon])
            st = (r[i_status] or "").strip()
            ts = (r[i_ts] if i_ts is not None and i_ts < len(r) else "")

            if not fresh(ts):
                continue

            placed = False
            # å˜—è©¦åˆä½µåˆ°æ—¢æœ‰ä»£è¡¨é»ï¼ˆè·é›¢ <= _STATUS_NEAR_Mï¼‰
            for m in merged:
                if _is_close_m(lat_s, lon_s, m["lat"], m["lon"]):
                    # å–è¼ƒæ–°çš„é‚£ç­†
                    if ts > m["ts"]:
                        m.update(lat=lat_s, lon=lon_s, status=st, ts=ts)
                    placed = True
                    break

            if not placed:
                # ä¸Šé™ä¿è­·ï¼šè¶…éä¸Šé™ä¸å†åŠ å…¥æ–°ç¾¤çµ„ï¼Œä½†ä»å…è¨±æ›´æ–°æ—¢æœ‰ç¾¤çµ„ï¼ˆè¦‹ä¸Šé¢ï¼‰
                if len(merged) < STATUS_INDEX_MAX_KEYS:
                    merged.append({"lat": lat_s, "lon": lon_s, "status": st, "ts": ts})
                else:
                    # å·²æ»¿å°±ç•¥éæ–°ä½ç½®ï¼Œé¿å…ç„¡ä¸Šé™æˆé•·
                    continue

        # è½‰æˆè¼¸å‡ºæ ¼å¼
        for m in merged:
            out[(m["lat"], m["lon"])] = {"status": m["status"], "ts": m["ts"]}

        _status_index_cache.update(ts=now, data=out)
        return out

    except Exception as e:
        logging.warning(f"å»ºç«‹ç‹€æ…‹ç´¢å¼•å¤±æ•—ï¼š{e}")
        _status_index_cache["ts"] = now
        _status_index_cache["data"] = {}
        return {}

# ==== ç’°å¢ƒè®Šæ•¸ï¼ˆçµ±ä¸€ LIFF è®€å–ï¼‰====
def _get_liff_status_id() -> str:
    return (
        os.getenv("LIFF_STATUS_ID")      
        or os.getenv("LIFF_ID_STATUS")
        or os.getenv("LIFF_ID")
        or ""
    ).strip()

LIFF_ID_STATUS = _get_liff_status_id()
PUBLIC_URL = os.getenv("PUBLIC_URL", "").rstrip("/")

# ==== é é¢ routes ====
@app.route("/achievements_liff")
def achievements_liff_page():
    uid = (request.args.get("uid") or "").strip()
    lang = (request.args.get("lang") or "").strip().lower()
    if uid and not lang:
        try:
            lang = "en" if get_user_lang(uid) == "en" else "zh"
        except Exception:
            lang = "zh"
        qs = request.args.to_dict(flat=True)
        qs["lang"] = lang
        return redirect(request.path + "?" + urllib.parse.urlencode(qs), code=302)

    return render_template(
        "achievements_liff.html",
        liff_id=LIFF_ID_STATUS,
        public_url=PUBLIC_URL,
        uid=uid,
        lang=(lang if lang in ["en","zh"] else "zh")
    )

@app.route("/badges_liff")
def badges_liff_page():
    uid = (request.args.get("uid") or "").strip()
    lang = (request.args.get("lang") or "").strip().lower()
    if uid and not lang:
        try:
            lang = "en" if get_user_lang(uid) == "en" else "zh"
        except Exception:
            lang = "zh"
        qs = request.args.to_dict(flat=True)
        qs["lang"] = lang
        return redirect(request.path + "?" + urllib.parse.urlencode(qs), code=302)

    return render_template(
        "badges_liff.html",
        liff_id=LIFF_ID_STATUS,
        public_url=PUBLIC_URL,
        uid=uid,
        lang=(lang if lang in ["en","zh"] else "zh")
    )

# ==== å°å·¥å…·ï¼šè®€å–ç‹€æ…‹è¡¨ä¸¦å½™ç¸½ ====
def _read_status_rows():
    try:
        _ensure_sheets_ready()
        ws = status_ws
        if not ws:
            return []
        try:
            header, data = _get_header_and_tail(ws)
        except Exception:
            header, data = _get_header_and_tail(ws, MAX_SHEET_ROWS)
            if not header:
                return []

        ix = {h: i for i, h in enumerate(header)}
        out = []
        for r in data:
            def g(k):
                i = ix.get(k); 
                return (r[i].strip() if (i is not None and i < len(r)) else "")
            out.append({
                "lat": g("lat"), "lon": g("lon"),
                "status": g("status"),
                "user_id": g("user_id"),
                "display_name": g("display_name"),
                "timestamp": g("timestamp"),
            })
        return out
    except Exception as e:
        logging.error(f"_read_status_rows error: {e}")
        return []
def _parse_ts(ts: str):
    try:
        s = (ts or "").strip()
        if not s:
            return None

        # ISO Z â†’ +00:00
        if s.endswith("Z"):
            s = s[:-1] + "+00:00"

        try:
            return datetime.fromisoformat(s)
        except Exception:
            pass

        for fmt in (
            "%Y-%m-%d %H:%M:%S",
            "%Y/%m/%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y/%m/%d %H:%M",
        ):
            try:
                return datetime.strptime(s, fmt)
            except Exception:
                continue

        return None
    except Exception:
        return None

def _stats_for_user(uid: str):
    rows = _read_status_rows()
    total = 0
    by_status = {}
    last_ts = None

    for r in rows:
        if uid and r.get("user_id") != uid:
            continue

        total += 1
        s = r.get("status") or ""
        by_status[s] = by_status.get(s, 0) + 1

        ts = r.get("timestamp")
        if ts:
            t = _parse_ts(ts)
            if t is not None:
                if last_ts is None or t > last_ts:
                    last_ts = t

    return {
        "total": total,
        "by_status": by_status,
        "last_ts": last_ts.isoformat() if last_ts else None
    }

def get_search_count(uid: str) -> int:
    try:
        conn = _get_db()
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM search_log WHERE user_id = ?", (uid,))
        row = cur.fetchone()
        conn.close()
        return int(row[0]) if row and row[0] is not None else 0
    except Exception as e:
        logging.warning(f"æŸ¥è©¢ search_log å¤±æ•—: {e}")
        return 0

# ==== æˆå°± API ====
ACHIEVEMENT_RULES = {
    "first": {
        "goal": 1,
        "counter": "total",
        "desc": {
            "zh": "å®Œæˆç¬¬ä¸€æ¬¡ç‹€æ…‹å›å ±",
            "en": "Complete your first status report"
        }
    },
    "helper10": {
        "goal": 10,
        "counter": "total",
        "desc": {
            "zh": "ç´¯ç©å›å ± 10 æ¬¡",
            "en": "Report status 10 times"
        }
    },
    "pro_reporter": {
        "goal": 20,
        "counter": "total",
        "desc": {
            "zh": "ç´¯ç©å›å ± 20 æ¬¡",
            "en": "Report status 20 times"
        }
    },
    "helper50": {
        "goal": 50,
        "counter": "total",
        "desc": {
            "zh": "ç´¯ç©å›å ± 50 æ¬¡",
            "en": "Report status 50 times"
        }
    },
    "tissue_guard": {
        "goal": 3,
        "counter": "ç¼ºè¡›ç”Ÿç´™",
        "desc": {
            "zh": "å›å ±ã€ç¼ºè¡›ç”Ÿç´™ã€æ»¿ 3 æ¬¡",
            "en": "Report of 'toilet paper' shortage 3 time"
        }
    },
    "tissue_master": {
        "goal": 10,
        "counter": "ç¼ºè¡›ç”Ÿç´™",
        "desc": {
            "zh": "å›å ±ã€ç¼ºè¡›ç”Ÿç´™ã€æ»¿ 10 æ¬¡",
            "en": "Report of 'toilet paper' shortage 10 time"
        }
    },
    "queue_scout": {
    "goal": 3,
    "counter": "æœ‰äººæ’éšŠ",
    "desc": {
        "zh": "å›å ±ã€æœ‰äººæ’éšŠã€æ»¿ 3 æ¬¡",
        "en": "Report 'Queue present' status 3 times"
    }
    },
    "queue_commander": {
        "goal": 10,
        "counter": "æœ‰äººæ’éšŠ",
        "desc": {
            "zh": "å›å ±ã€æœ‰äººæ’éšŠã€æ»¿ 10 æ¬¡",
            "en": "Report 'Queue present' status 10 times"
        }
    },
    "maintenance_watcher": {
        "goal": 3,
        "counter": "æš«åœä½¿ç”¨",
        "desc": {
            "zh": "å›å ±ã€æš«åœä½¿ç”¨ã€æ»¿ 3 æ¬¡",
            "en": "Report 'Out of service' status 3 times"
        }
    },
    "good_news": {
        "goal": 5,
        "counter": "æ¢å¾©æ­£å¸¸",
        "desc": {
            "zh": "å›å ±ã€æ¢å¾©æ­£å¸¸ã€æ»¿ 5 æ¬¡",
            "en": "Report 'Back to normal' status 5 times"
        }
    },
}

@app.route("/api/achievements")
def api_achievements():
    uid = request.args.get("user_id", "").strip()
    stats = _stats_for_user(uid)
    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}

    # âœ… èªè¨€åªæŸ¥ä¸€æ¬¡ï¼ˆä¸è¦æ”¾åœ¨è¿´åœˆå…§ï¼‰
    lang = get_user_lang(uid)

    out = []
    for cfg in BADGE_CONFIG:
        key = cfg["key"]
        rule = ACHIEVEMENT_RULES.get(key)
        if not rule:
            # å¦‚æœæœ‰åœ¨ BADGE_CONFIG å¢åŠ æ–° key ä½†é‚„æ²’åœ¨ ACHIEVEMENT_RULES å®šç¾©ï¼Œå°±å…ˆè·³é
            continue

        counter_type = rule["counter"]
        if counter_type == "total":
            progress = total
        else:
            # counter_type å°æ‡‰åˆ° by_status è£¡çš„ä¸­æ–‡ keyï¼Œä¾‹å¦‚ã€Œç¼ºè¡›ç”Ÿç´™ã€ã€Œæœ‰äººæ’éšŠã€ç­‰
            progress = int(by.get(counter_type, 0) or 0)

        goal = int(rule["goal"] or 0)

        out.append({
            "key": key,
            "title": cfg["name"],  # å’Œå¾½ç« åç¨±ä¸€è‡´
            "desc": (rule["desc"]["en"] if lang == "en" else rule["desc"]["zh"]),
            "goal": goal,
            "progress": progress,
            # âœ… æˆå°±è§£é–æ‡‰è©²ç”¨æˆå°±è‡ªå·±çš„è¦å‰‡ï¼ˆprogress >= goalï¼‰
            "unlocked": (progress >= goal),
            "icon": cfg.get("icon", ""),
        })

    return {"ok": True, "achievements": out}, 200

def build_usage_review_text(uid: str) -> str:
    # æ”¹æˆç”¨ DB è£¡çš„ search_log çµ±è¨ˆæŸ¥è©¢æ¬¡æ•¸
    search_times = get_search_count(uid)

    stats = _stats_for_user(uid)
    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}
    last_ts = stats.get("last_ts") or L(uid, "å°šç„¡ç´€éŒ„", "No record")

    try:
        contribs = get_user_contributions(uid) or []
        num_contribs = len(contribs)
    except Exception:
        num_contribs = 0

    try:
        favs = get_user_favorites(uid) or []
        num_favs = len(favs)
    except Exception:
        num_favs = 0

    unlocked_badges = 0
    try:
        rules = _badge_rules(uid)
        unlocked_badges = sum(1 for v in rules.values() if v)
    except Exception:
        pass

    lines = []

    # === æŸ¥è©¢æ¬¡æ•¸ ===
    lines.append(L(
        uid,
        f"ãƒ»ä½ ç¸½å…±æŸ¥è©¢éé™„è¿‘å»æ‰€ï¼š{search_times} æ¬¡",
        f"â€¢ You searched nearby toilets {search_times} times"
    ))

    lines.append("")
    lines.append(L(uid, "ğŸ“Š ä½¿ç”¨å›é¡§", "ğŸ“Š Usage Summary"))
    lines.append("")

    # === ç‹€æ…‹å›å ± ===
    if total > 0:
        lines.append(L(
            uid,
            f"ãƒ»ç‹€æ…‹å›å ±æ¬¡æ•¸ï¼š{total} æ¬¡",
            f"â€¢ Status reports: {total} times"
        ))

        parts = []

        mapping = {
            "æ¢å¾©æ­£å¸¸": ("âœ…", "Back to normal"),
            "æœ‰äººæ’éšŠ": ("ğŸŸ¡", "Queue"),
            "ç¼ºè¡›ç”Ÿç´™": ("ğŸ§»", "No toilet paper"),
            "æš«åœä½¿ç”¨": ("â›”", "Out of service"),
        }

        for zh_key, (emo, en_label) in mapping.items():
            c = int(by.get(zh_key, 0) or 0)
            if c > 0:
                parts.append(
                    L(
                        uid,
                        f"{emo}{zh_key} {c} æ¬¡",
                        f"{emo}{en_label} {c}"
                    )
                )

        if parts:
            lines.append(L(
                uid,
                "  â”” ç‹€æ…‹é¡å‹ï¼š" + "ï½œ".join(parts),
                "  â”” Status types: " + " | ".join(parts)
            ))

        lines.append(L(
            uid,
            f"ãƒ»æœ€è¿‘ä¸€æ¬¡å›å ±æ™‚é–“ï¼š{last_ts}",
            f"â€¢ Last report time: {last_ts}"
        ))
    else:
        lines.append(L(
            uid,
            "ãƒ»ç›®å‰é‚„æ²’æœ‰ä»»ä½•ç‹€æ…‹å›å ±ç´€éŒ„",
            "â€¢ No status reports yet"
        ))

    lines.append("")

    # === æ–°å¢å»æ‰€ & æœ€æ„› ===
    lines.append(L(
        uid,
        f"ãƒ»ä½ æ–°å¢çš„å»æ‰€ï¼š{num_contribs} é–“",
        f"â€¢ Toilets you added: {num_contribs}"
    ))
    lines.append(L(
        uid,
        f"ãƒ»ä½ æ”¶è—çš„æœ€æ„›å»æ‰€ï¼š{num_favs} é–“",
        f"â€¢ Favorite toilets: {num_favs}"
    ))

    # === å¾½ç«  ===
    lines.append("")
    if unlocked_badges > 0:
        lines.append(L(
            uid,
            f"ğŸ… å·²è§£é–å¾½ç« æ•¸ï¼š{unlocked_badges} å€‹ï¼ˆå¯è¼¸å…¥ã€Œå¾½ç« ã€æŸ¥çœ‹è©³ç´°ï¼‰",
            f"ğŸ… Badges unlocked: {unlocked_badges} (type 'Badges' to view)"
        ))
    else:
        lines.append(L(
            uid,
            "ğŸ… é‚„æ²’è§£é–å¾½ç« ï¼Œè©¦è‘—å¤šå›å ±å¹¾æ¬¡ç‹€æ…‹å°±æœƒæ…¢æ…¢è§£é–å›‰ï¼",
            "ğŸ… No badges unlocked yet. Try reporting more status updates!"
        ))

    lines.append("")
    lines.append(L(
        uid,
        "ğŸ” å°æé†’ï¼šå¯ä»¥è¼¸å…¥ã€Œé™„è¿‘å»æ‰€ã€æˆ–å‚³é€ä½ç½®ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€ ğŸš½",
        "ğŸ” Tip: Type 'Nearby toilets' or share your location to find toilets ğŸš½"
    ))

    lines.append("")
    lines.append(L(
        uid,
        "ğŸ¤– æŸ¥çœ‹ AI ç‚ºä½ ç”Ÿæˆçš„å€‹äººåŒ–ä½¿ç”¨åˆ†æï¼š",
        "ğŸ¤– View your AI-generated personal usage summary:"
    ))
    base = _base_url()
    lines.append(f"ğŸ‘‰ {base}/ai_usage_summary_page/{uid}")

    return "\n".join(lines)

def build_ai_usage_summary(uid: str) -> str:
    """
    ç”¨ AI å¹«ä½¿ç”¨è€…åšã€å€‹äººä½¿ç”¨å›é¡§ã€ç¸½çµã€‚
    - æœ‰è³‡æ–™æ™‚ï¼šå‘¼å« OpenAI ç”¢ç”Ÿç²¾ç°¡çš„ Wrapped é¢¨æ ¼æ–‡å­—
    - è³‡æ–™å¤ªå°‘æ™‚ï¼šç›´æ¥å›å›ºå®šæç¤ºï¼Œä¸æµªè²» AI æµé‡
    - æ²’æœ‰ AI client æ™‚ï¼šé€€å›åŸæœ¬çš„æ–‡å­—ç‰ˆä½¿ç”¨å›é¡§
    """
    # å…ˆæ‹¿ä½ åŸæœ¬çš„è³‡æ–™ä¾†æº
    search_times = get_search_count(uid)  # è³‡æ–™è¡¨ search_log
    stats = _stats_for_user(uid)          # ç‹€æ…‹å›å ±çµ±è¨ˆ

    total = int(stats.get("total", 0) or 0)
    by = stats.get("by_status", {}) or {}
    last_ts = stats.get("last_ts") or L(uid, "å°šç„¡ç´€éŒ„", "No record")

    try:
        contribs = get_user_contributions(uid) or []
        num_contribs = len(contribs)
    except Exception:
        num_contribs = 0

    try:
        favs = get_user_favorites(uid) or []
        num_favs = len(favs)
    except Exception:
        num_favs = 0

    # å¾½ç« æ•¸
    unlocked_badges = 0
    try:
        rules = _badge_rules(uid)
        unlocked_badges = sum(1 for v in rules.values() if v)
    except Exception:
        pass

    # ğŸ”¹ å¦‚æœå¹¾ä¹æ²’æœ‰ä»»ä½•ç´€éŒ„ï¼Œå°±ä¸è¦æµªè²» AIï¼Œç›´æ¥å›å›ºå®šæ–‡å­—
    if (search_times == 0 and total == 0 and
        num_contribs == 0 and num_favs == 0 and
        unlocked_badges == 0):
        return L(
            uid,
            "ç›®å‰é‚„æ²’æœ‰è¶³å¤ çš„ä½¿ç”¨ç´€éŒ„å¯ä»¥ç”¢ç”Ÿ AI ä½¿ç”¨å›é¡§å–”ï½\n"
            "å¯ä»¥å¤šå¤šä½¿ç”¨ã€Œé™„è¿‘å»æ‰€ã€ã€Œç‹€æ…‹å›å ±ã€ã€Œæ–°å¢å»æ‰€ã€ã€Œæ”¶è—æœ€æ„›ã€ï¼Œ\n"
            "ä¹‹å¾Œæˆ‘æœƒå¹«ä½ åšä¸€ä»½å°ˆå±¬çš„ä½¿ç”¨å ±å‘Š ğŸ™Œ",
            "Not enough usage data yet to generate an AI usage summary.\n"
            "Try using Nearby Toilets, Status Report, Add Toilet, and Favorites more often.\n"
            "Iâ€™ll prepare a personalized report for you soon ğŸ™Œ"
        )

    # ğŸ”¸ client é˜²å‘†ï¼ˆé¿å… client å°šæœªåˆå§‹åŒ–å°±è¢«å‘¼å«ï¼‰
    _client = globals().get("client", None)
    if _client is None:
        return build_usage_review_text(uid)

    # ğŸ”¹ æ¯å€‹ä½¿ç”¨è€…ã€ŒAI ä½¿ç”¨å›é¡§ã€æ¯å¤©æœ€å¤šè§¸ç™¼ AI_DAILY_LIMIT æ¬¡
    ok, used = _ai_quota_check_and_inc(f"usage:{uid or 'anonymous'}")
    if not ok:
        base = build_usage_review_text(uid)
        return base + "\n\nï¼ˆä»Šæ—¥ AI ä½¿ç”¨å›é¡§æ¬¡æ•¸å·²é”ä¸Šé™ï¼Œæ˜å¤©å†ä¾†çœ‹çœ‹æ–°çš„åˆ†æå§ ğŸ™ï¼‰"

    # âœ… ä¾ä½¿ç”¨è€…èªè¨€æ±ºå®š AI å›è¦†èªè¨€ï¼ˆåŠ é˜²å‘†ï¼‰
    try:
        lang = get_user_lang(uid)
    except Exception:
        lang = "zh"

    payload = {
        "search_times": search_times,
        "status_total": total,
        "status_by_type": by,
        "last_status_time": last_ts,
        "contributions": num_contribs,
        "favorites": num_favs,
        "unlocked_badges": unlocked_badges,
    }

    try:
        import json
        payload_json = json.dumps(payload, ensure_ascii=False)

        # âœ… ä¸­è‹± prompt åˆ†é›¢ï¼ˆé¿å…æ¨¡å‹èªè¨€æ··äº‚ï¼‰
        prompt_zh = f"""
ä½ æ˜¯ä¸€å€‹æº«æš–çš„ç”Ÿæ´»å°åŠ©æ‰‹ï¼Œè¦å¹«ä½¿ç”¨è€…ç¸½çµä»–ä½¿ç”¨ã€Œæ™ºæ…§å»æ‰€åŠ©æ‰‹ã€çš„æƒ…æ³ã€‚

ä¸‹é¢æ˜¯ä¸€ä½ä½¿ç”¨è€…çš„ä½¿ç”¨çµ±è¨ˆè³‡æ–™ï¼ˆJSONï¼‰ï¼š
{payload_json}

è«‹æ ¹æ“šé€™äº›æ•¸æ“šï¼Œå¹«ä»–ç”¢ç”Ÿä¸€æ®µã€Œå€‹äººä½¿ç”¨å›é¡§ã€ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- æ•´é«”ç¯‡å¹…æ§åˆ¶åœ¨ 4ï½7 è¡Œä»¥å…§
- ç¬¬ 1 è¡Œï¼šWrapped é¢¨æ ¼çš„ä¸€å¥é–‹å ´ç¸½çµ
- æ¥è‘—åˆ—å‡º 3ï½5 é»é‡é»ï¼ˆç”¨æ¢åˆ—ï¼‰
  - æŸ¥è©¢é™„è¿‘å»æ‰€æ¬¡æ•¸
  - ç‹€æ…‹å›å ±æ¬¡æ•¸ã€æœ€å¸¸è¦‹çš„ç‹€æ…‹é¡å‹
  - æ–°å¢å»æ‰€æ•¸
  - æ”¶è—æœ€æ„›æ•¸
  - è§£é–å¾½ç« æ•¸ï¼ˆè‹¥æœ‰ï¼‰
- æœ€å¾Œ 1 è¡Œï¼šä¸€å¥é¼“å‹µæˆ–å°å»ºè­°

è«‹ç›´æ¥è¼¸å‡ºçµ¦ä½¿ç”¨è€…çœ‹çš„å…§å®¹ï¼Œä¸è¦å†å‡ºç¾ JSON æˆ–æŠ€è¡“æè¿°ã€‚
        """.strip()

        prompt_en = f"""
You are a warm, friendly assistant summarizing a user's usage of the "Smart Toilet Assistant".

Here is the user's usage stats (JSON):
{payload_json}

Write a short "usage recap" with:
- English only
- 4â€“7 lines total
- Line 1: a Wrapped-style headline
- Then 3â€“5 bullet highlights (searches, status reports + most common types, contributions, favorites, badges)
- Final line: a short encouragement or tip

Output user-facing text only. Do NOT include JSON or technical descriptions.
        """.strip()

        prompt = prompt_en if lang == "en" else prompt_zh
        system_msg = (
            "You are a friendly assistant that writes a short usage recap in English."
            if lang == "en"
            else "ä½ æ˜¯ä¸€å€‹å¹«å¿™åšä½¿ç”¨å›é¡§çš„ç”Ÿæ´»å°åŠ©æ‰‹ï¼Œèªªè©±è¦ªåˆ‡ã€ç°¡æ½”ï¼Œç”¨ç¹é«”ä¸­æ–‡ã€‚"
        )

        resp = _client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt}
            ],
        )

        summary = (resp.choices[0].message.content or "").strip()
        return summary or build_usage_review_text(uid)

    except Exception as e:
        logging.error(f"AI usage summary error: {e}", exc_info=True)
        return build_usage_review_text(uid)

def build_ai_nearby_recommendation(uid: str, toilets):
    """
    ä¾æ“šé™„è¿‘å»æ‰€æ¸…å–®ï¼Œå‘¼å« OpenAI å¹«å¿™ç”¢ç”Ÿä¸€æ®µæ¨è–¦èªªæ˜æ–‡å­—ã€‚
    - å¦‚æœæ²’æœ‰ AI é‡‘é‘° / æ²’æœ‰å»æ‰€è³‡æ–™ï¼Œå°±ç›´æ¥å›ç©ºå­—ä¸²ï¼Œä¸å½±éŸ¿åŸæœ¬æµç¨‹
    - æ¯ä½ä½¿ç”¨è€…æ¯å¤© AI æ¨è–¦æ¬¡æ•¸æœ‰é™ï¼Œè¶…éå°±å›æç¤ºæ–‡å­—
    """
    if client is None:
        return ""
    if not toilets:
        return ""

    # ğŸ”¹ æ¯å€‹ä½¿ç”¨è€…ã€ŒAI æ¨è–¦é™„è¿‘å»æ‰€ã€æ¯å¤©æœ€å¤šè§¸ç™¼ AI_DAILY_LIMIT æ¬¡
    try:
        quota_key = uid or "anonymous"
        ok, used = _ai_quota_check_and_inc(f"nearby:{quota_key}")
    except Exception as e:
        logging.warning(f"AI nearby quota check failed: {e}")
        ok = True  # quota å£æ‰æ™‚ç•¶ä½œä¸é™åˆ¶

    if not ok:
        return L(
            uid,
            "ä»Šå¤© AI æ¨è–¦é™„è¿‘å»æ‰€çš„æ¬¡æ•¸å·²é”æ¯æ—¥ä¸Šé™å–”ï½\n"
            "å¦‚æœé‚„éœ€è¦æŸ¥è©¢ï¼Œå»ºè­°å…ˆåˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ ğŸ‘",
            "You have reached today's AI nearby recommendation limit.\n"
            "Please switch back to normal mode to continue ğŸ‘"
        )

    # âœ… 3-3ï¼šä¾ä½¿ç”¨è€…èªè¨€æ±ºå®š AI å›è¦†èªè¨€
    lang = get_user_lang(uid)
    lang_rule = "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚" if lang != "en" else "Please answer in English."

    try:
        import json

        # æœ€å¤šæ‹¿å‰ 5 é–“ï¼Œé¿å… token å¤ªå¤§
        indicators = build_feedback_index()
        status_map = build_status_index()

        items = []
        for t in toilets[:5]:
            try:
                lat_s = norm_coord(t["lat"])
                lon_s = norm_coord(t["lon"])
            except Exception:
                continue

            key = (lat_s, lon_s)
            ind = indicators.get(key, {})
            st = status_map.get(key, {})

            items.append({
                "name": t.get("name") or t.get("place_hint") or "æœªå‘½åå»æ‰€",
                "distance_m": int(t.get("distance", 0) or 0),
                "paper": ind.get("paper"),          # "æœ‰" / "æ²’æœ‰" / "?"
                "access": ind.get("access"),        # "æœ‰" / "æ²’æœ‰" / "?"
                "avg_score": ind.get("avg"),        # æ¸…æ½”åˆ†æ•¸å¹³å‡
                "status": (st.get("status") or ""), # ä¾‹å¦‚ï¼šæœ‰äººæ’éšŠã€æš«åœä½¿ç”¨ã€æ¢å¾©æ­£å¸¸
            })

        if not items:
            return ""

        payload = {
            "uid": uid,
            "nearby_toilets": items
        }

        prompt = f"""
ä½ æ˜¯ä¸€å€‹ã€Œæ™ºæ…§å»æ‰€åŠ©æ‰‹ã€çš„æ¨è–¦å°å¹«æ‰‹ï¼Œä½¿ç”¨è€…å‰›å‰›å‚³äº†ä»–çš„ä½ç½®ï¼Œæˆ‘å€‘å¹«ä»–æ‰¾åˆ°å¹¾é–“é™„è¿‘çš„å»æ‰€ã€‚

ä¸‹é¢æ˜¯æ•´ç†å¥½çš„é™„è¿‘å»æ‰€è³‡æ–™ï¼ˆJSONï¼‰ï¼š
{json.dumps(payload, ensure_ascii=False)}

è«‹ä½ æ ¹æ“šï¼š
- è·é›¢ï¼ˆdistance_mï¼Œè¶Šå°è¶Šè¿‘ï¼‰
- æ¸…æ½”åˆ†æ•¸ avg_scoreï¼ˆæ•¸å­—è¶Šé«˜ä»£è¡¨è¶Šä¹¾æ·¨ï¼Œå¦‚æœæ˜¯ null ä»£è¡¨ç›®å‰æ²’æœ‰è©•åˆ†ï¼‰
- è¡›ç”Ÿç´™ç‹€æ…‹ paperï¼ˆ"æœ‰"/"æ²’æœ‰"/"?"ï¼‰
- ç„¡éšœç¤™è¨­æ–½ accessï¼ˆ"æœ‰"/"æ²’æœ‰"/"?"ï¼‰
- å³æ™‚ç‹€æ…‹ statusï¼ˆä¾‹å¦‚ï¼šæœ‰äººæ’éšŠã€æš«åœä½¿ç”¨ã€æ¢å¾©æ­£å¸¸ï¼‰

å¹«ä½¿ç”¨è€…åšä¸€æ®µç°¡çŸ­çš„ã€Œæ¨è–¦èªªæ˜ã€ï¼Œè¦æ±‚ï¼š
{lang_rule}
- Keep the total length within 3â€“5 lines.
- First line: a quick overall summary.
- Then recommend 1â€“2 toilets (up to 3 max) with brief reasons.
- Final line: a short tip.

Please output user-facing text only. Do NOT include JSON or technical descriptions.
        """.strip()

        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": f"You are a friendly assistant that recommends nearby toilets. {lang_rule}"
                },
                {"role": "user", "content": prompt}
            ],
        )

        text = (resp.choices[0].message.content or "").strip()
        return text

    except Exception as e:
        logging.error(f"AI nearby recommendation error: {e}", exc_info=True)
        return ""

# --- ä¾ä½¿ç”¨è€…çµ±è¨ˆè¨ˆç®—è§£é– ---
def _badge_rules(uid: str):
    s = _stats_for_user(uid)
    by = s.get("by_status", {}) or {}
    total = int(s.get("total", 0) or 0)

    def c(k):
        return int(by.get(k, 0) or 0)

    return {
        "first": total >= 1,
        "helper10": total >= 10,
        "pro_reporter": total >= 20,
        "helper50": total >= 50,
        "tissue_guard": c("ç¼ºè¡›ç”Ÿç´™") >= 3,
        "tissue_master": c("ç¼ºè¡›ç”Ÿç´™") >= 10,
        "queue_scout": c("æœ‰äººæ’éšŠ") >= 3,
        "queue_commander": c("æœ‰äººæ’éšŠ") >= 10,
        "maintenance_watcher": c("æš«åœä½¿ç”¨") >= 3,
        "good_news": c("æ¢å¾©æ­£å¸¸") >= 5,
    }

# --- åœ–åƒ/åç¨±è¨­å®šï¼ˆæŠŠ icon æª”æ”¾é€² /static/badges/ï¼Œæª”åå¯ä¾ä½ å¯¦éš›ç´ æèª¿æ•´ï¼‰---
BADGE_CONFIG = [
    {"key":"first",               "name":"æ–°æ‰‹å ±åˆ°",     "icon":"/static/badges/first.png"},
    {"key":"helper10",            "name":"å‹¤å‹å°å¹«æ‰‹",   "icon":"/static/badges/helper10.png"},
    {"key":"pro_reporter",        "name":"è³‡æ·±å›å ±å“¡",   "icon":"/static/badges/pro_reporter.png"},
    {"key":"helper50",            "name":"è¶…ç´šå¹«æ‰‹",     "icon":"/static/badges/helper50.png"},
    {"key":"tissue_guard",        "name":"ç´™å·¾å®ˆè­·è€…",   "icon":"/static/badges/tissue_guard.png"},
    {"key":"tissue_master",       "name":"ç´™å·¾ç¸½ç®¡",     "icon":"/static/badges/tissue_master.png"},
    {"key":"queue_scout",         "name":"æ’éšŠåµæŸ¥å“¡",   "icon":"/static/badges/queue_scout.png"},
    {"key":"queue_commander",     "name":"æ’éšŠæŒ‡æ®å®˜",   "icon":"/static/badges/queue_commander.png"},
    {"key":"maintenance_watcher", "name":"ç¶­é‹å®ˆè­·è€…",   "icon":"/static/badges/maintenance_watcher.png"},
    {"key":"good_news",           "name":"å¥½æ¶ˆæ¯åˆ†äº«å“¡", "icon":"/static/badges/good_news.png"},
]

# --- å–ä»£åŸæœ¬çš„ /api/badges è·¯ç”± ---
@app.route("/api/badges")
def api_badges():
    uid = request.args.get("user_id", "").strip()
    unlocked_map = _badge_rules(uid)
    items = []
    for b in BADGE_CONFIG:
        items.append({
            "key": b["key"],
            "name": b["name"],
            "icon": b["icon"],
            "unlocked": bool(unlocked_map.get(b["key"], False)),
        })
    return {"ok": True, "badges": items}, 200

# === èˆŠè·¯ç”±ä¿ç•™===
@app.route("/toilet_feedback/<toilet_name>")
def toilet_feedback(toilet_name):
    _ensure_sheets_ready()

    liff_id = _get_liff_status_id()
    uid = (request.args.get("uid") or "").strip()
    lang = (request.args.get("lang") or "").strip().lower()
    if uid and not lang:
        try:
            lang = _user_lang_q(uid)
        except Exception:
            lang = "zh"
        qs = request.args.to_dict(flat=True)
        qs["lang"] = lang
        return redirect(request.path + "?" + urllib.parse.urlencode(qs), code=302)
    if worksheet is None or feedback_sheet is None:
        return render_template("toilet_feedback.html", toilet_name=toilet_name,
                               summary="ï¼ˆæš«æ™‚ç„¡æ³•é€£åˆ°é›²ç«¯è³‡æ–™ï¼‰",
                               feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="", liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh"))
    try:
        address = "æœªçŸ¥åœ°å€"
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) > 1 and row[1] == toilet_name:
                address = (row[2] if len(row) > 2 else "") or "æœªçŸ¥åœ°å€"
                break

        if address == "æœªçŸ¥åœ°å€":
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="è«‹æ”¹ç”¨åº§æ¨™ç‰ˆå…¥å£ï¼ˆå¡ç‰‡ä¸Šçš„ã€æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰ã€ï¼‰ã€‚",
                                   feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="", liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh"))

        rows_fb = feedback_sheet.get_all_values()
        header = rows_fb[0]; data_fb = rows_fb[1:]
        idx = _feedback_indices(header)
        if idx["address"] is None:
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="ï¼ˆè¡¨é ­ç¼ºå°‘ã€åœ°å€ã€æ¬„ä½ï¼‰", feedbacks=[], address=address,
                                   avg_pred_score="æœªé æ¸¬", lat="", lon="", liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh"))

        matched = [r for r in data_fb
                   if len(r) > idx["address"] and (r[idx["address"]] or "").strip() == address.strip()]

        fbs = []
        nums = []
        for r in matched:
            def val(k):
                i = idx[k]
                return (r[i] if i is not None and len(r) > i else "").strip()
            sc, rr, pp, aa = _pred_from_row(r, idx)
            try: nums.append(float(sc))
            except: pass
            fbs.append({
                "rating": val("rating"),
                "toilet_paper": val("paper"),
                "accessibility": val("access"),
                "time_of_use": val("time"),
                "comment": safe_html(val("comment")),
                "cleanliness_score": str(sc) if sc is not None else "",
                "created_at": val("created"),
            })
        fbs.sort(key=lambda d: d.get("created_at",""), reverse=True)
        avg_pred_score = round(sum(nums)/len(nums), 2) if nums else "æœªé æ¸¬"

        if matched:
            paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            for r in matched:
                _, _, pp, aa = _pred_from_row(r, idx)
                if pp in paper_counts: paper_counts[pp] += 1
                if aa in access_counts: access_counts[aa] += 1
            avg = avg_pred_score
            summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\nğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg}\nğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰']>=paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\nâ™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰']>=access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        else:
            summary = "å°šç„¡å›é¥‹è³‡æ–™"

        return render_template("toilet_feedback.html",
                               toilet_name=toilet_name, summary=summary,
                               feedbacks=fbs, address=address,
                               avg_pred_score=avg_pred_score, lat="", lon="", liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh"))
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ–°è·¯ç”± ===
@app.route("/toilet_feedback_by_coord/<lat>/<lon>")
def toilet_feedback_by_coord(lat, lon):
    _ensure_sheets_ready()

    liff_id = _get_liff_status_id()

    # âœ… èªè¨€ï¼šå„ªå…ˆç”¨ querystring ?lang=ï¼Œæ²’æœ‰å°±ç”¨è³‡æ–™åº«è¨˜éŒ„ï¼ˆéœ€å¸¶ uidï¼‰
    uid = (request.args.get("uid") or "").strip()
    lang = (request.args.get("lang") or "").strip().lower()
    if uid and not lang:
        try:
            lang = _user_lang_q(uid)
        except Exception:
            lang = "zh"
        qs = request.args.to_dict(flat=True)
        qs["lang"] = lang
        return redirect(request.path + "?" + urllib.parse.urlencode(qs), code=302)
    if feedback_sheet is None:
        return render_template("toilet_feedback.html",
                               toilet_name=f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰",
                               summary="ï¼ˆæš«æ™‚ç„¡æ³•é€£åˆ°é›²ç«¯è³‡æ–™ï¼‰",
                               feedbacks=[], address=f"{lat},{lon}",
                               avg_pred_score="æœªé æ¸¬", lat=lat, lon=lon,
                               liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh"))
    try:
        name = f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰"
        summary = get_feedback_summary_by_coord(lat, lon)
        feedbacks = get_feedbacks_by_coord(lat, lon)

        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header:
            header = []
        if not data:
            data = []

        idx = _feedback_indices(header)

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        scores = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                sc, _, _, _ = _pred_from_row(r, idx)
                if isinstance(sc, (int, float)):
                    scores.append(float(sc))
        avg_pred_score = round(sum(scores)/len(scores), 2) if scores else "æœªé æ¸¬"

        return render_template(
            "toilet_feedback.html",
            toilet_name=name,
            summary=summary,
            feedbacks=feedbacks,
            address=f"{lat},{lon}",
            avg_pred_score=avg_pred_score,
            lat=lat,
            lon=lon,
            liff_id=liff_id, uid=uid, lang=(lang if lang in ["en","zh"] else "zh")
        )
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ¸…æ½”åº¦è¶¨å‹¢ï¼ˆåç¨±ç‰ˆåˆ¥åï¼‰ ===
@app.route("/get_clean_trend/<path:toilet_name>")
def get_clean_trend_by_name(toilet_name):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {"success": True, "data": []}, 200

    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return {"success": True, "data": []}, 200
        idx = _feedback_indices(header)

        name_idx = idx.get("name")
        lat_idx = idx.get("lat")
        lon_idx = idx.get("lon")
        created_idx = idx.get("created")

        if name_idx is None or lat_idx is None or lon_idx is None:
            # è¡¨é ­ç¼ºå°‘å¿…è¦æ¬„ä½
            return {"success": True, "data": []}, 200

        # æ‰¾å‡ºåŒåçš„æ‰€æœ‰ç´€éŒ„ï¼Œå–å‡ºåº§æ¨™
        matched = [r for r in data if len(r) > name_idx and (r[name_idx] or "").strip() == toilet_name.strip()]
        if not matched:
            return {"success": True, "data": []}, 200

        # ä»¥æœ€æ–°ä¸€ç­†çš„åº§æ¨™ç‚ºä¸»
        if created_idx is not None:
            matched.sort(key=lambda x: (x[created_idx] if len(x) > created_idx else ""), reverse=True)
        ref = matched[0]
        lat = ref[lat_idx] if len(ref) > lat_idx else ""
        lon = ref[lon_idx] if len(ref) > lon_idx else ""

        # è½‰å‘¼å«åº§æ¨™ç‰ˆï¼ˆé‚è¼¯ä¸€è‡´ï¼‰
        return get_clean_trend_by_coord(lat, lon)

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåç¨±ç‰ˆï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === æ¸…æ½”åº¦è¶¨å‹¢ API ===
@app.route("/get_clean_trend_by_coord/<lat>/<lon>")
def get_clean_trend_by_coord(lat, lon):
    _ensure_sheets_ready()
    if feedback_sheet is None:
        return {"success": True, "data": []}, 200 
    try:
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return {"success": True, "data": []}, 200
        
        idx = _feedback_indices(header)

        if idx["lat"] is None or idx["lon"] is None:
            return {"success": False, "data": []}, 200

        # âœ… æ”¾å¯¬æ¯”å°ç²¾åº¦åˆ° 1e-4
        def close(a, b, tol=1e-4):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched_rows = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched_rows.append(r)

        if not matched_rows:
            return {"success": True, "data": []}, 200

        recomputed = []
        for r in matched_rows:
            created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if sc is None:
                sc = _simple_score(rr, pp, aa)
            if isinstance(sc, (int, float)):
                # âœ… é †ä¾¿æŠŠæ™‚é–“ä¹Ÿå›å‡ºå»ï¼Œå‰ç«¯ç•«åœ–æ›´ç©©
                recomputed.append({"t": created, "score": round(float(sc), 2)})

        if not recomputed:
            return {"success": True, "data": []}, 200

        # å¦‚æœå…¨éƒ¨åˆ†æ•¸å®Œå…¨ä¸€æ¨£ï¼Œå†å˜—è©¦ç”¨ç°¡åŒ–ç‰ˆåˆ†æ•¸
        vals = [p["score"] for p in recomputed]
        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            forced = []
            for r in matched_rows:
                created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
                _, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    forced.append({"t": created, "score": round(float(sc2), 2)})
            if forced:
                recomputed = forced

        # âœ… ç¢ºä¿æ™‚é–“æ’åº
        recomputed.sort(key=lambda d: d["t"])
        return {"success": True, "data": recomputed}, 200

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === AI å›é¥‹æ‘˜è¦é é¢ ===
@app.route("/ai_feedback_summary_page/<lat>/<lon>")
def ai_feedback_summary_page(lat, lon):
    """
    é¡¯ç¤ºæŸä¸€å€‹å»æ‰€ï¼ˆç”¨åº§æ¨™è¡¨ç¤ºï¼‰çš„ AI å›é¥‹æ‘˜è¦é é¢ã€‚
    å‰ç«¯æœƒåœ¨é€™å€‹é é¢è£¡ç”¨ JS å‘¼å« /api/ai_feedback_summary/<lat>/<lon>ã€‚
    """
    uid = (request.args.get("uid") or "").strip()

    base = PUBLIC_URL.rstrip("/") if PUBLIC_URL else request.url_root.rstrip("/")
    # çµ¦å‰ç«¯ JS ç”¨çš„ API URLï¼ˆé †ä¾¿æŠŠ uid å¸¶é€²å»ï¼Œç”¨ä¾†åšæ¯æ—¥é¡åº¦æ§åˆ¶ï¼‰
    api_url = f"{base}/api/ai_feedback_summary/{lat}/{lon}"
    if uid:
        api_url += f"?uid={quote(uid)}"

    # é †ä¾¿åšä¸€å€‹ã€Œå»ç•™ä¸‹å›é¥‹ã€çš„é€£çµï¼ˆå°±ç®—æ²’å›é¥‹ä¹Ÿå¯ä»¥ç”¨ï¼‰
    feedback_url = (
        f"{base}/feedback_form/"
        f"{quote('é€™é–“å»æ‰€')}/{quote(lat + ',' + lon)}"
        f"?lat={lat}&lon={lon}&address={quote(lat + ',' + lon)}"
    )

    return render_template(
        "ai_feedback_summary.html",
        lat=lat,
        lon=lon,
        api_url=api_url,
        feedback_url=feedback_url,
        uid=uid,
    )

@app.route("/ai_usage_summary_page/<uid>")
def ai_usage_summary_page(uid):
    text = build_ai_usage_summary(uid)
    return render_template(
        "ai_usage_summary.html",
        uid=uid,
        summary=text
    )

# === AI å›é¥‹æ‘˜è¦ APIï¼ˆæ”¾åœ¨æ¸…æ½”åº¦è¶¨å‹¢ API çš„ä¸‹é¢ï¼‰ ===
AI_MODEL = os.getenv("AI_MODEL", "gpt-4o-mini")
AI_KEY   = os.getenv("OPENAI_API_KEY", "")
client   = OpenAI(api_key=AI_KEY) if AI_KEY else None

# --- AI æ¯æ—¥é¡åº¦æ§åˆ¶ï¼ˆæ–¹æ¡ˆ Dï¼šåŒä¸€ä½¿ç”¨è€…æ¯å¤©æœ€å¤šè§¸ç™¼å¹¾æ¬¡ AIï¼‰ ---
AI_DAILY_LIMIT = int(os.getenv("AI_DAILY_LIMIT", "3"))  # é è¨­ 3 æ¬¡/äºº/å¤©

_ai_quota_lock = threading.Lock()
_ai_quota = {}  # key: (usage_key, date_str) -> count


def _ai_quota_check_and_inc(key: str):
    TW_TZ = timezone(timedelta(hours=8))

    today = datetime.now(TW_TZ).strftime("%Y-%m-%d")

    conn = _get_db()
    cur = conn.cursor()

    cur.execute("SELECT count FROM ai_quota WHERE key=? AND date=?", (key, today))
    row = cur.fetchone()
    cnt = row[0] if row else 0

    if cnt >= AI_DAILY_LIMIT:
        conn.close()
        return False, cnt

    if row:
        cur.execute("UPDATE ai_quota SET count=? WHERE key=? AND date=?", (cnt+1, key, today))
    else:
        cur.execute("INSERT INTO ai_quota (key, date, count) VALUES (?, ?, ?)", (key, today, 1))

    conn.commit()
    conn.close()

    return True, cnt+1

from flask import jsonify
import json

@app.route("/api/ai_feedback_summary/<lat>/<lon>")
def api_ai_feedback_summary(lat, lon):
    """
    ä¾ç…§åº§æ¨™è®€å– feedback_sheet çš„å›é¥‹ç´€éŒ„ï¼Œ
    ä¸Ÿçµ¦ OpenAI åšæ‘˜è¦ï¼Œä¾ä½¿ç”¨è€…èªè¨€å›å‚³ä¸­ / è‹±æ–‡ JSONã€‚
    """
    uid = (request.args.get("uid") or "").strip()  # âœ… å…ˆæ”¾æœ€å‰é¢ï¼Œé¿å… except ç”¨ä¸åˆ° uid

    try:
        _ensure_sheets_ready()
        if feedback_sheet is None:
            return jsonify({
                "success": False,
                "message": L(uid, "å›é¥‹è¡¨å°šæœªå°±ç·’ï¼Œè«‹ç¨å¾Œå†è©¦", "Feedback sheet not ready, please try again later")
            }), 503

        if client is None:
            return jsonify({
                "success": False,
                "message": L(uid, "AI é‡‘é‘°å°šæœªè¨­å®š", "AI key not configured")
            }), 500

        # === èªè¨€åˆ¤æ–· ===
        try:
            lang = get_user_lang(uid)
        except Exception:
            lang = "zh"

        # âœ… è®“ system ä¹Ÿè·Ÿèªè¨€ä¸€è‡´ï¼ˆé¿å…æ··èªï¼‰
        lang_rule = "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚" if lang != "en" else "Please answer in English."
        system_msg = (
            f"You analyze restroom feedback and summarize it clearly. {lang_rule}"
            if lang == "en"
            else f"ä½ è² è²¬åˆ†æå»æ‰€å›é¥‹ä¸¦æ¸…æ¥šæ‘˜è¦é‡é»ã€‚{lang_rule}"
        )

        # é©—è­‰ lat / lon
        try:
            lat_f = float(lat)
            lon_f = float(lon)
        except Exception:
            return jsonify({
                "success": False,
                "message": L(uid, "lat/lon æ ¼å¼éŒ¯èª¤", "Invalid latitude / longitude")
            }), 400

        # 1ï¸âƒ£ å¾é›²ç«¯å›é¥‹è¡¨æŠ“è³‡æ–™
        header, data = _get_header_and_tail(feedback_sheet, MAX_SHEET_ROWS)
        if not header or not data:
            return jsonify({
                "success": True,
                "summary": L(
                    uid,
                    "ç›®å‰é‚„æ²’æœ‰ä»»ä½•å›é¥‹è³‡æ–™ï¼Œå¯ä»¥é»ä¸‹é¢çš„æŒ‰éˆ•ä¾†å¹«å¿™ç•™ä¸€ç­†å›é¥‹ ğŸ™",
                    "No feedback yet. You can leave a review using the button below ğŸ™"
                ),
                "data": [],
                "has_data": False
            }), 200

        idx = _feedback_indices(header)
        if idx["lat"] is None or idx["lon"] is None:
            return jsonify({
                "success": False,
                "message": L(uid, "ç¼ºå°‘ lat/lon æ¬„ä½", "lat/lon column missing")
            }), 400

        def close(a, b, tol=1e-4):
            try:
                return abs(float(a) - float(b)) <= tol
            except Exception:
                return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if not (close(r[idx["lat"]], lat_f) and close(r[idx["lon"]], lon_f)):
                continue

            def v(key):
                i = idx.get(key)
                return (r[i] if i is not None and i < len(r) else "").strip()

            matched.append({
                "rating":     v("rating"),
                "paper":      v("paper"),
                "access":     v("access"),
                "comment":    v("comment"),
                "created_at": v("created"),
            })

        if not matched:
            return jsonify({
                "success": True,
                "summary": L(
                    uid,
                    "ç›®å‰é‚„æ²’æœ‰ä»»ä½•å›é¥‹è³‡æ–™ï¼Œå¯ä»¥é»ä¸‹é¢çš„æŒ‰éˆ•ä¾†å¹«å¿™ç•™ä¸€ç­†å›é¥‹ ğŸ™",
                    "No feedback yet. You can leave a review using the button below ğŸ™"
                ),
                "data": [],
                "has_data": False
            }), 200

        # æœ€å¤šé€ 30 ç­†çµ¦ AI
        matched = matched[:30]

        # 2ï¸âƒ£ æ¯æ—¥ AI é¡åº¦æ§åˆ¶ï¼ˆuid â†’ fallback IPï¼‰
        xff = (request.headers.get("X-Forwarded-For") or "").split(",")[0].strip()
        ip = xff or (request.remote_addr or "unknown")
        quota_key = uid or f"ip:{ip}"

        ok, used = _ai_quota_check_and_inc(f"fb:{quota_key}")
        if not ok:
            return jsonify({
                "success": True,
                "summary": T("ai_summary_limit", uid=uid),
                "data": matched,
                "has_data": True,
                "limit_reached": True
            }), 200

        # 3ï¸âƒ£ çµ„ AI Promptï¼ˆä¾èªè¨€ï¼‰
        matched_json = json.dumps(matched, ensure_ascii=False)

        if lang == "en":
            prompt = f"""
You are a restroom cleanliness analysis assistant.

Please read the following feedback data (JSON format) and provide:
1. Common recent issues (e.g. lack of toilet paper, slippery floor, odor, broken facilities)
2. Overall user sentiment (positive / neutral / negative) with a brief explanation
3. Cleanliness trend (getting cleaner / getting worse / mostly stable). If data is insufficient, explain why.
4. A concise recommendation in **no more than 3 lines**

Please respond in **English**, using bullet points or short sentences.

Feedback data (JSON):
{matched_json}
            """.strip()
        else:
            prompt = f"""
ä½ æ˜¯ä¸€å€‹å»æ‰€æ¸…æ½”åº¦åˆ†æåŠ©ç†ï¼Œè«‹é–±è®€ä»¥ä¸‹å›é¥‹è³‡æ–™ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œä¸¦è¼¸å‡ºï¼š

1. æœ€è¿‘å¸¸è¦‹çš„ä¸»è¦å•é¡Œï¼ˆä¾‹å¦‚ï¼šè¡›ç”Ÿç´™ä¸è¶³ã€åœ°æ¿æ¿•æ»‘ã€ç•°å‘³ã€è¨­å‚™è€èˆŠç­‰ï¼‰
2. ä½¿ç”¨è€…æ•´é«”æƒ…ç·’å‚¾å‘ï¼ˆæ­£é¢ / ä¸­æ€§ / è² é¢ï¼‰ï¼Œç°¡çŸ­èªªæ˜åŸå› 
3. æ¸…æ½”åº¦ç‹€æ…‹çš„è¶¨å‹¢ï¼ˆè®Šä¹¾æ·¨ / è®Šé«’ / å¤§è‡´æŒå¹³ï¼‰ï¼Œå¦‚æœè³‡æ–™ä¸è¶³è«‹èªªæ˜
4. æœ€å¾Œè«‹ç”¨ä¸‰è¡Œä»¥å…§ï¼Œçµ¦å‡ºä¸€æ®µç¸½çµå»ºè­°

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€æ¢åˆ—å¼æˆ–çŸ­å¥ï¼Œè®“ä¸€èˆ¬ä½¿ç”¨è€…å®¹æ˜“é–±è®€ã€‚

ä»¥ä¸‹æ˜¯å›é¥‹è³‡æ–™ï¼ˆJSONï¼‰ï¼š
{matched_json}
            """.strip()

        ai_resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt}
            ]
        )

        summary = (ai_resp.choices[0].message.content or "").strip()

        return jsonify({
            "success": True,
            "summary": summary,
            "data": matched,
            "has_data": True
        }), 200

    except Exception as e:
        logging.error(f"AI summary error: {e}", exc_info=True)
        return jsonify({
            "success": False,
            "message": L(uid, "AI ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦", "AI error, please try again later")
        }), 500

# === åŒæ„é é¢ / éš±ç§é  ===
@app.route("/consent", methods=["GET"])
def render_consent_page():
    return render_template("consent.html")

@app.route("/privacy", methods=["GET"])
def render_privacy_page():
    return render_template("privacy_policy.html")

# ç‹€æ…‹ LIFF é é¢
@app.route("/status_liff")
def status_liff():
    liff_id = _get_liff_status_id()
    public_url = os.getenv("PUBLIC_URL", "").rstrip("/")

    # âœ… èªè¨€ï¼šLIFF æ²’è¾¦æ³•è‡ªå‹•çŸ¥é“ä½ åœ¨èŠå¤©è£¡åˆ‡çš„èªè¨€ï¼Œæ‰€ä»¥ç”¨ querystring å¸¶ uid/lang
    uid = (request.args.get("uid") or "").strip()
    lang = (request.args.get("lang") or "").strip().lower()

    # å¦‚æœæœ‰ uid ä½†æ²’å¸¶ langï¼Œå°±ä¾è³‡æ–™åº«è¨˜éŒ„è‡ªå‹•è£œä¸Š langï¼Œé¿å…å‰ç«¯é‚„è¦è‡ªå·±ç®—
    if uid and not lang:
        try:
            lang = "en" if get_user_lang(uid) == "en" else "zh"
        except Exception:
            lang = "zh"
        # ä¿ç•™åŸæœ¬çš„å…¶ä»– querystringï¼ˆå¦‚ lat/lonï¼‰
        qs = request.args.to_dict(flat=True)
        qs["lang"] = lang
        return redirect(request.path + "?" + urllib.parse.urlencode(qs), code=302)

    if not liff_id:
        logging.error("LIFF_STATUS_ID / LIFF_ID_STATUS / LIFF_ID not set")
        return "LIFF ID not set", 500

    if not public_url:
        logging.error("PUBLIC_URL not set")
        return "PUBLIC_URL not set", 500

    return render_template(
        "status_liff.html",
        liff_id=liff_id,
        public_url=public_url,
        uid=uid,
        lang=(lang if lang in ["en","zh"] else "zh")
    )

# === LIFF åŒæ„ APIï¼ˆæ–°å¢ï¼šå¾®ç¯€æµï¼‹å¤±æ•—å…¥èƒŒæ™¯ä½‡åˆ—ï¼Œå› 200ï¼‰ ===
_last_consent_ts = {}
CONSENT_MIN_INTERVAL = float(os.getenv("CONSENT_MIN_INTERVAL", "1.0"))

@app.route("/api/consent", methods=["POST"])
def api_consent():
    try:
        payload = request.get_json(force=True, silent=False) or {}
        agreed = bool(payload.get("agree"))
        user_id = (payload.get("userId") or "").strip()
        display_name = payload.get("displayName") or ""
        source_type = payload.get("sourceType") or ""
        ua = payload.get("ua") or request.headers.get("User-Agent","")
        ts = payload.get("ts") or datetime.utcnow().isoformat()

        if not user_id:
            logging.warning(f"/api/consent missing userId. payload={payload}")
            return {"ok": False, "message": "ç¼ºå°‘ userId"}, 400

        now = time.time()
        last = _last_consent_ts.get(user_id, 0.0)
        if now - last < CONSENT_MIN_INTERVAL:
            return {"ok": True, "message": "accepted"}, 200
        _last_consent_ts[user_id] = now

        ok = upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
        if not ok:
            def job():
                try:
                    upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
                except Exception:
                    pass
            with _consent_lock:
                if len(_consent_q) < 1000:
                    _consent_q.append(job)
            return {"ok": True, "message": "queued"}, 200

        return {"ok": True}, 200
    except Exception as e:
        logging.error(f"/api/consent å¤±æ•—: {e}")
        return {"ok": False}, 500

@app.route("/_debug_predict")
def _debug_predict():
    try:
        r = int(request.args.get("rating"))
        paper = request.args.get("paper", "æ²’æ³¨æ„")
        acc = request.args.get("access", "æ²’æ³¨æ„")

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        feat = [r, paper_map.get(paper, 0), access_map.get(acc, 0)]
        exp = expected_from_feats([feat])

        return {
            "ok": True,
            "input": {"rating": r, "paper": paper, "access": acc},
            "expected": exp
        }, 200
    except Exception as e:
        logging.error(e)
        return {"ok": False}, 500

def _short_txt(s, n=60):
    try:
        s = (s or "").strip()
        return s if len(s) <= n else (s[:n-1] + "â€¦")
    except Exception:
        return s

# === å»ºç«‹ Flex ===
def create_toilet_flex_messages(toilets, uid=None):
    indicators = build_feedback_index()
    status_map = build_status_index()

    # === è³‡æ–™ä¾†æºé¡¯ç¤ºå°ç…§ï¼ˆä¸­/è‹±ï¼‰===
    SOURCE_LABEL = {
        "public_csv": ("æ”¿åºœé–‹æ”¾è³‡æ–™", "Government Open Data"),
        "sheet": ("ä½¿ç”¨è€…æ–°å¢", "User Added"),
        "osm": ("OpenStreetMap", "OpenStreetMap"),
        "user": ("ä½¿ç”¨è€…æ–°å¢", "User Added"),
        "favorite": ("æˆ‘çš„æœ€æ„›", "My Favorites"),
    }

    # === ç‹€æ…‹ï¼ˆä¸­/è‹±ï¼‰===
    STATUS_EN = {
        "æ¢å¾©æ­£å¸¸": "Back to normal",
        "æœ‰äººæ’éšŠ": "Queue present",
        "ç¼ºè¡›ç”Ÿç´™": "No toilet paper",
        "æš«åœä½¿ç”¨": "Out of service",
    }

    bubbles = []
    for toilet in toilets[:5]:
        actions = []

        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        addr_text = toilet.get('address') or L(uid, "ï¼ˆç„¡åœ°å€ï¼Œä½¿ç”¨åº§æ¨™ï¼‰", "(No address, using coordinates)")

        # -------------------------
        # âœ… titleï¼ˆä¿®æ­£ï¼šä¸è¦å…ˆæ‹¼ä¸­æ–‡å† Lï¼‰
        # -------------------------
        title = (toilet.get('name') or "").strip()
        if (not title) or title == "ç„¡åç¨±":
            ph = (toilet.get("place_hint") or "").strip()

            zh_title = f"{ph}ï¼ˆé™„è¿‘ï¼‰å»æ‰€" if ph else "ï¼ˆæœªå‘½åï¼‰å»æ‰€"
            en_title = f"Toilet near {ph}" if ph else "(Unnamed) Toilet"
            title = L(uid, zh_title, en_title)

        # === ä¾†æºæ–‡å­—ï¼ˆå°å°é¡¯ç¤ºï¼‰===
        source_type = toilet.get("type", "")
        src_zh_en = SOURCE_LABEL.get(source_type, ("å…¶ä»–ä¾†æº", "Other source"))
        source_text = L(uid, src_zh_en[0], src_zh_en[1])

        # åªè®€ä¸‰å€‹æ¬„ä½ï¼ˆå¯èƒ½ç‚ºç©ºï¼‰
        lvl   = (toilet.get("level") or "").strip()
        pos   = (toilet.get("floor_hint") or "").strip()
        hours = (toilet.get("open_hours") or "").strip()

        # é¡å¤–é¡¯ç¤ºè¡Œ
        extra_lines = []
        st_obj = status_map.get((lat_s, lon_s))
        if st_obj and st_obj.get("status"):
            st = st_obj["status"]
            emoji = "ğŸŸ¡" if st == "æœ‰äººæ’éšŠ" else ("ğŸ§»" if st == "ç¼ºè¡›ç”Ÿç´™" else ("â›”" if st == "æš«åœä½¿ç”¨" else "âœ…"))
            st_en = STATUS_EN.get(st, st)

            extra_lines.append({
                "type": "text",
                "text": _short_txt(L(uid, f"{emoji} ç‹€æ…‹ï¼š{st}", f"{emoji} Status: {st_en}")),
                "size": "sm", "color": "#666666", "wrap": True
            })

        if lvl or pos:
            if lvl and pos and (lvl.strip().lower() != pos.strip().lower()):
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(L(uid, f"ğŸ· æ¨“å±¤ï¼š{lvl}", f"ğŸ· Floor: {lvl}")),
                    "size": "sm", "color": "#666666", "wrap": True
                })
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(L(uid, f"ğŸ§­ ä½ç½®ï¼š{pos}", f"ğŸ§­ Location: {pos}")),
                    "size": "sm", "color": "#666666", "wrap": True
                })
            else:
                val = pos or lvl
                extra_lines.append({
                    "type": "text",
                    "text": _short_txt(L(uid, f"ğŸ§­ ä½ç½®/æ¨“å±¤ï¼š{val}", f"ğŸ§­ Location/Floor: {val}")),
                    "size": "sm", "color": "#666666", "wrap": True
                })

        if hours:
            extra_lines.append({
                "type": "text",
                "text": _short_txt(L(uid, f"ğŸ•’ é–‹æ”¾ï¼š{hours}", f"ğŸ•’ Hours: {hours}")),
                "size": "sm", "color": "#666666", "wrap": True
            })

        # æŒ‡ç¤ºç‡ˆæ–‡å­—ï¼ˆpaper/access/avgï¼‰
        ind = indicators.get((lat_s, lon_s), {"paper": "?", "access": "?", "avg": None})

        # â­ è©•åˆ†é¡¯ç¤ºä¸åˆ†èªè¨€
        star_text = f"â­{ind['avg']}" if ind.get("avg") is not None else "â­â€”"

        # ğŸ§» paper é¡¯ç¤º
        if ind.get("paper") == "æœ‰":
            paper_text = L(uid, "ğŸ§»æœ‰", "ğŸ§»Yes")
        elif ind.get("paper") == "æ²’æœ‰":
            paper_text = L(uid, "ğŸ§»ç„¡", "ğŸ§»No")
        else:
            paper_text = "ğŸ§»â€”"

        # â™¿ access é¡¯ç¤º
        if ind.get("access") == "æœ‰":
            access_text = L(uid, "â™¿æœ‰", "â™¿Yes")
        elif ind.get("access") == "æ²’æœ‰":
            access_text = L(uid, "â™¿ç„¡", "â™¿No")
        else:
            access_text = "â™¿â€”"

        # æŒ‰éˆ•
        base = _base_url()

        actions.append({
            "type": "uri",
            "label": L(uid, "å°èˆª", "Navigate"),
            "uri": f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"
        })

        actions.append({
            "type": "uri",
            "label": L(uid, "æŸ¥è©¢å›é¥‹", "View feedback"),
            "uri": _append_uid_lang(f"{base}/toilet_feedback_by_coord/{lat_s}/{lon_s}", uid, _user_lang_q(uid))
        })

        addr_raw = toilet.get('address') or ""
        addr_param = quote(addr_raw or "-")
        actions.append({
            "type": "uri",
            "label": L(uid, "å»æ‰€å›é¥‹", "Leave feedback"),
            "uri": (
                f"{base}/feedback_form/"
                f"{quote(title)}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
            )
        })

        ai_uri = f"{base}/ai_feedback_summary_page/{lat_s}/{lon_s}" + (f"?uid={quote(uid)}" if uid else "")
        actions.append({
            "type": "uri",
            "label": L(uid, "AI å›é¥‹æ‘˜è¦", "AI summary"),
            "uri": ai_uri
        })

        if toilet.get("type") == "favorite" and uid:
            actions.append({
                "type": "postback",
                "label": L(uid, "ç§»é™¤æœ€æ„›", "Remove favorite"),
                "data": f"remove_fav:{quote(title)}:{lat_s}:{lon_s}"
            })
        elif toilet.get("type") not in ["user", "favorite"] and uid:
            actions.append({
                "type": "postback",
                "label": L(uid, "åŠ å…¥æœ€æ„›", "Add favorite"),
                "data": f"add:{quote(title)}:{lat_s}:{lon_s}"
            })

        # === ä¸»é«”å…§å®¹ï¼ˆåŠ ä¸Šè³‡æ–™ä¾†æºï¼‰===
        dist = int(toilet.get('distance', 0) or 0)
        dist_text = L(uid, f"{dist} å…¬å°º", f"{dist} m")

        body_contents = [
            {"type": "text", "text": title, "weight": "bold", "size": "lg", "wrap": True},
            {"type": "text", "text": f"{paper_text}  {access_text}  {star_text}", "size": "sm", "color": "#555555", "wrap": True},
            {"type": "text", "text": addr_text, "size": "sm", "color": "#666666", "wrap": True},
        ] + extra_lines + [
            {"type": "text", "text": dist_text, "size": "sm", "color": "#999999"},
            {
                "type": "text",
                "text": L(uid, f"è³‡æ–™ä¾†æºï¼š{source_text}", f"Source: {source_text}"),
                "size": "xs",
                "color": "#AAAAAA",
                "wrap": True
            }
        ]

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": body_contents
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {"type": "button", "style": "primary", "height": "sm", "action": actions[0]}
                ] + [
                    {"type": "button", "style": "secondary", "height": "sm", "action": a}
                    for a in actions[1:]
                ]
            }
        }

        bubbles.append(bubble)

    return {"type": "carousel", "contents": bubbles}

# === åˆ—å‡º æˆ‘çš„è²¢ç» & åˆªé™¤ ===
def get_user_contributions(uid):
    _ensure_sheets_ready()
    if worksheet is None:
        return []
    items = []
    try:
        rows = worksheet.get_all_values()
        if not rows or len(rows) < 2:
            return items
        header = rows[0]; data = rows[1:]
        idx = _toilet_sheet_indices(header)
        for i, r in enumerate(data, start=2):
            if idx["user_id"] is None: break
            if len(r) <= idx["user_id"]: continue
            if r[idx["user_id"]] != uid: continue
            try:
                lat = float(r[idx["lat"]]); lon = float(r[idx["lon"]])
            except:
                continue
            items.append({
                "row_index": i,
                "name": (r[idx["name"]] if idx["name"] is not None and len(r)>idx["name"] else "ç„¡åç¨±"),
                "address": (r[idx["address"]] if idx["address"] is not None and len(r)>idx["address"] else ""),
                "lat": float(norm_coord(lat)),
                "lon": float(norm_coord(lon)),
                "created": (r[idx["created"]] if idx["created"] is not None and len(r)>idx["created"] else ""),
            })
        return items
    except Exception as e:
        logging.error(f"è®€å–æˆ‘çš„è²¢ç»å¤±æ•—ï¼š{e}")
        return items

def create_my_contrib_flex(uid):
    contribs = get_user_contributions(uid)
    if not contribs:
        return None

    bubbles = []
    for it in contribs[:10]:
        lat_s = norm_coord(it["lat"])
        lon_s = norm_coord(it["lon"])
        addr_raw = it.get('address','') or ""
        addr_param = quote(addr_raw or "-")

        actions = [
            {
                "type": "uri",
                "label": L(uid, "å°èˆª", "Navigate"),
                "uri": f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"
            },
            {
                "type": "uri",
                "label": L(uid, "æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰", "View feedback (coord)"),
                "uri": _append_uid_lang(f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}", uid, _user_lang_q(uid))
            },
            {
                "type": "uri",
                "label": L(uid, "å»æ‰€å›é¥‹", "Leave feedback"),
                "uri": (
                    f"https://school-i9co.onrender.com/feedback_form/{quote(it['name'])}/{addr_param}"
                    f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
                )
            },
            {
                "type": "postback",
                "label": L(uid, "åˆªé™¤æ­¤è²¢ç»", "Delete this contribution"),
                "data": f"confirm_delete_my_toilet:{it['row_index']}"
            }
        ]

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": it["name"], "size": "lg", "weight": "bold", "wrap": True},
                    {"type": "text", "text": it.get("address") or L(uid, "ï¼ˆç„¡åœ°å€ï¼‰", "(No address)"),
                     "size": "sm", "color": "#666666", "wrap": True},
                    {"type": "text", "text": it.get("created",""), "size": "xs", "color": "#999999"}
                ]
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {"type": "button", "style": "primary", "height": "sm", "action": actions[0]}
                ] + [
                    {"type": "button", "style": "secondary", "height": "sm", "action": a}
                    for a in actions[1:]
                ]
            }
        }

        bubbles.append(bubble)

    return {"type":"carousel", "contents": bubbles}

# === Webhook ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

@app.route("/", methods=["GET"])
def home():
    return "Toilet bot is running!", 200

# === å…±ç”¨ç‹€æ…‹ ===
user_locations = {}
pending_delete_confirm = {}
user_search_count = {}
user_loc_mode = {}  # æ–°å¢ï¼šè¨˜éŒ„ä½¿ç”¨è€…ç›®å‰æŸ¥å»æ‰€æ¨¡å¼ï¼ˆ"normal" or "ai"ï¼‰

# å»ºè­°ï¼šé«˜ä½µç™¼æ™‚é¿å…ç«¶æ…‹
_dict_lock = threading.Lock()
def set_user_location(uid, latlon):
    with _dict_lock:
        user_locations[uid] = latlon

def get_user_location(uid):
    with _dict_lock:
        return user_locations.get(uid)

def set_user_loc_mode(uid, mode):
    with _dict_lock:
        user_loc_mode[uid] = mode

def get_user_loc_mode(uid):
    with _dict_lock:
        return user_loc_mode.get(uid, "normal")

# === å…±ç”¨åŸ·è¡Œç·’æ± ï¼ˆé¿å…æ¯æ¬¡è‡¨æ™‚å»ºç«‹ï¼‰ ===
_pool = ThreadPoolExecutor(max_workers=2)

def build_nearby_toilets(uid, lat, lon, radius=500):
    # === Grid cache keyï¼ˆç¬¬ä¸€æ­¥ï¼‰===
    lat_g = grid_coord(lat)
    lon_g = grid_coord(lon)
    query_key = f"nearby:{lat_g},{lon_g},{radius}"

    cached = get_cached_data(query_key)
    if cached:
        logging.debug(f"[cache hit] nearby {query_key}")
        return cached

    futures = []
    csv_res, sheet_res, osm_res = [], [], []

    try:
        futures.append(("csv",   _pool.submit(query_public_csv_toilets, lat, lon, radius)))
        futures.append(("sheet", _pool.submit(query_sheet_toilets,      lat, lon, radius)))
        futures.append(("osm",   _pool.submit(query_overpass_toilets,   lat, lon, radius)))

        for name, fut in futures:
            try:
                res = fut.result(timeout=LOC_QUERY_TIMEOUT_SEC)
                if   name == "csv":   csv_res   = res or []
                elif name == "sheet": sheet_res = res or []
                else:                 osm_res   = res or []
            except FuturesTimeoutError:
                logging.warning(f"{name} æŸ¥è©¢é€¾æ™‚")
            except Exception as e:
                logging.warning(f"{name} æŸ¥è©¢å¤±æ•—: {e}")

    finally:
        for _, fut in futures:
            if not fut.done():
                fut.cancel()

    quick = _merge_and_dedupe_lists(csv_res, sheet_res, osm_res)
    sort_toilets(quick)
    result = quick[:LOC_MAX_RESULTS]

    # === å¯«å…¥ cacheï¼ˆGrid cacheï¼‰===
    save_cache(query_key, result)

    return result

# === TextMessage ===
# === TextMessage ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    if _too_old_to_reply(event):
        logging.warning("[handle_text] event too old; skip reply.")
        return

    uid = event.source.user_id
    text_raw = event.message.text or ""

    # =========================
    # ğŸ”§ å¼·åŒ–æ–‡å­—æ­£è¦åŒ–
    # =========================
    text_norm = text_raw.strip()
    text = text_norm.lower()
    text_key = " ".join(text.split())  # å£“æ‰ \n / \t / å¤šç©ºç™½

    # =========================
    # ğŸ”¥ è‹±æ–‡ Nearby Toilets æœ€å„ªå…ˆå®¹éŒ¯ï¼ˆä¸é å®Œå…¨æ¯”å°ï¼‰
    # =========================
    if ("nearby" in text_key) and (("toilet" in text_key) or ("restroom" in text_key)):
        set_user_loc_mode(uid, "normal")
        try:
            safe_reply(
                event,
                make_location_quick_reply(
                    L(
                        uid,
                        "ğŸ“ è«‹é»ä¸‹æ–¹ã€ç™¼é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€",
                        "ğŸ“ Please share your location and I will find nearby toilets for you"
                    ),
                    mode="normal"
                )
            )
        except Exception as e:
            logging.error(f"[nearby] quick reply failed: {e}", exc_info=True)
            safe_reply(
                event,
                TextSendMessage(
                    text=L(uid, "âŒ ç³»çµ±éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦", "âŒ System error. Please try again later.")
                )
            )
        return

    # =========================
    # ğŸš« é‡è¤‡äº‹ä»¶ / åŒæ„æ¢æ¬¾ gate
    # =========================
    if is_duplicate_and_mark_event(event):
        return

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    reply_messages = []

    # =========================
    # âœ… ä¸­è‹±æ–‡æ–‡å­—æŒ‡ä»¤ â†’ cmd
    # =========================
    TEXT_TO_CMD = {
        # é™„è¿‘å»æ‰€
        "é™„è¿‘å»æ‰€": "nearby",
        "nearby toilets": "nearby",
        "nearby": "nearby",
        "toilets nearby": "nearby",

        # AI æ¨è–¦
        "aiæ¨è–¦é™„è¿‘å»æ‰€": "nearby_ai",
        "ai nearby toilets": "nearby_ai",
        "ai recommend": "nearby_ai",
        "ai recommendation": "nearby_ai",

        # åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼
        "åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼": "mode_normal",
        "switch to normal": "mode_normal",
        "normal mode": "mode_normal",

        # æˆ‘çš„æœ€æ„›
        "æˆ‘çš„æœ€æ„›": "favs",
        "my favorites": "favs",
        "favorites": "favs",

        # æˆ‘çš„è²¢ç»
        "æˆ‘çš„è²¢ç»": "contrib",
        "my contributions": "contrib",
        "contributions": "contrib",

        # æ–°å¢å»æ‰€
        "æ–°å¢å»æ‰€": "add",
        "add toilet": "add",
        "add a toilet": "add",

        # æ„è¦‹å›é¥‹
        "æ„è¦‹å›é¥‹": "feedback",
        "feedback": "feedback",

        # åˆä½œä¿¡ç®±
        "åˆä½œä¿¡ç®±": "contact",
        "contact": "contact",

        # ç‹€æ…‹å›å ±
        "ç‹€æ…‹å›å ±": "status",
        "status report": "status",
        "report status": "status",

        # æˆå°±
        "æˆå°±": "ach",
        "achievements": "ach",

        # å¾½ç« 
        "å¾½ç« ": "badges",
        "badges": "badges",

        # ä½¿ç”¨å›é¡§
        "ä½¿ç”¨å›é¡§": "review",
        "usage summary": "review",
        "review": "review",

        # ä½¿ç”¨èªªæ˜
        "ä½¿ç”¨èªªæ˜": "help",
        "help": "help",
    }

    # ä¸‰æ®µå¼ lookupï¼ˆæœ€ç©©ï¼‰
    cmd = TEXT_TO_CMD.get(text_norm)
    if cmd is None:
        cmd = TEXT_TO_CMD.get(text)
    if cmd is None:
        cmd = TEXT_TO_CMD.get(text_key)

    # =========================
    # ğŸ§¹ pending_delete_confirmï¼ˆç¶­æŒä½ åŸæœ¬é‚è¼¯ï¼‰
    # =========================
    if uid in pending_delete_confirm:
        # å‡è¨­ä½ åŸæœ¬æ˜¯åš yes/no ç¢ºèª
        confirm = text_key in ("yes", "y", "æ˜¯", "ç¢ºèª")
        if confirm:
            handle_confirm_delete(uid)
            safe_reply(event, TextSendMessage(text=L(uid, "âœ… å·²åˆªé™¤", "âœ… Deleted")))
        else:
            safe_reply(event, TextSendMessage(text=L(uid, "âŒ å·²å–æ¶ˆ", "âŒ Cancelled")))
        pending_delete_confirm.discard(uid)
        return

    # =========================
    # âœ… cmd åˆ†æ´¾ï¼ˆåŸæœ¬é‚è¼¯å…¨éƒ¨ä¿ç•™ï¼‰
    # =========================
    if cmd == "nearby":
        set_user_loc_mode(uid, "normal")
        safe_reply(
            event,
            make_location_quick_reply(
                L(uid,
                  "ğŸ“ è«‹é»ä¸‹æ–¹ã€ç™¼é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€",
                  "ğŸ“ Please share your location and I will find nearby toilets for you"),
                mode="normal"
            )
        )
        return

    elif cmd == "nearby_ai":
        set_user_loc_mode(uid, "ai")
        safe_reply(
            event,
            make_location_quick_reply(
                L(uid,
                  "ğŸ“ è«‹å‚³é€ä½ ç¾åœ¨çš„ä½ç½®ï¼Œæˆ‘æœƒç”¨ AI å¹«ä½ æŒ‘é™„è¿‘æœ€é©åˆçš„å»æ‰€",
                  "ğŸ“ Please share your location. I will use AI to pick the best nearby toilets."),
                mode="ai"
            )
        )
        return

    elif cmd == "mode_normal":
        set_user_loc_mode(uid, "normal")
        safe_reply(
            event,
            make_location_quick_reply(
                L(uid,
                  "âœ… å·²åˆ‡æ›å›ä¸€èˆ¬æ¨¡å¼ï¼Œè«‹é»ã€ç™¼é€æˆ‘çš„ä½ç½®ã€æˆ‘æœƒå¹«ä½ æ‰¾æœ€è¿‘çš„å»æ‰€",
                  "âœ… Switched to normal mode. Please share your location to find nearby toilets."),
                mode="normal"
            )
        )
        return

    elif cmd == "favs":
        favs = get_user_favorites(uid)
        if not favs:
            reply_messages.append(TextSendMessage(text=L(uid, "ä½ å°šæœªæ”¶è—ä»»ä½•å»æ‰€", "You have no favorites yet.")))
        else:
            loc = get_user_location(uid)
            if loc:
                lat, lon = loc
                for f in favs:
                    f["distance"] = haversine(lat, lon, f["lat"], f["lon"])
            msg = create_toilet_flex_messages(favs, uid=uid)
            reply_messages.append(FlexSendMessage(L(uid, "æˆ‘çš„æœ€æ„›", "My Favorites"), msg))

    elif cmd == "contrib":
        msg = create_my_contrib_flex(uid)
        if msg:
            reply_messages.append(FlexSendMessage(L(uid, "æˆ‘æ–°å¢çš„å»æ‰€", "My Contributions"), msg))
        else:
            reply_messages.append(TextSendMessage(text=L(uid, "ä½ é‚„æ²’æœ‰æ–°å¢éå»æ‰€å–”ã€‚", "You haven't added any toilets yet.")))

    elif cmd == "add":
        base = "https://school-i9co.onrender.com/add"
        loc = get_user_location(uid)
        if loc:
            la, lo = loc
            url = f"{base}?uid={quote(uid)}&lat={la}&lon={lo}#openExternalBrowser=1"
        else:
            url = f"{base}?uid={quote(uid)}#openExternalBrowser=1"
        reply_messages.append(TextSendMessage(text=L(uid, f"è«‹å‰å¾€æ­¤é æ–°å¢å»æ‰€ï¼š\n{url}", f"Please add a toilet here:\n{url}")))

    elif cmd == "feedback":
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdsibz15enmZ3hJsQ9s3BiTXV_vFXLy0llLKlpc65vAoGo_hg/viewform?usp=sf_link"
        reply_messages.append(TextSendMessage(text=L(
            uid,
            f"ğŸ’¡ è«‹é€éä¸‹åˆ—é€£çµå›å ±å•é¡Œæˆ–æä¾›æ„è¦‹ï¼š\n{form_url}",
            f"ğŸ’¡ Please send feedback via:\n{form_url}"
        )))

    elif cmd == "contact":
        email = os.getenv("FEEDBACK_EMAIL", "hello@example.com")
        ig_url = "https://www.instagram.com/toiletmvp?igsh=MWRvMnV2MTNyN2RkMw=="
        reply_messages.append(TextSendMessage(text=L(
            uid,
            f"ğŸ“¬ åˆä½œä¿¡ç®±ï¼š{email}\n\nğŸ“¸ å®˜æ–¹IG: {ig_url}",
            f"ğŸ“¬ Contact: {email}\n\nğŸ“¸ IG: {ig_url}"
        )))

    elif cmd == "status":
        url = _status_liff_url(uid=uid)
        safe_reply(event, TextSendMessage(text=L(uid, f"âš¡ é–‹å•Ÿç‹€æ…‹å›å ±ï¼š\n{url}", f"âš¡ Open status report:\n{url}")))
        return

    elif cmd == "ach":
        reply_url = f"{PUBLIC_URL}/achievements_liff?uid={uid}&lang={get_user_lang(uid)}"
        safe_reply(event, TextSendMessage(text=L(uid, f"æŸ¥çœ‹æˆå°± ğŸ‘‰ {reply_url}", f"View achievements ğŸ‘‰ {reply_url}")))
        return

    elif cmd == "badges":
        reply_url = f"{PUBLIC_URL}/badges_liff?uid={uid}&lang={get_user_lang(uid)}"
        safe_reply(event, TextSendMessage(text=L(uid, f"æŸ¥çœ‹å¾½ç«  ğŸ‘‰ {reply_url}", f"View badges ğŸ‘‰ {reply_url}")))
        return

    elif cmd == "review":
        summary = build_usage_review_text(uid)
        reply_messages.append(TextSendMessage(text=summary))

    elif cmd == "help":
        reply_messages.append(TextSendMessage(text=T("help_text", uid=uid)))

    # =========================
    # âœ… æ°¸é ä¸æ²‰é»˜
    # =========================
    if reply_messages:
        safe_reply(event, reply_messages)
    else:
        safe_reply(
            event,
            TextSendMessage(text=L(
                uid,
                "æˆ‘æ²’æœ‰çœ‹æ‡‚ä½ çš„æŒ‡ä»¤ ğŸ™\nä½ å¯ä»¥è©¦è©¦ï¼šé™„è¿‘å»æ‰€ / ä½¿ç”¨èªªæ˜",
                "I didnâ€™t understand ğŸ™\nTry: Nearby Toilets / Help"
            ))
        )

# === LocationMessage ===
@handler.add(MessageEvent, message=LocationMessage)
def handle_location(event):
    if _too_old_to_reply(event):
        logging.warning("[handle_location] event too old; skip reply.")
        return
    uid = event.source.user_id
    show_loading(uid, seconds=15)
    lat = event.message.latitude
    lon = event.message.longitude

    # è¨˜éŒ„æŸ¥è©¢æ¬¡æ•¸ï¼ˆå¯« DBï¼‰
    try:
        conn = _get_db()
        cur = conn.cursor()
        cur.execute(
            "INSERT INTO search_log (user_id, lat, lon, ts) VALUES (?,?,?,?)",
            (uid, norm_coord(lat), norm_coord(lon),
             datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"))
        )
        conn.commit()
        conn.close()
    except Exception as e:
        logging.warning(f"è¨˜éŒ„æŸ¥è©¢æ¬¡æ•¸å¤±æ•—: {e}")

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    if is_duplicate_and_mark_event(event):
        return

    # è¨˜ä¸‹ä½¿ç”¨è€…æœ€è¿‘ä¸€æ¬¡çš„ä½ç½®
    set_user_location(uid, (lat, lon))

    if not _try_acquire_loc_slot():
        safe_reply(event, make_retry_location_text())
        return

    try:
        toilets = build_nearby_toilets(uid, lat, lon)

        if toilets:
            # å…ˆç”¢å‡ºåŸæœ¬çš„å»æ‰€ carousel
            msg = create_toilet_flex_messages(toilets, uid=uid)

            # çœ‹ç›®å‰æ˜¯ä¸€èˆ¬æ¨¡å¼é‚„æ˜¯ AI æ¨¡å¼
            mode = get_user_loc_mode(uid)

            if mode == "ai":
                # ğŸ§  AI æ¨¡å¼ï¼šæŠŠ AI æ¨è–¦æ–‡å­—å¡æˆã€Œç¬¬ä¸€å€‹ bubbleã€
                ai_text = build_ai_nearby_recommendation(uid, toilets)

                if ai_text:
                    ai_bubble = {
                        "type": "bubble",
                        "body": {
                            "type": "box",
                            "layout": "vertical",
                            "contents": [
                                {
                                    "type": "text",
                                    "text": L(uid, "ğŸ¤– AI æ¨è–¦åˆ†æ", "ğŸ¤– AI Recommendation"),
                                    "weight": "bold",
                                    "size": "lg",
                                    "wrap": True,
                                },
                                {
                                    "type": "text",
                                    "text": ai_text,
                                    "size": "sm",
                                    "color": "#444444",
                                    "wrap": True,
                                },
                            ]
                        }
                    }
                    try:
                        # å®‰å…¨æ’å…¥åˆ° carousel æœ€å‰é¢
                        if isinstance(msg, dict) and msg.get("type") == "carousel":
                            msg.setdefault("contents", [])
                            contents = msg.get("contents")
                            if isinstance(contents, list):
                                contents.insert(0, ai_bubble)
                    except Exception as e:
                        logging.warning(f"æ’å…¥ AI bubble å¤±æ•—: {e}")

                # ğŸ‘‰ è¨Šæ¯æ•¸é‡ï¼š1 å‰‡ Flex + 1 å‰‡ quick-reply æ–‡å­—
                messages = [
                    FlexSendMessage(L(uid, "é™„è¿‘å»æ‰€ï¼ˆAI æ¨¡å¼ï¼‰", "Nearby Toilets (AI Mode)"), msg),
                    make_location_quick_reply(L(uid, "æƒ³ç”¨ AI å†åˆ†æå…¶ä»–ä½ç½®å—ï¼Ÿ", "Want AI to analyze another location?")),
                ]

            else:
                # âš¡ ä¸€èˆ¬æ¨¡å¼ï¼šåŸæœ¬è¡Œç‚ºä¸è®Š
                messages = [
                    FlexSendMessage(L(uid, "é™„è¿‘å»æ‰€", "Nearby Toilets"), msg),
                    make_location_quick_reply(
                        L(uid, "æƒ³æ›å€‹åœ°é»å†æ‰¾å—ï¼Ÿ", "Want to search another location?")
                    ),
                ]

            safe_reply(event, messages)

    except Exception as e:
        logging.error(f"nearby error: {e}", exc_info=True)
        safe_reply(event, TextSendMessage(text=L(uid, "ç³»çµ±å¿™ç·šä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™", "System is busy. Please try again later ğŸ™")))
    finally:
        _release_loc_slot()

# === Postback ===
@handler.add(PostbackEvent)
def handle_postback(event):
    uid = event.source.user_id
    data_raw = (event.postback.data or "").strip()

    # =========================
    # 0ï¸âƒ£ è§£æ postback åƒæ•¸ï¼ˆæ”¯æ´ä»»ä½•é †åº / URL encodeï¼‰
    #    æ”¯æ´ï¼š
    #      switch=more&lang=en
    #      switch=main&lang=zh
    #      cmd=nearby&lang=en
    # =========================
    decoded = data_raw
    qs = {}
    _lang = _cmd = _switch = None

    try:
        decoded = unquote(data_raw)
        qs = parse_qs(decoded, keep_blank_values=True)

        _lang   = (qs.get("lang")   or [None])[0]
        _cmd    = (qs.get("cmd")    or [None])[0]
        _switch = (qs.get("switch") or [None])[0]
    except Exception:
        # è§£æå¤±æ•—å°±èµ° fallbackï¼ˆä¿ç•™åŸå­—ä¸²ï¼‰
        qs = {}

    # âœ… ä»»ä½• postback åªè¦å¸¶ lang å°±å…ˆæ›´æ–°èªè¨€ï¼ˆåˆ‡ menu/æŒ‰åŠŸèƒ½éƒ½ç®—ï¼‰
    if _lang in ("en", "zh"):
        try:
            set_user_lang(uid, _lang)
        except Exception:
            pass

    # âœ… richmenuswitchï¼šåªåšã€Œåˆ‡æ›ç¢ºèªã€ï¼Œä¸è¦èµ° gate/ä¸è¦è§¸ç™¼å…¶å®ƒåŠŸèƒ½
    #    ï¼ˆé¿å…ä½ è¦ºå¾—ã€Œæ²’åˆ‡æˆåŠŸã€å…¶å¯¦åªæ˜¯ LINE UI å¿«å–/å¾Œç«¯æ²’å›è¦†ï¼‰
    if _switch in ("more", "main"):
        safe_reply(
            event,
            TextSendMessage(text=T("menu_switched", uid=uid))
        )
        return

    # âœ… å¦‚æœæœ‰ cmdï¼Œçµ±ä¸€æ”¶æ–‚æˆ cmd=xxxï¼ˆè®“ä½ ä¸‹é¢åŸæœ¬ cmd åˆ†æ´¾èƒ½å‘½ä¸­ï¼‰
    if _cmd:
        data = f"cmd={_cmd}"
    else:
        data = decoded  # ä¿ç•™åŸå­—ä¸²ï¼ˆä¾‹å¦‚ lang=en / set_lang:en é€™ç¨®ï¼‰

    # =========================
    # 1ï¸âƒ£ èªè¨€åˆ‡æ›ï¼ˆæœ€å„ªå…ˆï¼‰
    # =========================
    if data in ("lang=en", "lang=zh"):
        try:
            lang = "en" if data == "lang=en" else "zh"
            set_user_lang(uid, lang)
            safe_reply(
                event,
                TextSendMessage(
                    text=T("lang_switched_en", uid=uid) if lang == "en" else T("lang_switched_zh", uid=uid)
                )
            )
        except Exception as e:
            logging.error(f"åˆ‡æ›èªè¨€å¤±æ•—: {e}", exc_info=True)
            safe_reply(event, TextSendMessage(text=T("lang_switch_fail", uid=uid)))
        return

    if data == "set_lang:en":
        set_user_lang(uid, "en")
        safe_reply(event, TextSendMessage(text=T("lang_switched_en", uid=uid)))
        return

    if data == "set_lang:zh":
        set_user_lang(uid, "zh")
        safe_reply(event, TextSendMessage(text=T("lang_switched_zh", uid=uid)))
        return

    # =========================
    # 2ï¸âƒ£ é‡è¤‡äº‹ä»¶æ“‹æ‰
    # =========================
    if is_duplicate_and_mark_event(event):
        return

    # =========================
    # 3ï¸âƒ£ åŒæ„æ¢æ¬¾ gate
    # =========================
    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return
    
    try:
        # ==========================================================
        # 3.5ï¸âƒ£ Rich Menu çµ±ä¸€æŒ‡ä»¤ï¼šcmd=xxxx
        # ==========================================================
        if data.startswith("cmd="):
            cmd = data.split("=", 1)[1].strip().split("&", 1)[0]
            if cmd in ("noop_main", "noop_more"):
                return

            # =========================
            # âœ… æ–°å¢ï¼šé™„è¿‘å»æ‰€ï¼ˆé‡é»ï¼‰
            # =========================
            if cmd == "nearby":
                mode = get_user_loc_mode(uid)
                safe_reply(
                    event,
                    make_location_quick_reply(
                        L(uid,
                          "ğŸ“ è«‹é»ä¸‹æ–¹ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘ç«‹åˆ»å¹«ä½ æ‰¾å»æ‰€",
                          "ğŸ“ Please share your location and Iâ€™ll find nearby toilets for you"),
                        mode=mode,
                        uid=uid
                    )
                )
                return

            # æˆ‘çš„æœ€æ„›
            if cmd == "favs":
                favs = get_user_favorites(uid)
                if not favs:
                    safe_reply(event, TextSendMessage(text=L(uid, "ä½ å°šæœªæ”¶è—ä»»ä½•å»æ‰€", "You have no favorites yet.")))
                    return

                loc = get_user_location(uid)
                if loc:
                    lat, lon = loc
                    for f in favs:
                        f["distance"] = haversine(lat, lon, f["lat"], f["lon"])

                msg = create_toilet_flex_messages(favs, uid=uid)
                safe_reply(event, FlexSendMessage(L(uid, "æˆ‘çš„æœ€æ„›", "My Favorites"), msg))
                return

            # ä½¿ç”¨èªªæ˜
            if cmd == "help":
                safe_reply(event, TextSendMessage(text=T("help_text", uid=uid)))
                return

            # æ–°å¢å»æ‰€
            if cmd == "add":
                base = "https://school-i9co.onrender.com/add"
                loc = get_user_location(uid)
                if loc:
                    la, lo = loc
                    url = f"{base}?uid={quote(uid)}&lat={la}&lon={lo}#openExternalBrowser=1"
                else:
                    url = f"{base}?uid={quote(uid)}#openExternalBrowser=1"

                safe_reply(event, TextSendMessage(text=L(
                    uid,
                    f"è«‹å‰å¾€æ­¤é æ–°å¢å»æ‰€ï¼š\n{url}",
                    f"Please add a toilet here:\n{url}"
                )))
                return

            # æˆ‘çš„è²¢ç»
            if cmd == "contrib":
                msg = create_my_contrib_flex(uid)
                if msg:
                    safe_reply(event, FlexSendMessage(L(uid, "æˆ‘æ–°å¢çš„å»æ‰€", "My Contributions"), msg))
                else:
                    safe_reply(event, TextSendMessage(text=L(uid, "ä½ é‚„æ²’æœ‰æ–°å¢éå»æ‰€å–”ã€‚", "You haven't added any toilets yet.")))
                return

            # æ„è¦‹å›é¥‹
            if cmd == "feedback":
                form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdsibz15enmZ3hJsQ9s3BiTXV_vFXLy0llLKlpc65vAoGo_hg/viewform?usp=sf_link"
                safe_reply(event, TextSendMessage(text=L(
                    uid,
                    f"ğŸ’¡ è«‹é€éä¸‹åˆ—é€£çµå›å ±å•é¡Œæˆ–æä¾›æ„è¦‹ï¼š\n{form_url}",
                    f"ğŸ’¡ Please send feedback via:\n{form_url}"
                )))
                return

            # ç‹€æ…‹å›å ±
            if cmd == "status":
                url = _status_liff_url(uid=uid)
                safe_reply(event, TextSendMessage(text=L(
                    uid,
                    f"âš¡ é–‹å•Ÿç‹€æ…‹å›å ±ï¼š\n{url}",
                    f"âš¡ Open status report:\n{url}"
                )))
                return

            # æˆå°±
            if cmd == "ach":
                reply_url = f"{PUBLIC_URL}/achievements_liff?uid={uid}&lang={get_user_lang(uid)}"
                safe_reply(event, TextSendMessage(text=L(
                    uid,
                    f"æŸ¥çœ‹æˆå°± ğŸ‘‰ {reply_url}",
                    f"View achievements ğŸ‘‰ {reply_url}"
                )))
                return

            # å¾½ç« 
            if cmd == "badges":
                reply_url = f"{PUBLIC_URL}/badges_liff?uid={uid}&lang={get_user_lang(uid)}"
                safe_reply(event, TextSendMessage(text=L(
                    uid,
                    f"æŸ¥çœ‹å¾½ç«  ğŸ‘‰ {reply_url}",
                    f"View badges ğŸ‘‰ {reply_url}"
                )))
                return

            # ä½¿ç”¨å›é¡§
            if cmd == "review":
                summary = build_usage_review_text(uid)
                safe_reply(event, TextSendMessage(text=summary))
                return

            return

        # =========================
        # 4ï¸âƒ£ Quick Replyï¼šä¸€èˆ¬ä½ç½®
        # =========================
        if data == "ask_location":
            mode = get_user_loc_mode(uid)
            safe_reply(
                event,
                make_location_quick_reply(
                    L(uid,
                      "ğŸ“ è«‹é»ä¸‹æ–¹ã€å‚³é€æˆ‘çš„ä½ç½®ã€ï¼Œæˆ‘ç«‹åˆ»å¹«ä½ æ‰¾å»æ‰€",
                      "ğŸ“ Please share your location and Iâ€™ll find nearby toilets for you"),
                    mode=mode,
                    uid=uid
                )
            )
            return

        # =========================
        # 5ï¸âƒ£ Quick Replyï¼šAI ä½ç½®
        # =========================
        if data == "ask_ai_location":
            set_user_loc_mode(uid, "ai")
            safe_reply(
                event,
                make_location_quick_reply(
                    L(uid,
                      "ğŸ“ è«‹å‚³é€ä½ çš„ä½ç½®ï¼Œæˆ‘æœƒç”¨ AI å¹«ä½ æŒ‘é™„è¿‘æœ€é©åˆçš„å»æ‰€",
                      "ğŸ“ Please share your location. I will use AI to pick the best nearby toilets."),
                    mode="ai",
                    uid=uid
                )
            )
            return

    except Exception as e:
        logging.error(f"âŒ è™•ç† postback å¤±æ•—: {e}", exc_info=True)

# === æ–°å¢å»æ‰€é é¢ ===
@app.route("/add", methods=["GET"])
def render_add_page():
    uid = request.args.get("uid", "")
    lat = request.args.get("lat", "")
    lon = request.args.get("lon", "")
    preset_address = ""

    if lat and lon:
        try:
            ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
            url = f"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat={lat}&lon={lon}&addressdetails=1"
            headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                a = data.get("address", {})
                pretty = " ".join(filter(None, [
                    a.get("country", ""),
                    a.get("state", a.get("region", "")),
                    a.get("city", a.get("town", a.get("village", a.get("county", "")))),
                    a.get("suburb", a.get("neighbourhood", "")),
                    a.get("road", ""),
                    a.get("house_number", ""),
                    a.get("postcode", "")
                ])).strip()
                preset_address = pretty or data.get("display_name", "")
        except Exception as e:
            logging.warning(f"reverse geocode å¤±æ•—: {e}")

    return render_template(
        "submit_toilet.html",
        preset_address=preset_address,
        preset_lat=lat,
        preset_lon=lon
    )

# === Sheets å¯«å…¥ä¿è­·ï¼šè¶…é 1e7 cells å°± fallback åˆ°æœ¬æ©Ÿå„²å­˜ ===
_toilet_sheet_over_quota = False
_toilet_sheet_over_quota_ts = 0

def _fallback_store_toilet_row_locally(row_values):
    # CSV + SQLite éƒ½ä¸æ˜¯ thread-safeï¼Œéœ€è¦é–ä½æ•´æ®µ
    with _fallback_lock:

        # 1) é™„åŠ åˆ° public_toilets.csv
        try:
            if not os.path.exists(TOILETS_FILE_PATH):
                with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(PUBLIC_HEADERS)

            header = ensure_toilet_sheet_header(worksheet)
            idx = {h:i for i,h in enumerate(header)}

            def v(col):
                try:
                    return row_values[idx[col]]
                except Exception:
                    return ""

            name = v("name")
            addr = v("address")
            lat_s = v("lat")
            lon_s = v("lon")

            with open(TOILETS_FILE_PATH, "a", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "00000","0000000","æœªçŸ¥é‡Œ","USERADD",
                    name, addr, "ä½¿ç”¨è€…è£œå……",
                    lat_s, lon_s,
                    "æ™®é€šç´š","å…¬å…±å ´æ‰€","æœªçŸ¥","ä½¿ç”¨è€…","0"
                ])

        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³æœ¬åœ° CSV å¤±æ•—ï¼š{e}")

        # 2) å¯«å…¥ SQLite
        try:
            conn = sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)
            cur = conn.cursor()
            cur.execute("""
            CREATE TABLE IF NOT EXISTS user_toilets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT, name TEXT, address TEXT,
                lat TEXT, lon TEXT,
                level TEXT, floor_hint TEXT, entrance_hint TEXT,
                access_note TEXT, open_hours TEXT, timestamp TEXT
            )
            """)

            header = ensure_toilet_sheet_header(worksheet)
            idx = {h:i for i,h in enumerate(header)}

            def v(col):
                try:
                    return row_values[idx[col]]
                except:
                    return ""

            cur.execute("""
                INSERT INTO user_toilets (
                    user_id, name, address, lat, lon,
                    level, floor_hint, entrance_hint,
                    access_note, open_hours, timestamp
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                v("user_id"), v("name"), v("address"),
                v("lat"), v("lon"),
                v("level"), v("floor_hint"), v("entrance_hint"),
                v("access_note"), v("open_hours"),
                v("timestamp")
            ))

            conn.commit()
            conn.close()

        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³ SQLite å¤±æ•—ï¼š{e}")

def _append_toilet_row_safely(ws, row_values):
    global _toilet_sheet_over_quota, _toilet_sheet_over_quota_ts

    if _toilet_sheet_over_quota:
        _fallback_store_toilet_row_locally(row_values)
        return ("fallback", "Google è©¦ç®—è¡¨å·²é”å„²å­˜ä¸Šé™ï¼Œæ”¹ç‚ºæš«å­˜æœ¬æ©Ÿã€‚")

    try:
        with _gsheet_lock:
            ws.append_row(row_values, value_input_option="USER_ENTERED")
        return ("ok", "å·²å¯«å…¥ Google è©¦ç®—è¡¨")

    except Exception as e:
        s = str(e)
        if "10000000" in s or "above the limit" in s:
            logging.error("ğŸ§± Google è©¦ç®—è¡¨é”åˆ° 1e7 cells ä¸Šé™ï¼Œå•Ÿç”¨æœ¬æ©Ÿæš«å­˜ã€‚")
            _toilet_sheet_over_quota = True
            _toilet_sheet_over_quota_ts = time.time()
            logging.error("âŒ Sheets å·²æ»¿ï¼ŒSQLite fallback å·²åœç”¨ï¼Œè«‹è™•ç†è³‡æ–™å„²å­˜ç­–ç•¥")
            return ("fallback", "Google è©¦ç®—è¡¨å·²é”å„²å­˜ä¸Šé™ï¼Œæ”¹ç‚ºæš«å­˜æœ¬æ©Ÿã€‚")

        raise

def _get_db():
    return sqlite3.connect(CACHE_DB_PATH, timeout=5, check_same_thread=False)

def _ensure_pending_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pending_gsheet (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        payload_json TEXT NOT NULL,
        created_ts REAL
    )
    """)
    conn.commit(); conn.close()

_ensure_pending_table()

# === æŸ¥è©¢ç´€éŒ„ search_log ===
def _ensure_search_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS search_log (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id TEXT,
        lat TEXT,
        lon TEXT,
        ts TEXT
    )
    """)
    conn.commit()
    conn.close()

_ensure_search_table()

def _ensure_user_lang_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS user_lang (
        user_id TEXT PRIMARY KEY,
        lang TEXT
    )
    """)
    conn.commit()
    conn.close()

_ensure_user_lang_table()

def _ensure_search_index():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("CREATE INDEX IF NOT EXISTS idx_search_user ON search_log(user_id)")
    conn.commit()
    conn.close()

_ensure_search_index()
# === æŸ¥è©¢ç´€éŒ„ search_log ===
def _ensure_ai_quota_table():
    conn = _get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS ai_quota (
        key TEXT,
        date TEXT,
        count INTEGER,
        PRIMARY KEY(key, date)
    )
    """)
    conn.commit()
    conn.close()

_ensure_ai_quota_table()

def _queue_pending_row(row_values):
    try:
        conn = _get_db(); cur = conn.cursor()
        cur.execute("INSERT INTO pending_gsheet (payload_json, created_ts) VALUES (?, ?)",
                    (json.dumps(row_values, ensure_ascii=False), time.time()))
        conn.commit(); conn.close()
    except Exception as e:
        logging.warning(f"queue pending failed: {e}")

def _drain_pending(limit=200):
    _ensure_sheets_ready()
    if worksheet is None:
        return 0, "worksheet not ready"

    conn = _get_db(); cur = conn.cursor()
    cur.execute("SELECT id, payload_json FROM pending_gsheet ORDER BY id ASC LIMIT ?", (limit,))
    rows = cur.fetchall()
    if not rows:
        conn.close(); return 0, "empty"

    ok = 0
    for row_id, payload in rows:
        try:
            vals = json.loads(payload)
            with _gsheet_lock:
                worksheet.append_row(vals, value_input_option="USER_ENTERED")
            cur.execute("DELETE FROM pending_gsheet WHERE id=?", (row_id,))
            ok += 1
        except Exception as e:
            logging.warning(f"backfill append failed: {e}")
            break
    conn.commit(); conn.close()
    return ok, "done"

ADMIN_TOKEN = os.getenv("ADMIN_TOKEN", "")

@app.route("/admin/backfill", methods=["POST"])
def admin_backfill():
    token = (request.headers.get("X-Admin-Token") or "").strip()
    if not ADMIN_TOKEN or token != ADMIN_TOKEN:
        return {"ok": False, "message": "unauthorized"}, 401

    n, note = _drain_pending(limit=500)
    return {"ok": True, "written": n, "note": note}, 200


# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ API ===
@app.route("/submit_toilet", methods=["POST"])
def submit_toilet():
    _ensure_sheets_ready()
    if worksheet is None:
        return {"success": False, "message": "é›²ç«¯è¡¨æ ¼æš«æ™‚ç„¡æ³•é€£ç·šï¼Œè«‹ç¨å¾Œå†è©¦"}, 503
    try:
        data = request.get_json(force=True, silent=False) or {}
        logging.info(f"ğŸ“¥ æ”¶åˆ°è¡¨å–®è³‡æ–™: {data}")

        uid   = (data.get("user_id") or "web").strip()
        name  = (data.get("name") or "").strip()
        addr  = (data.get("address") or "").strip()

        level          = (data.get("level") or "").strip()
        floor_hint     = (data.get("floor_hint") or "").strip()
        entrance_hint  = (data.get("entrance_hint") or "").strip()
        access_note    = (data.get("access_note") or "").strip()
        open_hours     = (data.get("open_hours") or "").strip()

        lat_in = (data.get("lat") or "").strip()
        lon_in = (data.get("lon") or "").strip()

        # å¿…å¡«æª¢æŸ¥
        if not name or not addr:
            return {"success": False, "message": "è«‹æä¾›ã€å»æ‰€åç¨±ã€èˆ‡ã€åœ°å€ã€"}, 400

        # ä½ç½®æè¿°åŸºæœ¬æª¢æŸ¥
        if floor_hint and len(floor_hint) < 4:
            return {"success": False, "message": "ã€ä½ç½®æè¿°ã€å¤ªçŸ­ï¼Œè«‹è‡³å°‘ 4 å€‹å­—"}, 400

        # æœªæä¾›ä½ç½®æè¿°å‰‡å˜—è©¦ç”±åç¨±æ¨æ–·
        if not floor_hint:
            inferred = _floor_from_name(name)
            if inferred:
                floor_hint = inferred

        # åº§æ¨™è§£æèˆ‡åœ°ç†ç·¨ç¢¼
        lat_f, lon_f = (None, None)
        if lat_in and lon_in:
            lat_f, lon_f = _parse_lat_lon(lat_in, lon_in)
        if lat_f is None or lon_f is None:
            lat_f, lon_f = geocode_address(addr)
        if lat_f is None or lon_f is None:
            return {"success": False, "message": "åœ°å€è½‰æ›å¤±æ•—ï¼Œè«‹ä¿®æ­£åœ°å€æˆ–æä¾›åº§æ¨™"}, 400

        lat_s, lon_s = norm_coord(lat_f), norm_coord(lon_f)

        # ä½ˆå±€è¡¨é ­ & å¯«å…¥æ¬„ä½
        header = ensure_toilet_sheet_header(worksheet)
        idx = {h: i for i, h in enumerate(header)}

        row_values = [""] * len(header)
        def put(col, val):
            if col in idx:
                row_values[idx[col]] = val

        put("user_id", uid)
        put("name", name)
        put("address", addr)
        put("lat", lat_s)
        put("lon", lon_s)
        put("level", level)
        put("floor_hint", floor_hint)
        put("entrance_hint", entrance_hint)
        put("access_note", access_note)
        put("open_hours", open_hours)
        put("timestamp", datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"))

        # âœ… å®‰å…¨å¯«å…¥ï¼ˆSheets æ»¿æ ¼è‡ªå‹• fallback åˆ°æœ¬æ©Ÿ CSV/SQLiteï¼‰
        status, note = _append_toilet_row_safely(worksheet, row_values)
        logging.info(f"ğŸ“ submit_toilet å¯«å…¥ç‹€æ…‹: {status} ({note}) name={name}")

        if status == "ok":
            return {"success": True, "message": f"âœ… å·²æ–°å¢å»æ‰€ {name}"}
        else:
            # fallbackï¼šè³‡æ–™å·²è½åœ°æœ¬æ©Ÿï¼Œä¹‹å¾Œå¯æ‰¹æ¬¡è£œå¯«åˆ°æ–°è©¦ç®—è¡¨
            return {"success": True, "message": f"âœ… å·²æš«å­˜ {name}ï¼ˆé›²ç«¯è¡¨å·²æ»¿ï¼Œç¨å¾Œå¯æ‰¹æ¬¡è£œå¯«ï¼‰"}

    except Exception as e:
        logging.error(f"âŒ æ–°å¢å»æ‰€éŒ¯èª¤:\n{traceback.format_exc()}")
        return {"success": False, "message": "ä¼ºæœå™¨éŒ¯èª¤"}, 500

# === èƒŒæ™¯æ’ç¨‹ï¼ˆé ç•™ï¼‰ ===
def auto_predict_cleanliness_background():
    while True:
        try:
            logging.info("ğŸŒ€ èƒŒæ™¯æ’ç¨‹å•Ÿå‹•ä¸­ï¼ˆæœªä¾†å¯åŠ å…¥è‡ªå‹•çµ±è¨ˆï¼‰")
        except Exception as e:
            logging.error(f"âŒ èƒŒæ™¯ä»»å‹™å‡ºéŒ¯ï¼š{e}")
        time.sleep(1800)

# === å•Ÿå‹• ===
if __name__ == "__main__":
    threading.Thread(target=auto_predict_cleanliness_background, daemon=True).start()
    threading.Thread(target=_self_keepalive_background, daemon=True).start()

    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
