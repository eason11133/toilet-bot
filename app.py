import os
import csv
import json
import logging
import requests
import traceback
from math import radians, cos, sin, asin, sqrt
from flask_cors import CORS
from flask import Flask, request, abort, render_template, redirect, url_for
from dotenv import load_dotenv
from urllib.parse import quote, unquote
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import (
    MessageEvent, TextMessage, LocationMessage,
    FlexSendMessage, PostbackEvent, TextSendMessage
)
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import joblib
import threading
import time
import statistics  # 95% CI ç”¨
from difflib import SequenceMatcher

try:
    import pandas as pd
except Exception:
    pd = None

# === åˆå§‹åŒ– ===
load_dotenv()
logging.basicConfig(level=logging.INFO)
app = Flask(__name__)
CORS(app)

line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

# æª”æ¡ˆ
DATA_DIR = os.path.join(os.getcwd(), "data")
TOILETS_FILE_PATH = os.path.join(DATA_DIR, "public_toilets.csv")  # å…¬å®¶è³‡æ–™/å‚™ä»½
FAVORITES_FILE_PATH = os.path.join(DATA_DIR, "favorites.txt")     # ä»æ²¿ç”¨åŸæª”åï¼Œä½†ä»¥ csv æ–¹å¼è®€å¯«
os.makedirs(DATA_DIR, exist_ok=True)

# ç¢ºä¿ favorites æª”å­˜åœ¨
if not os.path.exists(FAVORITES_FILE_PATH):
    open(FAVORITES_FILE_PATH, "a", encoding="utf-8").close()

# ç¢ºä¿ public_toilets.csv å…·æœ‰è¡¨é ­ï¼ˆä¾› DictReader ä½¿ç”¨ï¼‰
PUBLIC_HEADERS = [
    "country","city","village","number","name","address","administration",
    "latitude","longitude","grade","type2","type","exec","diaper"
]
if not os.path.exists(TOILETS_FILE_PATH):
    with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(PUBLIC_HEADERS)

# === Google Sheets è¨­å®š ===
GSHEET_SCOPE = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
GSHEET_CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON")
TOILET_SPREADSHEET_ID = "1Vg3tiqlXcXjcic2cAWCG-xTXfNzcI7wegEnZx8Ak7ys"  # ä¸»è³‡æ–™ï¼ˆä½¿ç”¨è€…æ–°å¢å»æ‰€ï¼‰
FEEDBACK_SPREADSHEET_ID = "15Ram7EZ9QMN6SZAVYQFNpL5gu4vTaRn4M5mpWUKmmZk"  # å›é¥‹/é æ¸¬

# â˜… åŒæ„æ›¸è¨­å®š
CONSENT_SHEET_TITLE = "consent"
CONSENT_PAGE_URL = os.getenv("CONSENT_PAGE_URL", "https://school-i9co.onrender.com/consent")

gc = worksheet = feedback_sheet = consent_ws = None

# === è¼‰å…¥æ¨¡å‹ ===
BASE_DIR = os.path.abspath(os.path.dirname(__file__))

def load_cleanliness_model():
    try:
        model_path = os.path.join(BASE_DIR, 'models', 'clean_model.pkl')
        model = joblib.load(model_path)
        logging.info("âœ… æ¸…æ½”åº¦æ¨¡å‹å·²è¼‰å…¥")
        return model
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def load_label_encoder():
    try:
        encoder_path = os.path.join(BASE_DIR, 'models', 'label_encoder.pkl')
        encoder = joblib.load(encoder_path)
        logging.info("âœ… LabelEncoder å·²è¼‰å…¥")
        return encoder
    except Exception as e:
        logging.error(f"âŒ LabelEncoder è¼‰å…¥å¤±æ•—: {e}")
        return None

cleanliness_model = load_cleanliness_model()
label_encoder = load_label_encoder()

# === åƒæ•¸ ===
LAST_N_HISTORY = 5

# === å·¥å…·ï¼šåº§æ¨™æ¨™æº–åŒ–ï¼è§£æ ===
def norm_coord(x, ndigits=6):
    try:
        return f"{round(float(x), ndigits):.{ndigits}f}"
    except:
        return str(x)

def _parse_lat_lon(lat_s, lon_s):
    try:
        lat = float(str(lat_s).strip())
        lon = float(str(lon_s).strip())
    except Exception:
        return None, None

    if abs(lat) > 90 and abs(lon) <= 90:
        lat, lon = lon, lat

    if not (-90 <= lat <= 90 and -180 <= lon <= 180):
        return None, None

    return lat, lon

# === åˆå§‹åŒ– Google Sheets ===
def init_gsheet():
    global gc, worksheet, feedback_sheet, consent_ws
    try:
        if not GSHEET_CREDENTIALS_JSON:
            raise RuntimeError("ç¼ºå°‘ GSHEET_CREDENTIALS_JSON")
        creds_dict = json.loads(GSHEET_CREDENTIALS_JSON)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, GSHEET_SCOPE)
        gc = gspread.authorize(creds)

        worksheet = gc.open_by_key(TOILET_SPREADSHEET_ID).sheet1
        fb_spread = gc.open_by_key(FEEDBACK_SPREADSHEET_ID)
        feedback_sheet = fb_spread.sheet1

        # â˜… å–å¾—æˆ–å»ºç«‹ consent å·¥ä½œè¡¨
        try:
            consent_ws = fb_spread.worksheet(CONSENT_SHEET_TITLE)
        except gspread.exceptions.WorksheetNotFound:
            consent_ws = fb_spread.add_worksheet(title=CONSENT_SHEET_TITLE, rows=1000, cols=10)
            consent_ws.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])

        logging.info("âœ… Sheets åˆå§‹åŒ–å®Œæˆï¼ˆå« consentï¼‰")
    except Exception as e:
        logging.critical(f"âŒ Sheets åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

init_gsheet()

# === è¨ˆç®—è·é›¢ ===
def haversine(lat1, lon1, lat2, lon2):
    try:
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
        return 2 * asin(sqrt(a)) * 6371000  # m
    except Exception as e:
        logging.error(f"è¨ˆç®—è·é›¢å¤±æ•—: {e}")
        return 0

# === é˜²é‡è¤‡ï¼ˆ10 ç§’è¦–ç‚ºé‡è¤‡ï¼‰ ===
DEDUPE_WINDOW = int(os.getenv("DEDUPE_WINDOW", "10"))
_RECENT_EVENTS = {}

def is_duplicate_and_mark(key: str, window: int = DEDUPE_WINDOW) -> bool:
    now = time.time()
    ts = _RECENT_EVENTS.get(key)
    if ts is not None and (now - ts) < window:
        logging.info(f"ğŸ” skip duplicate: {key}")
        return True
    _RECENT_EVENTS[key] = now
    if len(_RECENT_EVENTS) > 5000 or (len(_RECENT_EVENTS) > 1000):
        for k, tstamp in list(_RECENT_EVENTS.items()):
            if now - tstamp > window:
                _RECENT_EVENTS.pop(k, None)
    return False

def is_redelivery(event) -> bool:
    try:
        dc = getattr(event, "delivery_context", None)
        return bool(getattr(dc, "is_redelivery", False))
    except Exception:
        return False

def safe_reply(event, messages):
    try:
        line_bot_api.reply_message(event.reply_token, messages)
    except LineBotApiError as e:
        msg_txt = ""
        try:
            msg_txt = getattr(getattr(e, "error", None), "message", "") or str(e)
        except Exception:
            msg_txt = str(e)
        if is_redelivery(event) or ("Invalid reply token" in msg_txt):
            logging.warning(f"reply_message å¤±æ•—ä½†ä¸ pushï¼ˆé¿å…é‡è¤‡ï¼‰ï¼š{msg_txt}")
            return
        logging.warning(f"reply_message å¤±æ•—ï¼Œæ”¹ç”¨ pushï¼š{msg_txt}")
        try:
            uid = getattr(event.source, "user_id", None)
            if uid:
                line_bot_api.push_message(uid, messages)
        except Exception as ex:
            logging.error(f"push_message ä¹Ÿå¤±æ•—ï¼š{ex}")

# === åŒæ„å·¥å…· ===
def _booly(v):
    s = str(v).strip().lower()
    return s in ["1", "true", "yes", "y", "åŒæ„"]

def has_consented(user_id: str) -> bool:
    """æŸ¥ consent sheet æ˜¯å¦æœ‰ agree=true çš„ç´€éŒ„"""
    try:
        if not user_id or consent_ws is None:
            return False
        rows = consent_ws.get_all_values()
        if not rows or len(rows) < 2:
            return False
        header = rows[0]; data = rows[1:]
        try:
            i_uid = header.index("user_id")
            i_ag  = header.index("agreed")
        except ValueError:
            return False
        for r in data:
            if len(r) <= max(i_uid, i_ag):
                continue
            if (r[i_uid] or "").strip() == user_id and _booly(r[i_ag]):
                return True
        return False
    except Exception as e:
        logging.warning(f"æŸ¥è©¢åŒæ„å¤±æ•—: {e}")
        return False

def upsert_consent(user_id: str, agreed: bool, display_name: str, source_type: str, ua: str, ts_iso: str):
    """ä»¥ user_id é€²è¡Œ upsert åˆ° consent sheet"""
    try:
        rows = consent_ws.get_all_values()
        if not rows:
            consent_ws.update("A1:F1", [["user_id","agreed","display_name","source_type","ua","timestamp"]])
            rows = [["user_id","agreed","display_name","source_type","ua","timestamp"]]
        header = rows[0]; data = rows[1:]

        idx = {h:i for i,h in enumerate(header)}
        for k in ["user_id","agreed","display_name","source_type","ua","timestamp"]:
            if k not in idx:
                header.append(k); idx[k] = len(header)-1
        if len(header) != len(rows[0]):
            consent_ws.update("A1", [header])

        # æ‰¾èˆŠè³‡æ–™åˆ—
        row_to_update = None
        for i, r in enumerate(data, start=2):
            if len(r) > idx["user_id"] and (r[idx["user_id"]] or "").strip() == user_id:
                row_to_update = i
                break

        row_values = [""] * len(header)
        row_values[idx["user_id"]] = user_id or ""
        row_values[idx["agreed"]] = "true" if agreed else "false"
        row_values[idx["display_name"]] = display_name or ""
        row_values[idx["source_type"]] = source_type or ""
        row_values[idx["ua"]] = ua or ""
        row_values[idx["timestamp"]] = ts_iso or datetime.utcnow().isoformat()

        if row_to_update:
            consent_ws.update(f"A{row_to_update}", [row_values])
        else:
            consent_ws.append_row(row_values, value_input_option="USER_ENTERED")
        return True
    except Exception as e:
        logging.error(f"å¯«å…¥/æ›´æ–°åŒæ„å¤±æ•—: {e}")
        return False

def ensure_consent_or_prompt(user_id: str):
    """æœªåŒæ„æ™‚å›å‚³å¼•å°è¨Šæ¯ï¼ˆè¦åœ¨ handler å…§ç”¨ safe_reply ç™¼é€å¾Œ returnï¼‰"""
    if has_consented(user_id):
        return None
    tip = (
        "ğŸ›¡ï¸ ä½¿ç”¨å‰è«‹å…ˆå®ŒæˆåŒæ„ï¼š\n"
        f"{CONSENT_PAGE_URL}\n\n"
        "è‹¥ä¸åŒæ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡ç„¡æ³•æä¾›ã€‚"
    )
    return TextSendMessage(text=tip)

# === å¾ Google Sheets æŸ¥ä½¿ç”¨è€…æ–°å¢å»æ‰€ ===
def query_sheet_toilets(user_lat, user_lon, radius=500):
    toilets = []
    try:
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) < 5:
                continue
            name = (row[1] if len(row) > 1 else "").strip() or "ç„¡åç¨±"
            address = (row[2] if len(row) > 2 else "").strip()
            try:
                t_lat = float(row[3]); t_lon = float(row[4])
            except:
                continue
            dist = haversine(user_lat, user_lon, t_lat, t_lon)
            if dist <= radius:
                toilets.append({
                    "name": name,
                    "lat": float(norm_coord(t_lat)),
                    "lon": float(norm_coord(t_lon)),
                    "address": address,
                    "distance": dist,
                    "type": "sheet"
                })
    except Exception as e:
        logging.error(f"è®€å– Google Sheets å»æ‰€ä¸»è³‡æ–™éŒ¯èª¤: {e}")
    return sorted(toilets, key=lambda x: x["distance"])

# === OSM Overpassï¼ˆå¤šé¡åƒï¼‰ ===
def query_overpass_toilets(lat, lon, radius=500):
    query = f"""
    [out:json][timeout:25];
    (
      node["amenity"="toilets"](around:{radius},{lat},{lon});
      way["amenity"="toilets"](around:{radius},{lat},{lon});
      relation["amenity"="toilets"](around:{radius},{lat},{lon});
    );
    out center;
    """
    endpoints = [
        "https://overpass-api.de/api/interpreter",
        "https://overpass.kumi.systems/api/interpreter",
        "https://overpass.openstreetmap.ru/api/interpreter",
    ]
    ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
    headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}

    last_err = None
    for idx, url in enumerate(endpoints):
        try:
            resp = requests.post(url, data=query, headers=headers, timeout=30)
            ctype = (resp.headers.get("Content-Type") or "").lower()
            if resp.status_code != 200 or "json" not in ctype:
                snippet = (resp.text or "")[:200].replace("\n", " ")
                logging.warning(f"Overpass é 200 æˆ–é JSON (endpoint {idx}): status={resp.status_code}, ctype={ctype}, body~={snippet}")
                last_err = RuntimeError("overpass non-json")
                continue

            data = resp.json()
            elements = data.get("elements", [])
            toilets = []
            for elem in elements:
                if elem["type"] == "node":
                    t_lat, t_lon = elem["lat"], elem["lon"]
                elif "center" in elem:
                    t_lat, t_lon = elem["center"]["lat"], elem["center"]["lon"]
                else:
                    continue

                tags = elem.get("tags", {})
                name = tags.get("name", "ç„¡åç¨±")
                address = tags.get("addr:full", "") or tags.get("addr:street", "") or ""
                toilets.append({
                    "name": name,
                    "lat": float(norm_coord(t_lat)),
                    "lon": float(norm_coord(t_lon)),
                    "address": address,
                    "distance": haversine(lat, lon, t_lat, t_lon),
                    "type": "osm"
                })
            return sorted(toilets, key=lambda x: x["distance"])
        except Exception as e:
            last_err = e
            logging.warning(f"Overpass API æŸ¥è©¢å¤±æ•—ï¼ˆendpoint {idx}ï¼‰: {e}")

    logging.error(f"Overpass å…¨éƒ¨ç«¯é»å¤±æ•—ï¼š{last_err}")
    return []

# === è®€æœ¬åœ° public_toilets.csv ===
def query_public_csv_toilets(user_lat, user_lon, radius=500):
    pts = []
    if not os.path.exists(TOILETS_FILE_PATH):
        return pts
    try:
        with open(TOILETS_FILE_PATH, "r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    t_lat = float(row.get("latitude"))
                    t_lon = float(row.get("longitude"))
                except Exception:
                    continue
                dist = haversine(user_lat, user_lon, t_lat, t_lon)
                if dist <= radius:
                    name = (row.get("name") or "ç„¡åç¨±").strip()
                    addr = (row.get("address") or "").strip()
                    pts.append({
                        "name": name,
                        "lat": float(norm_coord(t_lat)),
                        "lon": float(norm_coord(t_lon)),
                        "address": addr,
                        "distance": dist,
                        "type": "public_csv",
                        "grade": row.get("grade", ""),
                        "category": row.get("type2", "")
                    })
    except Exception as e:
        logging.error(f"è®€ public_toilets.csv å¤±æ•—ï¼š{e}")
    return sorted(pts, key=lambda x: x["distance"])

# === åˆä½µ + ç°¡å–®å»é‡ ===
def _merge_and_dedupe_lists(*lists, dist_th=35, name_sim_th=0.55):
    all_pts = []
    for l in lists:
        if l: all_pts.extend(l)
    all_pts.sort(key=lambda x: x["distance"])

    merged = []
    for p in all_pts:
        dup = False
        for q in merged:
            try:
                near = haversine(p["lat"], p["lon"], q["lat"], q["lon"]) <= dist_th
            except Exception:
                near = False
            sim = SequenceMatcher(None, (p.get("name") or "").lower(), (q.get("name") or "").lower()).ratio()
            if near and sim >= name_sim_th:
                dup = True
                break
        if not dup:
            merged.append(p)
    return merged

# === æœ€æ„›ç®¡ç† ===
def add_to_favorites(uid, toilet):
    try:
        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        with open(FAVORITES_FILE_PATH, "a", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([uid, toilet['name'], lat_s, lon_s, toilet.get('address','')])
    except Exception as e:
        logging.error(f"åŠ å…¥æœ€æ„›å¤±æ•—: {e}")

def remove_from_favorites(uid, name, lat, lon):
    try:
        lat_s = norm_coord(lat)
        lon_s = norm_coord(lon)
        rows = []
        changed = False
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    rows.append(row); continue
                if not (row[0] == uid and row[1] == name and row[2] == lat_s and row[3] == lon_s):
                    rows.append(row)
                else:
                    changed = True
        with open(FAVORITES_FILE_PATH, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerows(rows)
        return changed
    except Exception as e:
        logging.error(f"ç§»é™¤æœ€æ„›å¤±æ•—: {e}")
        return False

def get_user_favorites(uid):
    favs = []
    try:
        with open(FAVORITES_FILE_PATH, "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 5:
                    continue
                if row[0] == uid:
                    favs.append({
                        "name": row[1],
                        "lat": float(row[2]),
                        "lon": float(row[3]),
                        "address": row[4],
                        "distance": 0,
                        "type": "favorite"
                    })
    except Exception as e:
        logging.error(f"è®€å–æœ€æ„›å¤±æ•—: {e}")
    return favs

# === åœ°å€è½‰ç¶“ç·¯åº¦ ===
def geocode_address(address):
    try:
        ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
        url = f"https://nominatim.openstreetmap.org/search?format=json&q={quote(address)}"
        headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
        resp = requests.get(url, headers=headers, timeout=10)
        data = resp.json()
        if resp.status_code == 200 and data:
            return float(data[0]['lat']), float(data[0]['lon'])
    except Exception as e:
        logging.error(f"åœ°å€è½‰ç¶“ç·¯åº¦å¤±æ•—: {e}")
    return None, None

# === é™„è¿‘å»æ‰€ APIï¼ˆå·²ç´å…¥ CSV + å»é‡ï¼‰ ===
@app.route("/nearby_toilets", methods=["GET"])
def nearby_toilets():
    user_lat = request.args.get('lat')
    user_lon = request.args.get('lon')
    if not user_lat or not user_lon:
        return {"error": "ç¼ºå°‘ä½ç½®åƒæ•¸"}, 400

    user_lat = float(user_lat)
    user_lon = float(user_lon)

    public_csv_toilets = query_public_csv_toilets(user_lat, user_lon, radius=500) or []
    sheet_toilets = query_sheet_toilets(user_lat, user_lon, radius=500) or []
    osm_toilets = query_overpass_toilets(user_lat, user_lon, radius=500) or []

    all_toilets = _merge_and_dedupe_lists(public_csv_toilets, sheet_toilets, osm_toilets)

    if not all_toilets:
        return {"message": "é™„è¿‘æ‰¾ä¸åˆ°å»æ‰€"}, 404
    return {"toilets": all_toilets}, 200

# === é¡¯ç¤ºå›é¥‹è¡¨å–®ï¼ˆå…è¨±æ²’æœ‰ addressï¼‰ ===
@app.route("/feedback_form/<toilet_name>/", defaults={'address': ''})
@app.route("/feedback_form/<toilet_name>/<path:address>")
def feedback_form(toilet_name, address):
    address = address or request.args.get("address", "")
    return render_template(
        "feedback_form.html",
        toilet_name=toilet_name,
        address=address,
        lat=request.args.get("lat", ""),
        lon=request.args.get("lon", "")
    )

# === Header å°é½Šå·¥å…· ===
def _norm_h(s):
    return (s or "").strip().lower()

def _find_idx(header, candidates):
    hmap = {_norm_h(h): i for i, h in enumerate(header)}
    for c in candidates:
        if _norm_h(c) in hmap:
            return hmap[_norm_h(c)]
    return None

def _feedback_indices(header):
    return {
        "name": _find_idx(header, ["åç¨±", "name", "toilet_name"]),
        "address": _find_idx(header, ["åœ°å€", "address"]),
        "rating": _find_idx(header, ["æ¸…æ½”åº¦è©•åˆ†", "æ¸…æ½”è©•åˆ†", "rating", "score"]),
        "paper": _find_idx(header, ["æ˜¯å¦æœ‰è¡›ç”Ÿç´™", "toilet_paper", "è¡›ç”Ÿç´™", "ç´™"]),
        "access": _find_idx(header, ["æ˜¯å¦æœ‰ç„¡éšœç¤™è¨­æ–½", "accessibility", "ç„¡éšœç¤™"]),
        "time": _find_idx(header, ["ä½¿ç”¨æ™‚é–“", "time_of_use", "time"]),
        "comment": _find_idx(header, ["ç•™è¨€", "comment", "å‚™è¨»"]),
        "pred": _find_idx(header, ["é æ¸¬åˆ†æ•¸", "é æ¸¬è©•åˆ†", "cleanliness_score", "predicted_score"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["created_at", "å»ºç«‹æ™‚é–“", "æ™‚é–“", "timestamp"]),
    }

def _toilet_sheet_indices(header):
    return {
        "user_id": _find_idx(header, ["user_id", "uid", "ä½¿ç”¨è€…"]),
        "name": _find_idx(header, ["name", "åç¨±"]),
        "address": _find_idx(header, ["address", "åœ°å€"]),
        "lat": _find_idx(header, ["lat", "ç·¯åº¦"]),
        "lon": _find_idx(header, ["lon", "ç¶“åº¦", "lng", "long"]),
        "created": _find_idx(header, ["timestamp", "created_at", "å»ºç«‹æ™‚é–“"]),
    }

# === æ¸…æ½”åº¦é æ¸¬ ===
def expected_from_feats(feats):
    try:
        if not feats or cleanliness_model is None:
            return None

        if pd is not None:
            df = pd.DataFrame(feats, columns=["rating","toilet_paper","accessibility"])
            probs = cleanliness_model.predict_proba(df)
        else:
            probs = cleanliness_model.predict_proba(feats)

        try:
            classes_enc = cleanliness_model.classes_
            labels = label_encoder.inverse_transform(classes_enc)
            labels = [float(x) for x in labels]
        except Exception:
            labels = [float(c) + 1.0 for c in cleanliness_model.classes_]

        exps = [sum(float(p)*float(l) for p, l in zip(p_row, labels)) for p_row in probs]
        return round(sum(exps)/len(exps), 2) if exps else None
    except Exception as e:
        logging.error(f"âŒ æ¸…æ½”åº¦é æ¸¬éŒ¯èª¤: {e}")
        return None


def _simple_score(rr, paper, acc):
    try:
        base = 1.0 + 4.0 * (int(rr) - 1) / 9.0
    except Exception:
        return None
    bonus = (0.25 if (paper == "æœ‰") else 0.0) + (0.25 if (acc == "æœ‰") else 0.0)
    score = base + bonus
    if score < 1.0: score = 1.0
    if score > 5.0: score = 5.0
    return round(score, 2)

# === å¾å–®åˆ—è³‡æ–™å¾—åˆ°åˆ†æ•¸ ===
def _pred_from_row(r, idx):
    paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
    access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}

    rr = None
    if idx["rating"] is not None and len(r) > idx["rating"]:
        try:
            rr = int((r[idx["rating"]] or "").strip())
        except:
            rr = None
    pp = (r[idx["paper"]] or "").strip() if idx["paper"] is not None and len(r) > idx["paper"] else "æ²’æ³¨æ„"
    aa = (r[idx["access"]] or "").strip() if idx["access"] is not None and len(r) > idx["access"] else "æ²’æ³¨æ„"

    score = None
    if rr is not None and cleanliness_model is not None:
        try:
            feat = [rr, paper_map.get(pp, 0), access_map.get(aa, 0)]
            score = expected_from_feats([feat])
        except Exception:
            score = None
    if score is None and idx["pred"] is not None and len(r) > idx["pred"]:
        try:
            score = float((r[idx["pred"]] or "").strip())
        except:
            score = None
    if score is None:
        score = _simple_score(rr, pp, aa)
    return (score, rr, pp, aa)

# === ä»¥æœ€è¿‘ N ç­†åšã€Œå³æ™‚é æ¸¬ã€èˆ‡ 95% CI ===
def compute_nowcast_ci(lat, lon, k=LAST_N_HISTORY, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return None

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return None

        def close(a, b):
            try:
                return abs(float(a) - float(b)) <= tol
            except:
                return False

        same = [r for r in data
                if len(r) > max(idx["lat"], idx["lon"])
                and close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon)]
        if not same:
            return None

        if idx["created"] is not None:
            same.sort(key=lambda x: x[idx["created"]], reverse=True)
        recent = same[:k]

        vals = []
        for r in recent:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                vals.append(float(sc))
        if not vals:
            return None

        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            vals = []
            for r in recent:
                sc, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    vals.append(sc2)
            if not vals:
                return None

        mean = round(sum(vals) / len(vals), 2)
        if len(vals) == 1:
            return {"mean": mean, "lower": mean, "upper": mean, "n": 1}

        try:
            s = statistics.stdev(vals)
        except statistics.StatisticsError:
            s = 0.0
        se = s / (len(vals) ** 0.5)
        lower = max(1.0, round(mean - 1.96 * se, 2))
        upper = min(5.0, round(mean + 1.96 * se, 2))
        return {"mean": mean, "lower": lower, "upper": upper, "n": len(vals)}
    except Exception as e:
        logging.error(f"âŒ compute_nowcast_ci å¤±æ•—: {e}")
        return None

# === Nowcast API ===
@app.route("/get_nowcast_by_coord/<lat>/<lon>")
def get_nowcast_by_coord(lat, lon):
    try:
        res = compute_nowcast_ci(lat, lon)
        if not res:
            return {"success": True, "n": 0}, 200
        res["success"] = True
        return res, 200
    except Exception as e:
        logging.error(f"âŒ Nowcast API éŒ¯èª¤: {e}")
        return {"success": False}, 500

# === å›é¥‹ ===
@app.route("/submit_feedback", methods=["POST"])
def submit_feedback():
    try:
        data = request.form
        name = (data.get("name","") or "").strip()
        address = (data.get("address","") or "").strip()

        lat_raw = data.get("lat","")
        lon_raw = data.get("lon","")
        lat_f, lon_f = _parse_lat_lon(lat_raw, lon_raw)
        if lat_f is None or lon_f is None:
            return "åº§æ¨™æ ¼å¼éŒ¯èª¤", 400
        lat = norm_coord(lat_f)
        lon = norm_coord(lon_f)

        rating = (data.get("rating","") or "").strip()
        toilet_paper = (data.get("toilet_paper","") or "").strip()
        accessibility = (data.get("accessibility","") or "").strip()
        time_of_use = (data.get("time_of_use","") or "").strip()
        comment = (data.get("comment","") or "").strip()

        if not all([name, rating, lat, lon]):
            return "ç¼ºå°‘å¿…è¦æ¬„ä½ï¼ˆéœ€è¦ï¼šnameã€ratingã€latã€lonï¼‰", 400

        try:
            r = int(rating)
            if r < 1 or r > 10:
                return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆåœ¨ 1 åˆ° 10 ä¹‹é–“", 400
        except ValueError:
            return "æ¸…æ½”åº¦è©•åˆ†å¿…é ˆæ˜¯æ•¸å­—", 400

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        cur_feat = [r, paper_map.get(toilet_paper, 0), access_map.get(accessibility, 0)]

        hist_feats = []
        try:
            rows = feedback_sheet.get_all_values()
            header = rows[0]; data_rows = rows[1:]
            idx = _feedback_indices(header)

            def close(a, b, tol=1e-6):
                try: return abs(float(a) - float(b)) <= tol
                except: return False

            same_coord = []
            for row in data_rows:
                if idx["lat"] is None or idx["lon"] is None:
                    break
                if len(row) <= max(idx["lat"], idx["lon"]):
                    continue
                if close(row[idx["lat"]], lat) and close(row[idx["lon"]], lon):
                    same_coord.append(row)

            if idx["created"] is not None:
                same_coord.sort(key=lambda x: x[idx["created"]], reverse=True)
            recent = same_coord[:LAST_N_HISTORY]

            if idx["rating"] is not None:
                for row in recent:
                    try:
                        rr = int((row[idx["rating"]] or "").strip())
                    except:
                        continue
                    pp = (row[idx["paper"]] or "").strip() if idx["paper"] is not None else "æ²’æ³¨æ„"
                    aa = (row[idx["access"]] or "").strip() if idx["access"] is not None else "æ²’æ³¨æ„"
                    hist_feats.append([rr, paper_map.get(pp,0), access_map.get(aa,0)])
        except Exception as e:
            logging.warning(f"è®€æ­·å²å›é¥‹å¤±æ•—ï¼Œåƒ…ç”¨å–®ç­†ç‰¹å¾µé æ¸¬ï¼š{e}")

        pred_with_hist = expected_from_feats([cur_feat] + hist_feats) or expected_from_feats([cur_feat]) or "æœªé æ¸¬"

        feedback_sheet.append_row([
            name, address, rating, toilet_paper, accessibility, time_of_use,
            comment, pred_with_hist, lat, lon, datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
        ])

        return redirect(url_for("feedback_form", toilet_name=name, address=address or "") + f"?lat={lat}&lon={lon}")
    except Exception as e:
        logging.error(f"âŒ æäº¤å›é¥‹è¡¨å–®éŒ¯èª¤: {e}")
        return "æäº¤å¤±æ•—", 500

# === è®€åº§æ¨™çš„å›é¥‹æ¸…å–® ===
def get_feedbacks_by_coord(lat, lon, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return []
        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        out = []
        for r in data:
            if idx["lat"] is None or idx["lon"] is None:
                break
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                def val(key):
                    i = idx[key]
                    return (r[i] if i is not None and len(r) > i else "").strip()
                out.append({
                    "rating": val("rating"),
                    "toilet_paper": val("paper"),
                    "accessibility": val("access"),
                    "time_of_use": val("time"),
                    "comment": val("comment"),
                    "cleanliness_score": val("pred"),
                    "created_at": val("created"),
                })
        out.sort(key=lambda d: d.get("created_at", ""), reverse=True)
        return out
    except Exception as e:
        logging.error(f"âŒ è®€å–å›é¥‹åˆ—è¡¨ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return []

# === ä»¥åº§æ¨™èšåˆçš„çµ±è¨ˆï¼ˆæ‘˜è¦ï¼‰â€” åˆ†æ•¸ä¸€è‡´åŒ– ===
def get_feedback_summary_by_coord(lat, lon, tol=1e-6):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return "ï¼ˆè¡¨é ­ç¼ºå°‘ lat/lon æ¬„ä½ï¼‰"

        def close(a, b):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched.append(r)

        if not matched:
            return "å°šç„¡å›é¥‹è³‡æ–™"

        paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
        scores = []
        comments = []

        for r in matched:
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if isinstance(sc, (int, float)):
                scores.append(float(sc))
            if pp in paper_counts: paper_counts[pp] += 1
            if aa in access_counts: access_counts[aa] += 1
            if idx["comment"] is not None and len(r) > idx["comment"]:
                c = (r[idx["comment"]] or "").strip()
                if c:
                    comments.append(c)

        avg_score = round(sum(scores) / len(scores), 2) if scores else "æœªé æ¸¬"

        summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\n"
        summary += f"ğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg_score}\n"
        summary += f"ğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰'] >= paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        summary += f"â™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰'] >= access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        if comments:
            summary += f"ğŸ’¬ æœ€æ–°ç•™è¨€ï¼š{comments[-1]}"
        return summary
    except Exception as e:
        logging.error(f"âŒ æŸ¥è©¢å›é¥‹çµ±è¨ˆï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "è®€å–éŒ¯èª¤"

# === å»ºæ¸…å–® ===
_feedback_index_cache = {"ts": 0, "data": {}}
_FEEDBACK_INDEX_TTL = 30  # ç§’

def build_feedback_index():
    global _feedback_index_cache
    now = time.time()
    if now - _feedback_index_cache["ts"] < _FEEDBACK_INDEX_TTL and _feedback_index_cache["data"]:
        return _feedback_index_cache["data"]

    result = {}
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            _feedback_index_cache = {"ts": now, "data": {}}
            return result
        header = rows[0]; data = rows[1:]
        idx = _feedback_indices(header)

        bucket = {}
        for r in data:
            try:
                if idx["lat"] is None or idx["lon"] is None:
                    continue
                lat_s = norm_coord(r[idx["lat"]])
                lon_s = norm_coord(r[idx["lon"]])
            except Exception:
                continue
            rec = bucket.setdefault((lat_s, lon_s), {"paper": {"æœ‰":0,"æ²’æœ‰":0}, "access":{"æœ‰":0,"æ²’æœ‰":0}, "scores":[]})
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if pp in rec["paper"]: rec["paper"][pp] += 1
            if aa in rec["access"]: rec["access"][aa] += 1
            if isinstance(sc, (int, float)): rec["scores"].append(float(sc))

        out = {}
        for key, v in bucket.items():
            paper = "æœ‰" if v["paper"]["æœ‰"] >= v["paper"]["æ²’æœ‰"] and sum(v["paper"].values())>0 else ("æ²’æœ‰" if sum(v["paper"].values())>0 else "?")
            access = "æœ‰" if v["access"]["æœ‰"] >= v["access"]["æ²’æœ‰"] and sum(v["access"].values())>0 else ("æ²’æœ‰" if sum(v["access"].values())>0 else "?")
            avg = round(sum(v["scores"])/len(v["scores"]),2) if v["scores"] else None
            out[key] = {"paper": paper, "access": access, "avg": avg}

        _feedback_index_cache = {"ts": now, "data": out}
        return out
    except Exception as e:
        logging.warning(f"å»ºç«‹æŒ‡ç¤ºç‡ˆç´¢å¼•å¤±æ•—ï¼š{e}")
        return {}

# === èˆŠè·¯ç”±ä¿ç•™ ===
@app.route("/toilet_feedback/<toilet_name>")
def toilet_feedback(toilet_name):
    try:
        address = "æœªçŸ¥åœ°å€"
        rows = worksheet.get_all_values()
        data = rows[1:]
        for row in data:
            if len(row) > 1 and row[1] == toilet_name:
                address = (row[2] if len(row) > 2 else "") or "æœªçŸ¥åœ°å€"
                break

        if address == "æœªçŸ¥åœ°å€":
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="è«‹æ”¹ç”¨åº§æ¨™ç‰ˆå…¥å£ï¼ˆå¡ç‰‡ä¸Šçš„ã€æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰ã€ï¼‰ã€‚",
                                   feedbacks=[], address="", avg_pred_score="æœªé æ¸¬", lat="", lon="")

        rows_fb = feedback_sheet.get_all_values()
        header = rows_fb[0]; data_fb = rows_fb[1:]
        idx = _feedback_indices(header)
        if idx["address"] is None:
            return render_template("toilet_feedback.html", toilet_name=toilet_name,
                                   summary="ï¼ˆè¡¨é ­ç¼ºå°‘ã€åœ°å€ã€æ¬„ä½ï¼‰", feedbacks=[], address=address,
                                   avg_pred_score="æœªé æ¸¬", lat="", lon="")

        matched = [r for r in data_fb
                   if len(r) > idx["address"] and (r[idx["address"]] or "").strip() == address.strip()]

        fbs = []
        nums = []
        for r in matched:
            def val(k):
                i = idx[k]
                return (r[i] if i is not None and len(r) > i else "").strip()
            sc, rr, pp, aa = _pred_from_row(r, idx)
            try: nums.append(float(sc))
            except: pass
            fbs.append({
                "rating": val("rating"),
                "toilet_paper": val("paper"),
                "accessibility": val("access"),
                "time_of_use": val("time"),
                "comment": val("comment"),
                "cleanliness_score": str(sc) if sc is not None else "",
                "created_at": val("created"),
            })
        fbs.sort(key=lambda d: d.get("created_at",""), reverse=True)
        avg_pred_score = round(sum(nums)/len(nums), 2) if nums else "æœªé æ¸¬"

        if matched:
            paper_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            access_counts = {"æœ‰": 0, "æ²’æœ‰": 0}
            for r in matched:
                _, _, pp, aa = _pred_from_row(r, idx)
                if pp in paper_counts: paper_counts[pp] += 1
                if aa in access_counts: access_counts[aa] += 1
            avg = avg_pred_score
            summary = f"ğŸ” ç­†æ•¸ï¼š{len(matched)}\nğŸ§¼ å¹³å‡æ¸…æ½”åˆ†æ•¸ï¼š{avg}\nğŸ§» è¡›ç”Ÿç´™ï¼š{'æœ‰' if paper_counts['æœ‰']>=paper_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\nâ™¿ ç„¡éšœç¤™ï¼š{'æœ‰' if access_counts['æœ‰']>=access_counts['æ²’æœ‰'] else 'æ²’æœ‰'}\n"
        else:
            summary = "å°šç„¡å›é¥‹è³‡æ–™"

        return render_template("toilet_feedback.html",
                               toilet_name=toilet_name, summary=summary,
                               feedbacks=fbs, address=address,
                               avg_pred_score=avg_pred_score, lat="", lon="")
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ–°è·¯ç”±ï¼šåº§æ¨™ç‰ˆï¼ˆä¸Šæ–¹è—è‰²å¹³å‡ä¹Ÿæ”¹æˆä¸€è‡´é‚è¼¯ï¼‰ ===
@app.route("/toilet_feedback_by_coord/<lat>/<lon>")
def toilet_feedback_by_coord(lat, lon):
    try:
        name = f"å»æ‰€ï¼ˆ{lat}, {lon}ï¼‰"
        summary = get_feedback_summary_by_coord(lat, lon)
        feedbacks = get_feedbacks_by_coord(lat, lon)

        rows = feedback_sheet.get_all_values()
        header = rows[0]; data = rows[1:]
        idx = _feedback_indices(header)

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        scores = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                sc, _, _, _ = _pred_from_row(r, idx)
                if isinstance(sc, (int, float)):
                    scores.append(float(sc))
        avg_pred_score = round(sum(scores)/len(scores), 2) if scores else "æœªé æ¸¬"

        return render_template(
            "toilet_feedback.html",
            toilet_name=name,
            summary=summary,
            feedbacks=feedbacks,
            address=f"{lat},{lon}",
            avg_pred_score=avg_pred_score,
            lat=lat,
            lon=lon
        )
    except Exception as e:
        logging.error(f"âŒ æ¸²æŸ“å›é¥‹é é¢ï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return "æŸ¥è©¢å¤±æ•—", 500

# === æ¸…æ½”åº¦è¶¨å‹¢ APIï¼ˆåº§æ¨™ï¼‰â€” åˆ†æ•¸ä¸€è‡´åŒ– ===
@app.route("/get_clean_trend_by_coord/<lat>/<lon>")
def get_clean_trend_by_coord(lat, lon):
    try:
        rows = feedback_sheet.get_all_values()
        if not rows or len(rows) < 2:
            return {"success": True, "data": []}, 200

        header = rows[0]
        idx = _feedback_indices(header)
        data = rows[1:]

        if idx["lat"] is None or idx["lon"] is None:
            return {"success": False, "data": []}, 200

        def close(a, b, tol=1e-6):
            try: return abs(float(a) - float(b)) <= tol
            except: return False

        matched_rows = []
        for r in data:
            if len(r) <= max(idx["lat"], idx["lon"]):
                continue
            if close(r[idx["lat"]], lat) and close(r[idx["lon"]], lon):
                matched_rows.append(r)

        if not matched_rows:
            return {"success": True, "data": []}, 200

        recomputed = []
        for r in matched_rows:
            created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
            sc, rr, pp, aa = _pred_from_row(r, idx)
            if sc is None:
                sc = _simple_score(rr, pp, aa)
            if isinstance(sc, (int, float)):
                recomputed.append((created, float(sc)))

        if not recomputed:
            return {"success": True, "data": []}, 200

        vals = [p for _, p in recomputed]
        if len(vals) >= 2 and (max(vals) - min(vals) < 1e-6):
            forced = []
            for r in matched_rows:
                created = r[idx["created"]] if idx["created"] is not None and len(r) > idx["created"] else ""
                _, rr, pp, aa = _pred_from_row(r, idx)
                sc2 = _simple_score(rr, pp, aa)
                if sc2 is not None:
                    forced.append((created, float(sc2)))
            if forced:
                recomputed = forced

        recomputed.sort(key=lambda t: t[0])
        out = [{"score": round(p, 2)} for _, p in recomputed]
        return {"success": True, "data": out}, 200

    except Exception as e:
        logging.error(f"âŒ è¶¨å‹¢ APIï¼ˆåº§æ¨™ï¼‰éŒ¯èª¤: {e}")
        return {"success": False, "data": []}, 500

# === åŒæ„é é¢ / éš±ç§é  ===
@app.route("/consent", methods=["GET"])
def render_consent_page():
    return render_template("consent.html")

@app.route("/privacy", methods=["GET"])
def render_privacy_page():
    # ä½ çš„æª”åæ˜¯ privacy.html
    return render_template("privacy.html")

# === LIFF é€è³‡æ–™å›ä¾†çš„ API ===
@app.route("/api/consent", methods=["POST"])
def api_consent():
    try:
        payload = request.get_json(force=True, silent=False) or {}
        agreed = bool(payload.get("agree"))
        user_id = (payload.get("userId") or "").strip()
        display_name = payload.get("displayName") or ""
        source_type = payload.get("sourceType") or ""
        ua = payload.get("ua") or request.headers.get("User-Agent","")
        ts = payload.get("ts") or datetime.utcnow().isoformat()

        if not user_id:
            return {"ok": False, "message": "ç¼ºå°‘ userId"}, 400

        ok = upsert_consent(user_id, agreed, display_name, source_type, ua, ts)
        if not ok:
            return {"ok": False, "message": "å¯«å…¥å¤±æ•—"}, 500

        return {"ok": True}, 200
    except Exception as e:
        logging.error(f"/api/consent å¤±æ•—: {e}")
        return {"ok": False}, 500

@app.route("/_debug_predict")
def _debug_predict():
    try:
        r = int(request.args.get("rating"))
        paper = request.args.get("paper", "æ²’æ³¨æ„")
        acc = request.args.get("access", "æ²’æ³¨æ„")

        paper_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        access_map = {"æœ‰": 1, "æ²’æœ‰": 0, "æ²’æ³¨æ„": 0}
        feat = [r, paper_map.get(paper, 0), access_map.get(acc, 0)]
        exp = expected_from_feats([feat])

        return {
            "ok": True,
            "input": {"rating": r, "paper": paper, "access": acc},
            "expected": exp
        }, 200
    except Exception as e:
        logging.error(e)
        return {"ok": False}, 500

# === å»ºç«‹ Flexï¼šé™„è¿‘ / æœ€æ„›ï¼ˆå«æŒ‡ç¤ºç‡ˆï¼‰ ===
def create_toilet_flex_messages(toilets, show_delete=False, uid=None):
    indicators = build_feedback_index()
    bubbles = []
    for toilet in toilets[:5]:
        actions = []

        lat_s = norm_coord(toilet['lat'])
        lon_s = norm_coord(toilet['lon'])
        addr_text = toilet.get('address') or "ï¼ˆç„¡åœ°å€ï¼Œä½¿ç”¨åº§æ¨™ï¼‰"

        ind = indicators.get((lat_s, lon_s), {"paper":"?","access":"?","avg":None})
        star_text = f"â­{ind['avg']}" if ind.get("avg") is not None else "â­â€”"
        paper_text = "ğŸ§»æœ‰" if ind.get("paper")=="æœ‰" else ("ğŸ§»ç„¡" if ind.get("paper")=="æ²’æœ‰" else "ğŸ§»â€”")
        access_text = "â™¿æœ‰" if ind.get("access")=="æœ‰" else ("â™¿ç„¡" if ind.get("access")=="æ²’æœ‰" else "â™¿â€”")

        actions.append({
            "type": "uri",
            "label": "å°èˆª",
            "uri": f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"
        })
        actions.append({
            "type": "uri",
            "label": "æŸ¥è©¢å›é¥‹",
            "uri": f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"
        })
        addr_raw = toilet.get('address') or ""
        addr_param = quote(addr_raw or "-")
        actions.append({
            "type": "uri",
            "label": "å»æ‰€å›é¥‹",
            "uri": (
                "https://school-i9co.onrender.com/feedback_form/"
                f"{quote(toilet['name'])}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
            )
        })

        if toilet.get("type") == "favorite" and uid:
            actions.append({
                "type": "postback",
                "label": "ç§»é™¤æœ€æ„›",
                "data": f"remove_fav:{quote(toilet['name'])}:{lat_s}:{lon_s}"
            })
        elif toilet.get("type") not in ["user", "favorite"] and uid:
            actions.append({
                "type": "postback",
                "label": "åŠ å…¥æœ€æ„›",
                "data": f"add:{quote(toilet['name'])}:{lat_s}:{lon_s}"
            })

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": toilet['name'], "weight": "bold", "size": "lg", "wrap": True},
                    {"type": "text", "text": f"{paper_text}  {access_text}  {star_text}", "size": "sm", "color": "#555555", "wrap": True},
                    {"type": "text", "text": addr_text, "size": "sm", "color": "#666666", "wrap": True},
                    {"type": "text", "text": f"{int(toilet['distance'])} å…¬å°º", "size": "sm", "color": "#999999"}
                ]
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {"type": "button", "style": "primary", "height": "sm", "action": actions[0]}
                ] + [
                    {"type": "button", "style": "secondary", "height": "sm", "action": a}
                    for a in actions[1:]
                ]
            }
        }
        bubbles.append(bubble)
    return {"type": "carousel", "contents": bubbles}

# === åˆ—å‡ºã€Œæˆ‘çš„è²¢ç»ã€ & å‰Šé™¤ ===
def get_user_contributions(uid):
    items = []
    try:
        rows = worksheet.get_all_values()
        if not rows or len(rows) < 2:
            return items
        header = rows[0]; data = rows[1:]
        idx = _toilet_sheet_indices(header)
        for i, r in enumerate(data, start=2):
            if idx["user_id"] is None: break
            if len(r) <= idx["user_id"]: continue
            if r[idx["user_id"]] != uid: continue
            try:
                lat = float(r[idx["lat"]]); lon = float(r[idx["lon"]])
            except:
                continue
            items.append({
                "row_index": i,
                "name": (r[idx["name"]] if idx["name"] is not None and len(r)>idx["name"] else "ç„¡åç¨±"),
                "address": (r[idx["address"]] if idx["address"] is not None and len(r)>idx["address"] else ""),
                "lat": float(norm_coord(lat)),
                "lon": float(norm_coord(lon)),
                "created": (r[idx["created"]] if idx["created"] is not None and len(r)>idx["created"] else ""),
            })
        return items
    except Exception as e:
        logging.error(f"è®€å–æˆ‘çš„è²¢ç»å¤±æ•—ï¼š{e}")
        return items

def create_my_contrib_flex(uid):
    contribs = get_user_contributions(uid)
    if not contribs:
        return None
    bubbles = []
    for it in contribs[:10]:
        lat_s = norm_coord(it["lat"]); lon_s = norm_coord(it["lon"])
        addr_raw = it.get('address','') or ""
        addr_param = quote(addr_raw or "-")
        actions = [
            {"type":"uri","label":"å°èˆª","uri":f"https://www.google.com/maps/search/?api=1&query={lat_s},{lon_s}"},
            {"type":"uri","label":"æŸ¥è©¢å›é¥‹ï¼ˆåº§æ¨™ï¼‰","uri":f"https://school-i9co.onrender.com/toilet_feedback_by_coord/{lat_s}/{lon_s}"},
            {"type":"uri","label":"å»æ‰€å›é¥‹",
             "uri":(
                f"https://school-i9co.onrender.com/feedback_form/{quote(it['name'])}/{addr_param}"
                f"?lat={lat_s}&lon={lon_s}&address={quote(addr_raw)}"
             )},
            {"type":"postback","label":"åˆªé™¤æ­¤è²¢ç»","data":f"confirm_delete_my_toilet:{it['row_index']}"}
        ]
        bubble = {
            "type":"bubble",
            "body":{
                "type":"box","layout":"vertical","contents":[
                    {"type":"text","text":it["name"],"size":"lg","weight":"bold","wrap":True},
                    {"type":"text","text":it.get("address") or "ï¼ˆç„¡åœ°å€ï¼‰","size":"sm","color":"#666666","wrap":True},
                    {"type":"text","text":f"{it['created']}", "size":"xs","color":"#999999"}
                ]
            },
            "footer":{
                "type":"box","layout":"vertical","spacing":"sm",
                "contents":[{"type":"button","style":"primary","height":"sm","action":actions[0]}] + [
                    {"type":"button","style":"secondary","height":"sm","action":a} for a in actions[1:]
                ]
            }
        }
        bubbles.append(bubble)
    return {"type":"carousel","contents":bubbles}

# === Webhook ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

@app.route("/", methods=["GET"])
def home():
    return "Toilet bot is running!", 200

# === ä½¿ç”¨è€…ä½ç½®è³‡æ–™ ===
user_locations = {}
pending_delete_confirm = {}  # {uid: {..., mode:'favorite'|'sheet_row'}}

# === TextMessage ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    uid = event.source.user_id
    text_raw = event.message.text or ""
    text = text_raw.strip().lower()

    if is_duplicate_and_mark(f"text|{uid}|{text}"):
        return

    # â˜… åŒæ„é–€æª»ï¼ˆæ–°èˆŠä½¿ç”¨è€…éƒ½è¦å…ˆåŒæ„ä¸€æ¬¡ï¼‰
    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    reply_messages = []

    if uid in pending_delete_confirm:
        info = pending_delete_confirm[uid]
        if text == "ç¢ºèªåˆªé™¤":
            if info.get("mode") == "sheet_row":
                ok = False
                try:
                    worksheet.delete_rows(int(info["row"]))
                    ok = True
                except Exception as e:
                    logging.error(f"åˆªä¸»è³‡æ–™åˆ—å¤±æ•—ï¼š{e}")
                msg = "âœ… å·²åˆªé™¤ä½ çš„è²¢ç»" if ok else "âŒ åˆªé™¤å¤±æ•—"
            else:
                success = remove_from_favorites(uid, info["name"], info["lat"], info["lon"])
                msg = "âœ… å·²åˆªé™¤è©²å»æ‰€" if success else "âŒ åˆªé™¤å¤±æ•—"
            del pending_delete_confirm[uid]
            reply_messages.append(TextSendMessage(text=msg))
        elif text == "å–æ¶ˆ":
            del pending_delete_confirm[uid]
            reply_messages.append(TextSendMessage(text="âŒ å·²å–æ¶ˆåˆªé™¤"))
        else:
            reply_messages.append(TextSendMessage(text="âš ï¸ è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€"))

    elif text == "é™„è¿‘å»æ‰€":
        if uid not in user_locations:
            reply_messages.append(TextSendMessage(text="è«‹å…ˆå‚³é€ä½ç½®"))
        else:
            lat, lon = user_locations[uid]
            toilets = _merge_and_dedupe_lists(
                query_public_csv_toilets(lat, lon) or [],
                query_sheet_toilets(lat, lon) or [],
                query_overpass_toilets(lat, lon) or [],
            )
            if not toilets:
                reply_messages.append(TextSendMessage(text="é™„è¿‘æ²’æœ‰å»æ‰€ï¼Œå¯èƒ½è¦åŸåœ°è§£æ”¾äº† ğŸ’¦"))
            else:
                msg = create_toilet_flex_messages(toilets, show_delete=False, uid=uid)
                reply_messages.append(FlexSendMessage("é™„è¿‘å»æ‰€", msg))

    elif text == "æˆ‘çš„æœ€æ„›":
        favs = get_user_favorites(uid)
        if not favs:
            reply_messages.append(TextSendMessage(text="ä½ å°šæœªæ”¶è—ä»»ä½•å»æ‰€"))
        else:
            if uid in user_locations:
                lat, lon = user_locations[uid]
                for f in favs:
                    f["distance"] = haversine(lat, lon, f["lat"], f["lon"])
            msg = create_toilet_flex_messages(favs, show_delete=True, uid=uid)
            reply_messages.append(FlexSendMessage("æˆ‘çš„æœ€æ„›", msg))

    elif text == "æˆ‘çš„è²¢ç»":
        msg = create_my_contrib_flex(uid)
        if msg:
            reply_messages.append(FlexSendMessage("æˆ‘æ–°å¢çš„å»æ‰€", msg))
        else:
            reply_messages.append(TextSendMessage(text="ä½ é‚„æ²’æœ‰æ–°å¢éå»æ‰€å–”ã€‚"))

    elif text == "æ–°å¢å»æ‰€":
        base = "https://school-i9co.onrender.com/add"
        if uid in user_locations:
            la, lo = user_locations[uid]
            url = f"{base}?uid={quote(uid)}&lat={la}&lon={lo}#openExternalBrowser=1"
        else:
            url = f"{base}#openExternalBrowser=1"
        reply_messages.append(TextSendMessage(text=f"è«‹å‰å¾€æ­¤é æ–°å¢å»æ‰€ï¼š\n{url}"))

    elif text == "å›é¥‹":
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdsibz15enmZ3hJsQ9s3BiTXV_vFXLy0llLKlpc65vAoGo_hg/viewform?usp=sf_link"
        reply_messages.append(TextSendMessage(text=f"ğŸ’¡ è«‹é€éä¸‹åˆ—é€£çµå›å ±å•é¡Œæˆ–æä¾›æ„è¦‹ï¼š\n{form_url}"))

    if reply_messages:
        safe_reply(event, reply_messages)

# === LocationMessage ===
@handler.add(MessageEvent, message=LocationMessage)
def handle_location(event):
    uid = event.source.user_id
    lat = event.message.latitude
    lon = event.message.longitude

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    key = f"loc|{uid}|{round(lat,5)},{round(lon,5)}"
    if is_duplicate_and_mark(key):
        return

    user_locations[uid] = (lat, lon)
    safe_reply(event, TextSendMessage(text="âœ… ä½ç½®å·²æ›´æ–°"))

# === Postback ===
@handler.add(PostbackEvent)
def handle_postback(event):
    uid = event.source.user_id
    data = event.postback.data or ""

    if is_duplicate_and_mark(f"pb|{uid}|{data}"):
        return

    gate_msg = ensure_consent_or_prompt(uid)
    if gate_msg:
        safe_reply(event, gate_msg)
        return

    try:
        if data.startswith("add:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            toilet = {
                "name": name,
                "lat": float(lat),
                "lon": float(lon),
                "address": f"{lat},{lon}",
                "distance": 0,
                "type": "sheet"
            }
            add_to_favorites(uid, toilet)
            safe_reply(event, TextSendMessage(text=f"âœ… å·²æ”¶è— {name}"))

        elif data.startswith("remove_fav:"):
            _, qname, lat, lon = data.split(":", 3)
            name = unquote(qname)
            success = remove_from_favorites(uid, name, lat, lon)
            msg = "âœ… å·²ç§»é™¤æœ€æ„›" if success else "âŒ ç§»é™¤å¤±æ•—"
            safe_reply(event, TextSendMessage(text=msg))

        elif data.startswith("confirm_delete:"):
            _, qname, qaddr, lat, lon = data.split(":", 4)
            name = unquote(qname)
            pending_delete_confirm[uid] = {
                "mode": "favorite",
                "name": name,
                "lat": norm_coord(lat),
                "lon": norm_coord(lon)
            }
            safe_reply(event, [
                TextSendMessage(text=f"âš ï¸ ç¢ºå®šè¦åˆªé™¤ {name} å—ï¼Ÿï¼ˆç›®å‰åˆªé™¤ç‚ºç§»é™¤æœ€æ„›ï¼‰"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])

        elif data.startswith("confirm_delete_my_toilet:"):
            _, row_str = data.split(":", 1)
            pending_delete_confirm[uid] = {
                "mode": "sheet_row",
                "row": int(row_str)
            }
            safe_reply(event, [
                TextSendMessage(text="âš ï¸ ç¢ºå®šè¦åˆªé™¤æ­¤ã€ä½ æ–°å¢çš„å»æ‰€ã€å—ï¼Ÿæ­¤å‹•ä½œæœƒå¾ä¸»è³‡æ–™è¡¨åˆªé™¤è©²åˆ—ã€‚"),
                TextSendMessage(text="è«‹è¼¸å…¥ã€ç¢ºèªåˆªé™¤ã€æˆ–ã€å–æ¶ˆã€")
            ])

    except Exception as e:
        logging.error(f"âŒ è™•ç† postback å¤±æ•—: {e}")

# === æ–°å¢å»æ‰€é é¢ ===
@app.route("/add", methods=["GET"])
def render_add_page():
    uid = request.args.get("uid", "")
    lat = request.args.get("lat", "")
    lon = request.args.get("lon", "")
    preset_address = ""

    if lat and lon:
        try:
            ua_email = os.getenv("CONTACT_EMAIL", "you@example.com")
            url = f"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat={lat}&lon={lon}&addressdetails=1"
            headers = {"User-Agent": f"ToiletBot/1.0 (+{ua_email})"}
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                a = data.get("address", {})
                pretty = " ".join(filter(None, [
                    a.get("country", ""),
                    a.get("state", a.get("region", "")),
                    a.get("city", a.get("town", a.get("village", a.get("county", "")))),
                    a.get("suburb", a.get("neighbourhood", "")),
                    a.get("road", ""),
                    a.get("house_number", ""),
                    a.get("postcode", "")
                ])).strip()
                preset_address = pretty or data.get("display_name", "")
        except Exception as e:
            logging.warning(f"reverse geocode å¤±æ•—: {e}")

    return render_template(
        "submit_toilet.html",
        preset_address=preset_address,
        preset_lat=lat,
        preset_lon=lon
    )

# === ä½¿ç”¨è€…æ–°å¢å»æ‰€ API ===
@app.route("/submit_toilet", methods=["POST"])
def submit_toilet():
    try:
        data = request.get_json()
        logging.info(f"ğŸ“¥ æ”¶åˆ°è¡¨å–®è³‡æ–™: {data}")

        uid = data.get("user_id") or "web"
        name = data.get("name")
        address = data.get("address")
        lat = data.get("lat", "")
        lon = data.get("lon", "")

        if not all([name, address]):
            return {"success": False, "message": "ç¼ºå°‘åƒæ•¸"}, 400

        lat_f, lon_f = None, None
        if lat and lon:
            lat_f, lon_f = _parse_lat_lon(lat, lon)
        if lat_f is None or lon_f is None:
            lat_f, lon_f = geocode_address(address)

        if lat_f is None or lon_f is None:
            return {"success": False, "message": "åœ°å€è½‰æ›å¤±æ•—"}, 400

        lat_s, lon_s = norm_coord(lat_f), norm_coord(lon_f)

        worksheet.append_row([
            uid, name, address, float(lat_s), float(lon_s),
            datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
        ])
        logging.info(f"âœ… å»æ‰€è³‡æ–™å·²å¯«å…¥ Google Sheets: {name}")

        try:
            if not os.path.exists(TOILETS_FILE_PATH):
                with open(TOILETS_FILE_PATH, "w", encoding="utf-8", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(PUBLIC_HEADERS)
            with open(TOILETS_FILE_PATH, "a", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "00000","0000000","æœªçŸ¥é‡Œ","USERADD", name, address, "ä½¿ç”¨è€…è£œå……",
                    lat_s, lon_s,
                    "æ™®é€šç´š","å…¬å…±å ´æ‰€","æœªçŸ¥","ä½¿ç”¨è€…","0"
                ])
        except Exception as e:
            logging.warning(f"å‚™ä»½è‡³æœ¬åœ° CSV å¤±æ•—ï¼š{e}")

        return {"success": True, "message": f"âœ… å·²æ–°å¢å»æ‰€ {name}"}
    except Exception as e:
        logging.error(f"âŒ æ–°å¢å»æ‰€éŒ¯èª¤:\n{traceback.format_exc()}")
        return {"success": False, "message": "ä¼ºæœå™¨éŒ¯èª¤"}, 500

# === èƒŒæ™¯æ’ç¨‹ï¼ˆé ç•™ï¼‰ ===
def auto_predict_cleanliness_background():
    while True:
        try:
            logging.info("ğŸŒ€ èƒŒæ™¯æ’ç¨‹å•Ÿå‹•ä¸­ï¼ˆæœªä¾†å¯åŠ å…¥è‡ªå‹•çµ±è¨ˆï¼‰")
        except Exception as e:
            logging.error(f"âŒ èƒŒæ™¯ä»»å‹™å‡ºéŒ¯ï¼š{e}")
        time.sleep(1800)

# === å•Ÿå‹• ===
if __name__ == "__main__":
    threading.Thread(target=auto_predict_cleanliness_background, daemon=True).start()
    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
